{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ed1d88a7",
      "metadata": {
        "id": "ed1d88a7"
      },
      "source": [
        "# Importação de Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f62fc9a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f62fc9a",
        "outputId": "f092be84-8b45-43c2-bd73-970c565748f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Todas as bibliotecas carregadas com sucesso!\n"
          ]
        }
      ],
      "source": [
        "#  Importação de bibliotecas completas para experimentos com MLflow e DVC/Dagshub\n",
        "\n",
        "# --- 1. Manipulação de Dados e Sistema ---\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import io\n",
        "import warnings\n",
        "import tempfile\n",
        "from tempfile import mkdtemp\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "# --- 2. Visualização ---\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --- 3. Versionamento e Conexão (DVC/Dagshub) ---\n",
        "import dvc.api\n",
        "from dagshub.data_engine import datasources\n",
        "import dagshub\n",
        "\n",
        "# --- 4. Rastreamento de Experimentos (MLflow) ---\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import mlflow.catboost\n",
        "import mlflow.lightgbm\n",
        "import mlflow.xgboost\n",
        "import mlflow.models.signature\n",
        "from mlflow.models import infer_signature\n",
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "# --- 5. Machine Learning (Scikit-learn) ---\n",
        "# 5.1. Modelos\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, StackingClassifier\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
        "\n",
        "# 5.2. Pré-processamento\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler, LabelEncoder\n",
        "\n",
        "# 5.3. Seleção e Validação de Modelos\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
        "\n",
        "# 5.4. Métricas de Avaliação\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    precision_recall_fscore_support,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    make_scorer,\n",
        "    mean_squared_error,\n",
        "    mean_absolute_error,\n",
        "    r2_score,\n",
        "    mean_absolute_percentage_error\n",
        ")\n",
        "# Alias para skm, se preferir usar (opcional)\n",
        "import sklearn.metrics as skm\n",
        "\n",
        "# --- 6. Bibliotecas de Gradient Boosting ---\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "from xgboost.callback import EarlyStopping as XGBCallback  # Renomeado para evitar conflito\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier\n",
        "import catboost\n",
        "from catboost import CatBoostClassifier, CatBoostRegressor\n",
        "\n",
        "# --- 7. Utilidades Diversas ---\n",
        "import requests\n",
        "\n",
        "# --- Configurações Finais ---\n",
        "\n",
        "print(\"Todas as bibliotecas carregadas com sucesso!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27f615f2",
      "metadata": {
        "id": "27f615f2"
      },
      "source": [
        "# Carregamento do Dataset Processado"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7518e5a",
      "metadata": {
        "id": "f7518e5a"
      },
      "source": [
        "Nesta etapa, vamos acessar o dataset processado diretamente do repositório versionado no **Dagshub/DVC**.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4694934b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221,
          "referenced_widgets": [
            "76355c4f832446b5aa9df0267d41ac4e",
            "51a2e8248c794ef789fa7511ee4e0d48",
            "9036a9a78fca4681940d2aacb603ac39",
            "4687d75d06ab4d1e84c5024bf006058f"
          ]
        },
        "id": "4694934b",
        "outputId": "d97a7907-5e61-425e-ee17-142f5c3c11bf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as estrellacouto05\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Accessing as estrellacouto05\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8e20a3e9a7744b9b6da166edf34b777",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>datapoint_id</th>\n",
              "      <th>dagshub_download_url</th>\n",
              "      <th>media type</th>\n",
              "      <th>size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>credit_score_processed.csv</td>\n",
              "      <td>103598542</td>\n",
              "      <td>https://dagshub.com/api/v1/repos/estrellacouto...</td>\n",
              "      <td>text/plain</td>\n",
              "      <td>32908761</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         path  datapoint_id  \\\n",
              "0  credit_score_processed.csv     103598542   \n",
              "\n",
              "                                dagshub_download_url  media type      size  \n",
              "0  https://dagshub.com/api/v1/repos/estrellacouto...  text/plain  32908761  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Carrega o dataset processado via Dagshub Data Engine\n",
        "ds = datasources.get('estrellacouto05/quantum-finance-credit-score', 'processed')\n",
        "\n",
        "# Exibe as primeiras linhas para verificação\n",
        "ds.all().dataframe\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "347c112d",
      "metadata": {
        "id": "347c112d"
      },
      "source": [
        "Após obter o objeto `datasource`, agora vamos recuperar o link de download do dataset versionado.   \n",
        "Com essa URL, carregamos os dados diretamente em um **DataFrame Pandas**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a86aafd9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9de5be7324e8430fba6952fd2d7c3438",
            "c373c6608ef64c55a98a97ee3df8a530"
          ]
        },
        "id": "a86aafd9",
        "outputId": "1a99524c-4ca4-4d02-a636-90d7d16e340f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51c06e31ee8346ae8e0c13e4e6044e42",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://dagshub.com/api/v1/repos/estrellacouto05/quantum-finance-credit-score/raw/main/data/processed/credit_score_processed.csv\n",
            "DataFrame carregado com sucesso!\n",
            "   idade  renda_anual  salario_liquido_mensal  qtd_contas_bancarias  \\\n",
            "0   23.0     19114.12             1824.843333                   3.0   \n",
            "1   23.0     19114.12             3335.886667                   3.0   \n",
            "2   35.0     19114.12             3335.886667                   3.0   \n",
            "3   23.0     19114.12             3335.886667                   3.0   \n",
            "4   23.0     19114.12             1824.843333                   3.0   \n",
            "\n",
            "   qtd_cartoes_credito  taxa_juros  qtd_emprestimos  dias_atraso_pagamento  \\\n",
            "0                    4         3.0              4.0                      3   \n",
            "1                    4         3.0              4.0                      1   \n",
            "2                    4         3.0              4.0                      3   \n",
            "3                    4         3.0              4.0                      5   \n",
            "4                    4         3.0              4.0                      6   \n",
            "\n",
            "   qtd_pagamentos_atrasados  variacao_limite_credito  ...  \\\n",
            "0                       7.0                    11.27  ...   \n",
            "1                      12.0                    11.27  ...   \n",
            "2                       7.0                     9.40  ...   \n",
            "3                       4.0                     6.27  ...   \n",
            "4                      12.0                    11.27  ...   \n",
            "\n",
            "   tipos_emprestimos_Credit-Builder Loan  \\\n",
            "0                                  False   \n",
            "1                                  False   \n",
            "2                                  False   \n",
            "3                                  False   \n",
            "4                                  False   \n",
            "\n",
            "   tipos_emprestimos_Debt Consolidation Loan  \\\n",
            "0                                      False   \n",
            "1                                      False   \n",
            "2                                      False   \n",
            "3                                      False   \n",
            "4                                      False   \n",
            "\n",
            "   tipos_emprestimos_Home Equity Loan  tipos_emprestimos_Mortgage Loan  \\\n",
            "0                               False                            False   \n",
            "1                               False                            False   \n",
            "2                               False                            False   \n",
            "3                               False                            False   \n",
            "4                               False                            False   \n",
            "\n",
            "   tipos_emprestimos_Not Specified  tipos_emprestimos_Payday Loan  \\\n",
            "0                            False                          False   \n",
            "1                            False                          False   \n",
            "2                            False                          False   \n",
            "3                            False                          False   \n",
            "4                            False                          False   \n",
            "\n",
            "   tipos_emprestimos_Personal Loan  tipos_emprestimos_Student Loan  \\\n",
            "0                            False                           False   \n",
            "1                            False                           False   \n",
            "2                            False                           False   \n",
            "3                            False                           False   \n",
            "4                            False                           False   \n",
            "\n",
            "   tipos_emprestimos_Two or More Types of Loan  score_credito  \n",
            "0                                         True              2  \n",
            "1                                         True              2  \n",
            "2                                         True              2  \n",
            "3                                         True              2  \n",
            "4                                         True              2  \n",
            "\n",
            "[5 rows x 49 columns]\n"
          ]
        }
      ],
      "source": [
        "# Obtém os primeiros registros do datasource e extrai o URL de download\n",
        "res = ds.head()\n",
        "\n",
        "for dp in res:\n",
        "    dataset_url = dp.download_url\n",
        "    print(\"Dataset URL:\", dataset_url)\n",
        "\n",
        "# Carrega variáveis de ambiente do arquivo .env\n",
        "load_dotenv(find_dotenv())\n",
        "\n",
        "dagshub_token = os.getenv(\"dagshub_token\")\n",
        "# Cria o cabeçalho de autenticação para a requisição\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {dagshub_token}\"\n",
        "}\n",
        "\n",
        "try:\n",
        "    # Faz a requisição GET para a URL do dataset, enviando o token no cabeçalho\n",
        "    response = requests.get(dataset_url, headers=headers)\n",
        "\n",
        "    # Verifica se a requisição foi bem-sucedida (código 200 OK)\n",
        "    response.raise_for_status()  # Isso vai gerar um erro se o download falhar (ex: token inválido, URL errada)\n",
        "\n",
        "    # O 'response.content' contém os dados brutos do arquivo CSV.\n",
        "    # Usamos 'io.StringIO' para que o pandas possa ler esses dados como se fossem um arquivo.\n",
        "    # O 'decode('utf-8')' converte os bytes para uma string.\n",
        "    csv_content = response.content.decode('utf-8')\n",
        "\n",
        "    # Carrega o conteúdo do CSV em um DataFrame do pandas\n",
        "    df = pd.read_csv(io.StringIO(csv_content))\n",
        "\n",
        "    # Exibe as primeiras linhas para verificação\n",
        "    print(\"DataFrame carregado com sucesso!\")\n",
        "    print(df.head())\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Ocorreu um erro ao tentar baixar o arquivo: {e}\")\n",
        "    print(\"Por favor, verifique se a URL de download e o token de acesso estão corretos.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Ocorreu um erro inesperado: {e}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ac53ac9",
      "metadata": {
        "id": "6ac53ac9"
      },
      "source": [
        "# Desenvolvimento e experimentos de modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0c9bf90",
      "metadata": {
        "id": "a0c9bf90"
      },
      "source": [
        "## Inicialização do Dagshub com MLflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "eb25c349",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "eb25c349",
        "outputId": "96312695-10d2-4c52-f9d3-aca98e6cb735"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"estrellacouto05/quantum-finance-credit-score\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Initialized MLflow to track repo \u001b[32m\"estrellacouto05/quantum-finance-credit-score\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository estrellacouto05/quantum-finance-credit-score initialized!\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Repository estrellacouto05/quantum-finance-credit-score initialized!\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dagshub inicializado e MLflow configurado.\n"
          ]
        }
      ],
      "source": [
        "# Inicializa o Dagshub com integração ao MLflow\n",
        "dagshub.init(repo_owner='estrellacouto05',\n",
        "             repo_name='quantum-finance-credit-score',\n",
        "             mlflow=True)\n",
        "\n",
        "print(\"Dagshub inicializado e MLflow configurado.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c0ae4d3f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0ae4d3f",
        "outputId": "c39c3c86-2d89-422b-f4c0-559ec75d5ddf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/14 21:53:52 INFO mlflow.tracking.fluent: Autologging successfully enabled for lightgbm.\n",
            "2025/09/14 21:53:54 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
            "2025/09/14 21:53:54 INFO mlflow.tracking.fluent: Autologging successfully enabled for xgboost.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLflow Autolog habilitado.\n"
          ]
        }
      ],
      "source": [
        "# Ativa o registro automático de experimentos com MLflow\n",
        "mlflow.autolog()\n",
        "\n",
        "print(\"MLflow Autolog habilitado.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88414c05",
      "metadata": {
        "id": "88414c05"
      },
      "source": [
        "## Separação de Features e Target\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f572696",
      "metadata": {
        "id": "6f572696"
      },
      "source": [
        "Nesta etapa, vamos separar as variáveis independentes (features) do target (`score_credito`).  \n",
        "Isso organiza o dataset para os modelos de Machine Learning, que aprenderão a prever o target com base nas features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "82edcf5a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82edcf5a",
        "outputId": "ec80770f-8ecf-4474-d638-bb5e2734ed2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de features: 48\n"
          ]
        }
      ],
      "source": [
        "# Lista todas as colunas e remove o target 'score_credito' da lista de features\n",
        "features = list(df.columns)\n",
        "features.remove(\"score_credito\")\n",
        "\n",
        "# Exibe o total de features selecionadas\n",
        "print(f\"Total de features: {len(features)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "c06c1784",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c06c1784",
        "outputId": "1689086f-5664-4b42-d708-f34946c0a56c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensões de X: (100000, 48)\n",
            "Dimensões de y: (100000,)\n"
          ]
        }
      ],
      "source": [
        "# Cria os DataFrames para features (X) e target (y)\n",
        "X = df[features]\n",
        "y = df[\"score_credito\"]\n",
        "\n",
        "# Exibe informações básicas para conferência\n",
        "print(\"Dimensões de X:\", X.shape)\n",
        "print(\"Dimensões de y:\", y.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15a6cb89",
      "metadata": {
        "id": "15a6cb89"
      },
      "source": [
        "## Divisão dos Dados e Escalonamento"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74b75f8d",
      "metadata": {
        "id": "74b75f8d"
      },
      "source": [
        "Nesta etapa, dividimos os dados em conjuntos de treino e teste para avaliar o desempenho dos modelos de forma justa.  \n",
        "Utilizamos **70% para treino** e **30% para teste**.\n",
        "\n",
        "Depois aplicamos o **RobustScaler**, que é ideal para dados com outliers, pois utiliza medianas e intervalos interquartis, evitando distorções.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e7e48371",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7e48371",
        "outputId": "5b4feabc-4e33-4fef-f185-99a271f7d038"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conjuntos criados:\n",
            "X_train: (70000, 48), X_test: (30000, 48)\n",
            "y_train: (70000,), y_test: (30000,)\n"
          ]
        }
      ],
      "source": [
        "# Divide os dados em treino (70%) e teste (30%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(\"Conjuntos criados:\")\n",
        "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
        "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "070c9592",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "070c9592",
        "outputId": "e0337b6d-a9ee-4d2e-f589-de8892e547b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Escalonamento concluído.\n",
            "Dimensões após escalonamento: (70000, 48) (30000, 48)\n"
          ]
        }
      ],
      "source": [
        "# Inicializa o RobustScaler\n",
        "scaler = RobustScaler()\n",
        "\n",
        "# Ajusta o scaler apenas com os dados de treino e transforma\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Aplica a mesma transformação nos dados de teste\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Escalonamento concluído.\")\n",
        "print(\"Dimensões após escalonamento:\", X_train_scaled.shape, X_test_scaled.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6bf9b202",
      "metadata": {
        "id": "6bf9b202"
      },
      "outputs": [],
      "source": [
        "X_train = X_train_scaled\n",
        "X_test = X_test_scaled"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbb42492",
      "metadata": {
        "id": "bbb42492"
      },
      "source": [
        "## Função de Avaliação e Log no MLflow (Classificação)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29f19e19",
      "metadata": {
        "id": "29f19e19"
      },
      "source": [
        "- **Métricas principais:** precision, recall e f1-score para cada classe.\n",
        "- **Destaque do recall da classe 0 (Poor)**, que é a mais importante.\n",
        "- **Matriz de confusão** gerada como gráfico e registrada no MLflow como artefato.\n",
        "- **Registro do modelo** no MLflow (CatBoost, XGBoost, LightGBM ou sklearn)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "526afc19",
      "metadata": {
        "id": "526afc19"
      },
      "outputs": [],
      "source": [
        "def evaluate_and_log_model(kind, model_name, model, X_test, y_test):\n",
        "    # Faz previsões\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    # Calcula métricas de classificação\n",
        "    training_accuracy_score_manual = model.score(X_train, y_train)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, predictions, labels=[0,1,2], zero_division=0)\n",
        "    report = classification_report(y_test, predictions, digits=3)\n",
        "\n",
        "    # Log de métricas macro (média das classes)\n",
        "    mlflow.log_metric(\"Precision_macro\", precision.mean())\n",
        "    mlflow.log_metric(\"Recall_macro\", recall.mean())\n",
        "    mlflow.log_metric(\"F1_macro\", f1.mean())\n",
        "\n",
        "    # Log da acurácia de treino\n",
        "    mlflow.log_metric(\"training_accuracy_score_manual\", training_accuracy_score_manual)\n",
        "\n",
        "\n",
        "    # Log detalhado de métricas por classe\n",
        "    mlflow.log_metric(\"Recall_class_0_Poor\", recall[0])\n",
        "    mlflow.log_metric(\"Precision_class_0_Poor\", precision[0])\n",
        "    mlflow.log_metric(\"F1_class_0_Poor\", f1[0])\n",
        "    mlflow.log_metric(\"Recall_class_1_Standard\", recall[1])\n",
        "    mlflow.log_metric(\"Recall_class_2_Good\", recall[2])\n",
        "\n",
        "    # Cria assinatura do modelo para salvar no MLflow\n",
        "    signature = infer_signature(X_test, predictions)\n",
        "\n",
        "    # Salva o modelo de acordo com o tipo\n",
        "    if kind == \"catboost\":\n",
        "        mlflow.catboost.log_model(model, model_name, signature=signature, input_example=X_test[:5])\n",
        "    elif kind == \"xgboost\":\n",
        "        mlflow.xgboost.log_model(model, model_name, signature=signature, input_example=X_test[:5])\n",
        "    elif kind == \"lightgbm\":\n",
        "        mlflow.lightgbm.log_model(model, model_name, signature=signature, input_example=X_test[:5])\n",
        "    else:\n",
        "        mlflow.sklearn.log_model(model, model_name, signature=signature, input_example=X_test[:5])\n",
        "\n",
        "    # Gera matriz de confusão\n",
        "    cm = confusion_matrix(y_test, predictions, labels=[0,1,2])\n",
        "    plt.figure(figsize=(6,4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Poor', 'Standard', 'Good'], yticklabels=['Poor', 'Standard', 'Good'])\n",
        "    plt.xlabel('Previsto')\n",
        "    plt.ylabel('Real')\n",
        "    plt.title(f'Matriz de Confusão - {model_name}')\n",
        "\n",
        "    # Salva a figura temporariamente e envia como artefato para o MLflow\n",
        "    with tempfile.TemporaryDirectory() as tmpdir:\n",
        "        cm_path = os.path.join(tmpdir, \"confusion_matrix.png\")\n",
        "        plt.savefig(cm_path)\n",
        "        plt.close()\n",
        "        mlflow.log_artifact(cm_path, artifact_path=\"confusion_matrix\")\n",
        "\n",
        "    # Print no console\n",
        "    print(f\"=== Avaliação do Modelo: {model_name} ===\")\n",
        "    print(report)\n",
        "    print(f\"Recall da classe 0 (Poor): {recall[0]:.3f}\")\n",
        "    print(f\"Acurácia de Treino: {training_accuracy_score_manual:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2998826d",
      "metadata": {
        "id": "2998826d"
      },
      "source": [
        "# Primeira Etapa de Treinamento de Modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2bd129a",
      "metadata": {
        "id": "d2bd129a"
      },
      "source": [
        "A partir deste ponto, iniciamos o ciclo de **treinamento de modelos com MLflow**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6108854d",
      "metadata": {
        "id": "6108854d"
      },
      "source": [
        "## XGBoost\n",
        "  \n",
        "Começamos com o **XGBoost Classifier**, um modelo de boosting altamente eficaz em dados tabulares.\n",
        "\n",
        "- Foi usado **RandomizedSearchCV** com 30 combinações aleatórias de hiperparâmetros.\n",
        "- Todas as métricas (precision, recall, f1-score) e a matriz de confusão foram registradas no MLflow.\n",
        "- Nosso foco principal é **maximizar o recall da classe 0 (Poor)**, já que é a categoria mais crítica para o projeto.\n",
        "\n",
        "Após avaliar o XGBoost, avançaremos para **LightGBM** e **CatBoost** para comparar os resultados.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c0fcd26",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "71ac518ccedf4d2fb102ebc2a5c1b336"
          ]
        },
        "id": "0c0fcd26",
        "outputId": "fca887fa-9625-4729-88cc-35c7114433d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n",
            "2025/08/03 22:02:56 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/get?run_uuid=f9ec195a72dd4afb9b91f99ef5f727b2&run_id=f9ec195a72dd4afb9b91f99ef5f727b2\n",
            "2025/08/03 22:13:25 INFO mlflow.sklearn.utils: Logging the 5 best runs, 25 runs will be omitted.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71ac518ccedf4d2fb102ebc2a5c1b336",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Avaliação do Modelo: XGBoost Classifier RandomSearch ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.767     0.727     0.747      8805\n",
            "           1      0.763     0.795     0.779     15873\n",
            "           2      0.669     0.642     0.655      5322\n",
            "\n",
            "    accuracy                          0.748     30000\n",
            "   macro avg      0.733     0.721     0.727     30000\n",
            "weighted avg      0.747     0.748     0.747     30000\n",
            "\n",
            "Recall da classe 0 (Poor): 0.727\n",
            "🏃 View run XGBoost_Classifier_RandomSearch at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/f9ec195a72dd4afb9b91f99ef5f727b2\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        }
      ],
      "source": [
        "with mlflow.start_run(run_name=\"XGBoost_Classifier_RandomSearch\"):\n",
        "\n",
        "    # Definindo a grade de hiperparâmetros ampliada\n",
        "    param_distributions = {\n",
        "        'n_estimators': [50, 100, 200, 300],\n",
        "        'max_depth': [3, 5, 7, 9],\n",
        "        'learning_rate': [0.01, 0.05, 0.1],\n",
        "        'subsample': [0.7, 0.8, 1.0],\n",
        "        'colsample_bytree': [0.7, 0.8, 1.0],\n",
        "        'min_child_weight': [1, 3, 5]\n",
        "    }\n",
        "\n",
        "    # Modelo base XGBoost\n",
        "    xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
        "\n",
        "    # RandomizedSearchCV para explorar combinações de hiperparâmetros\n",
        "    random_search = RandomizedSearchCV(\n",
        "        estimator=xgb,\n",
        "        param_distributions=param_distributions,\n",
        "        n_iter=30,                # número de combinações aleatórias a testar\n",
        "        scoring='recall_macro',   # métrica principal\n",
        "        cv=5,\n",
        "        n_jobs=-1,\n",
        "        verbose=1,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Treina com os dados escalonados\n",
        "    random_search.fit(X_train_scaled, y_train)\n",
        "    best_model = random_search.best_estimator_\n",
        "\n",
        "    # Log dos melhores parâmetros no MLflow\n",
        "    best_params = random_search.best_params_\n",
        "    for param, value in best_params.items():\n",
        "        mlflow.log_param(param, value)\n",
        "\n",
        "    # Avalia e registra o modelo\n",
        "    evaluate_and_log_model(\"xgboost\", \"XGBoost Classifier RandomSearch\", best_model, X_test_scaled, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a9660ef",
      "metadata": {
        "id": "4a9660ef"
      },
      "source": [
        "## LightGBM\n",
        "\n",
        "Agora vamos treinar o **LightGBM Classifier**, outro modelo de boosting eficiente e mais rápido que o XGBoost em muitos cenários.\n",
        "\n",
        "- Usaremos **RandomizedSearchCV** com 30 combinações, igual ao XGBoost, para manter o tempo de treino semelhante (~150 fits).\n",
        "- Vamos incluir parâmetros específicos do LightGBM, como **num_leaves**, que controla a complexidade das árvores.\n",
        "- Métrica de busca: **recall_macro**, priorizando melhor cobertura da classe “Poor”.\n",
        "- Tudo será registrado no **MLflow** para comparação posterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f00089af",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "4c1d453ad82f4afa9b495f2969e52775"
          ]
        },
        "id": "f00089af",
        "outputId": "4aa9ad29-de22-46da-c314-f6265152335b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n",
            "2025/08/03 22:21:43 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010766 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2708\n",
            "[LightGBM] [Info] Number of data points in the train set: 70000, number of used features: 48\n",
            "[LightGBM] [Info] Start training from score -1.243159\n",
            "[LightGBM] [Info] Start training from score -0.629475\n",
            "[LightGBM] [Info] Start training from score -1.722287\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/get?run_uuid=eaf41b22355a40d9a6a6b939818b364d&run_id=eaf41b22355a40d9a6a6b939818b364d\n",
            "2025/08/03 22:30:14 INFO mlflow.sklearn.utils: Logging the 5 best runs, 25 runs will be omitted.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c1d453ad82f4afa9b495f2969e52775",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Avaliação do Modelo: LightGBM Classifier RandomSearch ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.781     0.778     0.779      8805\n",
            "           1      0.788     0.810     0.799     15873\n",
            "           2      0.748     0.692     0.719      5322\n",
            "\n",
            "    accuracy                          0.780     30000\n",
            "   macro avg      0.773     0.760     0.766     30000\n",
            "weighted avg      0.779     0.780     0.779     30000\n",
            "\n",
            "Recall da classe 0 (Poor): 0.778\n",
            "🏃 View run LightGBM_Classifier_RandomSearch at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/eaf41b22355a40d9a6a6b939818b364d\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        }
      ],
      "source": [
        "with mlflow.start_run(run_name=\"LightGBM_Classifier_RandomSearch\"):\n",
        "\n",
        "    # Definição do espaço de busca\n",
        "    param_distributions = {\n",
        "        'n_estimators': [50, 100, 200, 300],\n",
        "        'max_depth': [3, 5, 7, 9, -1],  # -1 = sem limite de profundidade\n",
        "        'learning_rate': [0.01, 0.05, 0.1],\n",
        "        'num_leaves': [15, 31, 63, 127],\n",
        "        'subsample': [0.7, 0.8, 1.0],\n",
        "        'colsample_bytree': [0.7, 0.8, 1.0]\n",
        "    }\n",
        "\n",
        "    # Modelo base LightGBM\n",
        "    lgb = LGBMClassifier(objective='multiclass', num_class=3, random_state=42)\n",
        "\n",
        "    # RandomizedSearchCV – 30 combinações x 5 folds = 150 fits\n",
        "    random_search = RandomizedSearchCV(\n",
        "        estimator=lgb,\n",
        "        param_distributions=param_distributions,\n",
        "        n_iter=30,\n",
        "        scoring='recall_macro',\n",
        "        cv=5,\n",
        "        n_jobs=-1,\n",
        "        verbose=1,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Treina o modelo\n",
        "    random_search.fit(X_train_scaled, y_train)\n",
        "    best_model = random_search.best_estimator_\n",
        "\n",
        "    # Log dos melhores hiperparâmetros\n",
        "    best_params = random_search.best_params_\n",
        "    for param, value in best_params.items():\n",
        "        mlflow.log_param(param, value)\n",
        "\n",
        "    # Avalia e registra o modelo no MLflow\n",
        "    evaluate_and_log_model(\"lightgbm\", \"LightGBM Classifier RandomSearch\", best_model, X_test_scaled, y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5020f6bb",
      "metadata": {
        "id": "5020f6bb"
      },
      "source": [
        "Melhor foi light gbm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a75df856",
      "metadata": {
        "id": "a75df856"
      },
      "source": [
        "##  Random Forest Classifier\n",
        "\n",
        "Neste experimento, aplicamos o modelo `RandomForestClassifier` para classificação dos scores de crédito, utilizando `RandomizedSearchCV` com validação cruzada (CV=5) para otimização de hiperparâmetros.\n",
        "\n",
        "A escolha pelo `Random Forest` visa avaliar o desempenho de um modelo de ensemble tradicional, mais interpretável, como alternativa aos métodos baseados em Gradient Boosting (XGBoost e LightGBM).\n",
        "\n",
        "**Configurações do experimento:**\n",
        "- 50 combinações testadas com `RandomizedSearchCV` (`n_iter=50`)\n",
        "- Métrica de avaliação principal: `recall_macro`\n",
        "- Hiperparâmetros otimizados: número de estimadores, profundidade máxima (com limite para evitar overfitting), amostragem mínima para splits e folhas, tipo de critério, entre outros.\n",
        "- Avaliação com função customizada `evaluate_and_log_model`, registrando métricas detalhadas (precision, recall, f1-score, matriz de confusão), com foco no `recall` da classe 0 (`Poor`), além de logging via MLflow.\n",
        "\n",
        "O objetivo é verificar se o Random Forest entrega resultados competitivos e interpretar seu comportamento em comparação com os modelos anteriores.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd5cf818",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "f2bbc7a22b714cff8107277ca8c0efdd"
          ]
        },
        "id": "fd5cf818",
        "outputId": "c29651b8-a094-4aff-c5d5-e043ea22aab0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/08/05 11:25:15 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/08/05 12:00:24 INFO mlflow.sklearn.utils: Logging the 5 best runs, 45 runs will be omitted.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏃 View run auspicious-deer-16 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/702b80c4c87b4456a148eb28e2e1b791\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run monumental-ox-450 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/83a8a9a3b726467fa8b2980745aa22ca\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run grandiose-zebra-368 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/8f247204dc2d4f8a9a0ff3d2547aa025\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run burly-ape-995 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/e8bf5ee20de9424099f1d17821de5018\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run righteous-stoat-49 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/c98f0a60ff924f9fa4707f227671ffaf\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2bbc7a22b714cff8107277ca8c0efdd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Avaliação do Modelo: RandomForest Classifier RandomSearch ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.780     0.754     0.767      8805\n",
            "           1      0.778     0.807     0.793     15873\n",
            "           2      0.713     0.673     0.693      5322\n",
            "\n",
            "    accuracy                          0.768     30000\n",
            "   macro avg      0.757     0.745     0.751     30000\n",
            "weighted avg      0.767     0.768     0.767     30000\n",
            "\n",
            "Recall da classe 0 (Poor): 0.754\n",
            "🏃 View run RandomForest_Classifier_RandomSearch at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/df711845800e452aa800d9578ce58457\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏃 View run enchanting-shad-321 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/1ab7344499f74817a85e876013514d9f\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run serious-asp-250 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/c796d96f67054d22871e19825ce2175d\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run invincible-rook-21 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/22ef267fe2ca4032a2ddcce5d44abc9a\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run angry-asp-955 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/7d9fc16a65f342b798a7e2299bdbfabd\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run dashing-shrew-945 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/b72584f964e14e39a893f66197905e5c\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run gregarious-fish-885 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/8c777e711e93437388df358575141221\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/log-batch\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏃 View run worried-steed-201 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/09b6d6b37e724f3a8a1da73fa71fc074\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run chill-mare-104 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/1ff41165c2554efe88c2927706ff5571\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run chill-smelt-845 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/e221b0dce6884322ad9a016113666026\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run big-asp-866 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/7bead2d39d444bf188e4735a0c8630a6\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        }
      ],
      "source": [
        "# Início do experimento com MLflow\n",
        "with mlflow.start_run(run_name=\"RandomForest_Classifier_RandomSearch\"):\n",
        "\n",
        "    # Instancia o modelo base\n",
        "    rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "    # Espaço de busca ajustado (sem max_depth=None para evitar overfitting)\n",
        "    param_distributions = {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [5, 10, 15, 20],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4],\n",
        "        'max_features': ['auto', 'sqrt', 'log2'],\n",
        "        'bootstrap': [True, False],\n",
        "        'criterion': ['gini', 'entropy']\n",
        "    }\n",
        "\n",
        "    # RandomizedSearchCV com 50 combinações\n",
        "    random_search = RandomizedSearchCV(\n",
        "        estimator=rf,\n",
        "        param_distributions=param_distributions,\n",
        "        n_iter=50,\n",
        "        scoring='recall_macro',\n",
        "        cv=5,\n",
        "        n_jobs=-1,\n",
        "        verbose=1,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Treinamento\n",
        "    random_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Modelo final\n",
        "    best_model = random_search.best_estimator_\n",
        "\n",
        "    # Log dos melhores hiperparâmetros\n",
        "    best_params = random_search.best_params_\n",
        "    for param, value in best_params.items():\n",
        "        mlflow.log_param(param, value)\n",
        "\n",
        "    # Avaliação + log via função customizada\n",
        "    evaluate_and_log_model(\"sklearn\", \"RandomForest Classifier RandomSearch\", best_model, X_test_scaled, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79cdd708",
      "metadata": {},
      "source": [
        "## Ultima"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "70cb9698",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n",
            "2025/09/15 12:19:59 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028578 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2708\n",
            "[LightGBM] [Info] Number of data points in the train set: 70000, number of used features: 48\n",
            "[LightGBM] [Info] Start training from score -1.243159\n",
            "[LightGBM] [Info] Start training from score -0.629475\n",
            "[LightGBM] [Info] Start training from score -1.722287\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/get?run_uuid=d4082405211c46c5af186ef93c1a4bcf&run_id=d4082405211c46c5af186ef93c1a4bcf\n",
            "2025/09/15 12:39:26 INFO mlflow.sklearn.utils: Logging the 5 best runs, 25 runs will be omitted.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏃 View run gifted-elk-275 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/d4bf9908c90543ee90ff5f9ab41beeaf\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏃 View run gregarious-koi-312 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/943be36eb3e24db296d97cabe8962645\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "\n",
            "Melhores Hiperparâmetros Encontrados:\n",
            "{'subsample': 0.9, 'reg_lambda': 0.5, 'reg_alpha': 0.1, 'num_leaves': 55, 'n_estimators': 400, 'min_child_samples': 60, 'max_depth': 10, 'learning_rate': 0.05, 'colsample_bytree': 0.7}\n",
            "\n",
            "Melhor score de CV (recall_macro): 0.7227\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1dd2a29837b4aad9e67d40bde45a5ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Avaliação do Modelo: LGBM Classifier RandomSearch LowCost ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.764     0.721     0.742      8805\n",
            "           1      0.760     0.799     0.779     15873\n",
            "           2      0.692     0.652     0.672      5322\n",
            "\n",
            "    accuracy                          0.750     30000\n",
            "   macro avg      0.739     0.724     0.731     30000\n",
            "weighted avg      0.749     0.750     0.749     30000\n",
            "\n",
            "Recall da classe 0 (Poor): 0.721\n",
            "Acurácia de Treino: 0.829\n",
            "🏃 View run LGBM_Classifier_RandomSearch_LowCost at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/d4082405211c46c5af186ef93c1a4bcf\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/log-inputs\n"
          ]
        }
      ],
      "source": [
        "# Início do experimento com MLflow\n",
        "with mlflow.start_run(run_name=\"LGBM_Classifier_RandomSearch_LowCost\"):\n",
        "\n",
        "    # Instancia o modelo base com configurações fixas\n",
        "    lgbm = LGBMClassifier(\n",
        "        objective='multiclass',\n",
        "        num_class=3,          # Ajuste se o número de classes for diferente\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    # Espaço de busca mais enxuto e direcionado para 30 iterações\n",
        "    param_distributions = {\n",
        "        # 1. Controle de Complexidade (Parâmetros de maior impacto)\n",
        "        'num_leaves': [25, 31, 45, 55],\n",
        "        'max_depth': [6, 8, 10, 12],\n",
        "\n",
        "        # 2. Regularização (Valores discretos e impactantes)\n",
        "        'reg_alpha': [0.1, 0.5, 1.0, 1.5],\n",
        "        'reg_lambda': [0.1, 0.5, 1.0, 1.5],\n",
        "        'min_child_samples': [20, 40, 60],\n",
        "\n",
        "        # 3. Aleatoriedade (Valores comuns e eficazes)\n",
        "        'subsample': [0.7, 0.8, 0.9],\n",
        "        'colsample_bytree': [0.7, 0.8, 0.9],\n",
        "\n",
        "        # 4. Processo de Treinamento (Valores fixos para simplificar a busca)\n",
        "        'learning_rate': [0.05], # Fixo em um valor bom e seguro\n",
        "        'n_estimators': [400]    # Fixo em um valor razoável (use com Early Stopping se possível)\n",
        "    }\n",
        "\n",
        "    # RandomizedSearchCV com no máximo 30 combinações\n",
        "    random_search = RandomizedSearchCV(\n",
        "        estimator=lgbm,\n",
        "        param_distributions=param_distributions,\n",
        "        n_iter=30,  # <<< Limite de 30 treinos, como solicitado\n",
        "        scoring='recall_macro',\n",
        "        cv=5,\n",
        "        n_jobs=-1,\n",
        "        verbose=1,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Treinamento\n",
        "    # Para otimizar ainda mais, considere adicionar um callback de Early Stopping aqui, se seu\n",
        "    # ambiente permitir (ex: passando eval_set e callbacks para o .fit()).\n",
        "    random_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Modelo final com os melhores parâmetros\n",
        "    best_model = random_search.best_estimator_\n",
        "\n",
        "    # Log dos melhores hiperparâmetros no MLflow\n",
        "    best_params = random_search.best_params_\n",
        "    mlflow.log_params(best_params)\n",
        "    mlflow.log_metric(\"best_cv_score\", random_search.best_score_)\n",
        "\n",
        "    print(\"\\nMelhores Hiperparâmetros Encontrados:\")\n",
        "    print(best_params)\n",
        "    print(f\"\\nMelhor score de CV (recall_macro): {random_search.best_score_:.4f}\")\n",
        "\n",
        "    # Avaliação do modelo final no conjunto de teste e log no MLflow\n",
        "    evaluate_and_log_model(\"lightgbm\", \"LGBM Classifier RandomSearch LowCost\", best_model, X_test_scaled, y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "207244af",
      "metadata": {
        "id": "207244af"
      },
      "source": [
        "## Fine-Tuning do LightGBM com RandomizedSearchCV\n",
        "\n",
        "Nesta etapa, realizamos um ajuste fino (fine-tuning) no modelo LightGBM com foco em melhorar o **recall da classe 0 (Poor)**.  \n",
        "Baseado nos melhores parâmetros anteriores, restringimos os ranges de busca para explorar variações próximas e mais promissoras.  \n",
        "Usamos `RandomizedSearchCV` com `n_iter=50` e validação cruzada (`cv=5`), mantendo o controle de overfitting por meio de `num_leaves`, `subsample` e `colsample_bytree`.  \n",
        "Os resultados serão registrados automaticamente no MLflow via integração com o Dagshub.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "113812f7",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "963d3bc2bfc24245a19292ce5225ba0f"
          ]
        },
        "id": "113812f7",
        "outputId": "53e9c8b8-edaa-4fb8-ae06-ba09499d333d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n",
            "2025/08/05 12:35:54 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008393 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2708\n",
            "[LightGBM] [Info] Number of data points in the train set: 70000, number of used features: 48\n",
            "[LightGBM] [Info] Start training from score -1.243159\n",
            "[LightGBM] [Info] Start training from score -0.629475\n",
            "[LightGBM] [Info] Start training from score -1.722287\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/08/05 13:25:15 INFO mlflow.sklearn.utils: Logging the 5 best runs, 45 runs will be omitted.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "963d3bc2bfc24245a19292ce5225ba0f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Avaliação do Modelo: LightGBM FineTuned ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.785     0.786     0.785      8805\n",
            "           1      0.793     0.812     0.803     15873\n",
            "           2      0.755     0.701     0.727      5322\n",
            "\n",
            "    accuracy                          0.784     30000\n",
            "   macro avg      0.778     0.766     0.772     30000\n",
            "weighted avg      0.784     0.784     0.784     30000\n",
            "\n",
            "Recall da classe 0 (Poor): 0.786\n",
            "🏃 View run LightGBM_FineTuning at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/05cfe5fa3fa544bbba01799cb7f7b903\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        }
      ],
      "source": [
        "with mlflow.start_run(run_name=\"LightGBM_FineTuning\"):\n",
        "\n",
        "    model = LGBMClassifier(objective='multiclass', num_class=3, random_state=42)\n",
        "\n",
        "    param_distributions = {\n",
        "        'n_estimators': [300, 400, 500],\n",
        "        'learning_rate': [0.05, 0.08, 0.1],\n",
        "        'num_leaves': [95, 127, 150],\n",
        "        'max_depth': [5, 7, 9, -1],\n",
        "        'subsample': [0.6, 0.7, 0.8],\n",
        "        'colsample_bytree': [0.7, 0.85, 1.0]\n",
        "    }\n",
        "\n",
        "    randomized_search = RandomizedSearchCV(\n",
        "        estimator=model,\n",
        "        param_distributions=param_distributions,\n",
        "        n_iter=50,\n",
        "        scoring='recall_macro',\n",
        "        cv=5,\n",
        "        random_state=42,\n",
        "        verbose=1,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    randomized_search.fit(X_train_scaled, y_train)\n",
        "    best_model = randomized_search.best_estimator_\n",
        "\n",
        "    # Loga os melhores hiperparâmetros\n",
        "    mlflow.log_params(randomized_search.best_params_)\n",
        "\n",
        "    # Avalia e registra o modelo no MLflow\n",
        "    evaluate_and_log_model(\"lightgbm\", \"LightGBM FineTuned\", best_model, X_test_scaled, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c50aa013",
      "metadata": {
        "id": "c50aa013"
      },
      "source": [
        "### Fine-tuning adicional no LightGBM com foco em `n_estimators` e `learning_rate`\n",
        "\n",
        "Neste experimento, mantemos os melhores hiperparâmetros encontrados anteriormente (como `num_leaves`, `max_depth`, `subsample` e `colsample_bytree`) e realizamos um ajuste fino especificamente sobre os parâmetros `n_estimators` e `learning_rate`.\n",
        "\n",
        "O objetivo é verificar se o aumento do número de estimadores (de 500 para 750 e 1000) combinado com taxas de aprendizado mais baixas (0.05, 0.03 e 0.01) resulta em ganho de recall, principalmente da classe 0 (Poor), sem causar overfitting.\n",
        "\n",
        "A técnica continua sendo o `RandomizedSearchCV` com 50 iterações e validação cruzada (cv=5), mantendo o padrão adotado em experimentos anteriores.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "634194e7",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "bb49062cbf5e48e3a7555429db218321"
          ]
        },
        "id": "634194e7",
        "outputId": "7d176820-5ec1-4ad0-bfcd-75c0eccf5b2a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n",
            "2025/08/05 13:57:07 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024234 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2708\n",
            "[LightGBM] [Info] Number of data points in the train set: 70000, number of used features: 48\n",
            "[LightGBM] [Info] Start training from score -1.243159\n",
            "[LightGBM] [Info] Start training from score -0.629475\n",
            "[LightGBM] [Info] Start training from score -1.722287\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/get?run_uuid=eb3c5dfe89f44412971d50969d0c882f&run_id=eb3c5dfe89f44412971d50969d0c882f\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow-artifacts/artifacts/1bcdc4fa750b418bacafd99dfb9f17bf/eb3c5dfe89f44412971d50969d0c882f/artifacts/estimator.html\n",
            "2025/08/05 14:20:52 INFO mlflow.sklearn.utils: Logging the 5 best runs, 4 runs will be omitted.\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/log-metric\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb49062cbf5e48e3a7555429db218321",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Avaliação do Modelo: LightGBM Estimators-LR Tuning ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.785     0.789     0.787      8805\n",
            "           1      0.794     0.812     0.803     15873\n",
            "           2      0.759     0.701     0.729      5322\n",
            "\n",
            "    accuracy                          0.786     30000\n",
            "   macro avg      0.779     0.767     0.773     30000\n",
            "weighted avg      0.785     0.786     0.785     30000\n",
            "\n",
            "Recall da classe 0 (Poor): 0.789\n",
            "🏃 View run LightGBM_Estimators_LearningRate_Tuning at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/eb3c5dfe89f44412971d50969d0c882f\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        }
      ],
      "source": [
        "with mlflow.start_run(run_name=\"LightGBM_Estimators_LearningRate_Tuning\"):\n",
        "\n",
        "    model = LGBMClassifier(objective='multiclass', num_class=3, random_state=42)\n",
        "\n",
        "    param_distributions = {\n",
        "        'n_estimators': [500, 750, 1000],\n",
        "        'learning_rate': [0.05, 0.03, 0.01],\n",
        "        'num_leaves': [127],\n",
        "        'max_depth': [-1],\n",
        "        'subsample': [0.7],\n",
        "        'colsample_bytree': [1.0]\n",
        "    }\n",
        "\n",
        "    randomized_search = RandomizedSearchCV(\n",
        "        estimator=model,\n",
        "        param_distributions=param_distributions,\n",
        "        n_iter=50,\n",
        "        scoring='recall_macro',\n",
        "        cv=5,\n",
        "        random_state=42,\n",
        "        verbose=1,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    randomized_search.fit(X_train_scaled, y_train)\n",
        "    best_model = randomized_search.best_estimator_\n",
        "\n",
        "    # Log dos principais hiperparâmetros selecionados\n",
        "    mlflow.log_param(\"best_n_estimators\", best_model.n_estimators)\n",
        "    mlflow.log_param(\"best_learning_rate\", best_model.learning_rate)\n",
        "\n",
        "    # Avaliação e log do modelo\n",
        "    evaluate_and_log_model(\"lightgbm\", \"LightGBM Estimators-LR Tuning\", best_model, X_test_scaled, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1009ae78",
      "metadata": {
        "id": "1009ae78"
      },
      "source": [
        "###  Escolha final do modelo LightGBM (Fine-Tuning)\n",
        "\n",
        "Após dois ciclos de fine-tuning com o LightGBM, foram comparadas duas configurações principais:\n",
        "\n",
        "| Modelo | `n_estimators` | `learning_rate` | Recall Classe 0 (Poor) |\n",
        "|--------|----------------|------------------|--------------------------|\n",
        "| A (1º Fine-tune) | **500** | **0.1** | **0.786** |\n",
        "| B (2º Fine-tune) | **1000** | **0.05** | **0.789** |\n",
        "\n",
        "Apesar do modelo B utilizar o dobro de árvores com um `learning_rate` mais baixo (0.05), **a melhora no recall da classe 0 foi mínima** (de 0.786 para 0.789), sem ganho significativo em outras métricas. Além disso, esse aumento nos estimadores **eleva o custo computacional e o risco de overfitting** sem retorno proporcional em desempenho.\n",
        "\n",
        "####  Conclusão:\n",
        "Optamos por manter o modelo com:\n",
        "- `n_estimators = 500`\n",
        "- `learning_rate = 0.1`\n",
        "\n",
        "Essa combinação mostrou-se mais eficiente, com ótimo desempenho geral, menor complexidade e melhor equilíbrio entre performance e custo de treinamento.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f24ab6c",
      "metadata": {
        "id": "9f24ab6c"
      },
      "source": [
        "## CatBoost\n",
        "\n",
        "Agora vamos treinar o **CatBoost Classifier**, um modelo de boosting desenvolvido pela Yandex com excelente desempenho em bases com variáveis categóricas e estrutura mista (numéricas + booleanas).\n",
        "\n",
        "- Usaremos o **RandomizedSearchCV** com 30 combinações, mantendo o padrão de experimentação adotado nos modelos anteriores.\n",
        "- Serão explorados hiperparâmetros como **depth**, **learning_rate**, **l2_leaf_reg** e **border_count**.\n",
        "- A métrica de otimização interna será **TotalF1**, adequada para tarefas multiclasse, enquanto a métrica de avaliação externa continua sendo o **recall_macro**.\n",
        "- Toda a execução será rastreada e registrada no **MLflow**, com foco na classe “Poor” e comparação direta com os demais modelos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97bba751",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "24b0cb0b03194543ace098b8fc4496b1"
          ]
        },
        "id": "97bba751",
        "outputId": "5a689999-96d1-457c-de55-5923fba0caf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/get?run_uuid=56d42725396f4f47b84222b54a4b5b1e&run_id=56d42725396f4f47b84222b54a4b5b1e\n",
            "2025/08/05 18:17:53 INFO mlflow.sklearn.utils: Logging the 5 best runs, 25 runs will be omitted.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏃 View run trusting-stoat-841 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/65d6e49d1b96461b845982489c694680\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run victorious-skunk-835 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/59239c09c853459c9889f22835e8195e\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run receptive-yak-708 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/ed4a8cce2fdf46fcb168768bb4ff358e\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run adaptable-finch-354 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/3738e2e53f624e8d9df1a46d6e113ddb\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run bold-bass-164 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/1b6257e9c65e400eb6f22be375162f1b\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24b0cb0b03194543ace098b8fc4496b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Avaliação do Modelo: CatBoost FineTuned ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.771     0.743     0.756      8805\n",
            "           1      0.766     0.808     0.786     15873\n",
            "           2      0.719     0.644     0.680      5322\n",
            "\n",
            "    accuracy                          0.760     30000\n",
            "   macro avg      0.752     0.732     0.741     30000\n",
            "weighted avg      0.759     0.760     0.759     30000\n",
            "\n",
            "Recall da classe 0 (Poor): 0.743\n",
            "🏃 View run CatBoost_FineTuning at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/56d42725396f4f47b84222b54a4b5b1e\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        }
      ],
      "source": [
        "catboost_temp_dir = mkdtemp()\n",
        "\n",
        "with mlflow.start_run(run_name=\"CatBoost_FineTuning\"):\n",
        "\n",
        "    model = CatBoostClassifier(\n",
        "        loss_function='MultiClass',\n",
        "        eval_metric='TotalF1',  #  métrica escalar compatível\n",
        "        verbose=0,\n",
        "        train_dir=catboost_temp_dir,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    param_distributions = {\n",
        "        'iterations': [300, 500, 750],\n",
        "        'learning_rate': [0.01, 0.05, 0.1],\n",
        "        'depth': [4, 6, 8, 10],\n",
        "        'l2_leaf_reg': [1, 3, 5, 7],\n",
        "        'border_count': [32, 64, 128]\n",
        "    }\n",
        "\n",
        "    randomized_search = RandomizedSearchCV(\n",
        "        estimator=model,\n",
        "        param_distributions=param_distributions,\n",
        "        n_iter=30,\n",
        "        scoring='recall_macro',  # usado para selecionar o melhor modelo\n",
        "        cv=5,\n",
        "        verbose=1,\n",
        "        n_jobs=1,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    randomized_search.fit(X_train, y_train)\n",
        "\n",
        "    best_model = randomized_search.best_estimator_\n",
        "\n",
        "    # Log dos hiperparâmetros\n",
        "    mlflow.log_param(\"best_iterations\", best_model.get_params()[\"iterations\"])\n",
        "    mlflow.log_param(\"best_learning_rate\", best_model.get_params()[\"learning_rate\"])\n",
        "    mlflow.log_param(\"best_depth\", best_model.get_params()[\"depth\"])\n",
        "    mlflow.log_param(\"best_l2_leaf_reg\", best_model.get_params()[\"l2_leaf_reg\"])\n",
        "    mlflow.log_param(\"best_border_count\", best_model.get_params()[\"border_count\"])\n",
        "\n",
        "    # Avaliação\n",
        "    evaluate_and_log_model(\"catboost\", \"CatBoost FineTuned\", best_model, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1d63dd9",
      "metadata": {
        "id": "a1d63dd9"
      },
      "source": [
        "## Stacking Ensemble – LightGBM + CatBoost\n",
        "\n",
        "Após avaliarmos isoladamente os modelos **LightGBM** e **CatBoost**, partiremos agora para a construção de um **modelo em ensemble via StackingClassifier**, com o objetivo de combinar suas forças.\n",
        "\n",
        "- O **Stacking** é uma técnica de ensemble que combina diferentes algoritmos como base learners e utiliza um modelo meta para agregar suas previsões.\n",
        "- Utilizaremos o **LightGBM** e o **CatBoost**, ambos já ajustados com **RandomizedSearchCV**, como base learners do ensemble.\n",
        "- O meta-modelo escolhido será uma **árvore de decisão simples**, que aprenderá a combinar as predições das bases.\n",
        "- Optamos por `passthrough=False` para usar apenas as predições dos modelos base como entrada para o meta-modelo, reduzindo risco de overfitting.\n",
        "- O treinamento será feito sobre a mesma divisão `train/test`, e também avaliaremos a **robustez via validação cruzada externa** (5-fold).\n",
        "- Toda a execução será rastreada pelo **MLflow**, incluindo métricas, matriz de confusão e parâmetros.\n",
        "\n",
        "Essa abordagem visa obter um modelo mais generalizável e robusto, maximizando o desempenho sobre as diferentes classes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fb96fab",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "cba1a7d6dde242a193f12b0d18e96a4b"
          ]
        },
        "id": "5fb96fab",
        "outputId": "39413ea1-2b5d-4cf4-e801-0265b2eae3ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/get?run_uuid=c85566115777495aa40d6814d0bb7102&run_id=c85566115777495aa40d6814d0bb7102\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cba1a7d6dde242a193f12b0d18e96a4b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Avaliação do Modelo: Stacking LGBM + CatBoost ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.768     0.842     0.804      8805\n",
            "           1      0.833     0.773     0.802     15873\n",
            "           2      0.727     0.768     0.747      5322\n",
            "\n",
            "    accuracy                          0.792     30000\n",
            "   macro avg      0.776     0.794     0.784     30000\n",
            "weighted avg      0.795     0.792     0.793     30000\n",
            "\n",
            "Recall da classe 0 (Poor): 0.842\n",
            "🏃 View run Stacking_LGBM_CatBoost_RFMeta at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/c85566115777495aa40d6814d0bb7102\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        }
      ],
      "source": [
        "with mlflow.start_run(run_name=\"Stacking_LGBM_CatBoost_RFMeta\"):\n",
        "\n",
        "    # Modelos base com hiperparâmetros ajustados\n",
        "    estimators = [\n",
        "        (\"lgbm\", LGBMClassifier(\n",
        "            n_estimators=500,\n",
        "            learning_rate=0.1,\n",
        "            num_leaves=127,\n",
        "            max_depth=-1,\n",
        "            subsample=0.7,\n",
        "            colsample_bytree=1.0,\n",
        "            objective='multiclass',\n",
        "            num_class=3,\n",
        "            random_state=42\n",
        "        )),\n",
        "        (\"catboost\", CatBoostClassifier(\n",
        "            iterations=750,\n",
        "            learning_rate=0.05,\n",
        "            depth=10,\n",
        "            l2_leaf_reg=3,\n",
        "            border_count=64,\n",
        "            loss_function='MultiClass',\n",
        "            eval_metric='TotalF1',\n",
        "            verbose=0,\n",
        "            random_state=42\n",
        "        ))\n",
        "    ]\n",
        "\n",
        "    # Meta-modelo (estimador final)\n",
        "    final_estimator = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=3,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Definição do ensemble com passthrough=False\n",
        "    stacking_clf = StackingClassifier(\n",
        "        estimators=estimators,\n",
        "        final_estimator=final_estimator,\n",
        "        cv=5,\n",
        "        n_jobs=-1,\n",
        "        passthrough=False\n",
        "    )\n",
        "\n",
        "    # Treinamento\n",
        "    stacking_clf.fit(X_train, y_train)\n",
        "\n",
        "    # Avaliação com função central\n",
        "    evaluate_and_log_model(\"stacking\", \"Stacking LGBM + CatBoost\", stacking_clf, X_test, y_test)\n",
        "\n",
        "    # Log extra\n",
        "    mlflow.log_param(\"ensemble_method\", \"stacking\")\n",
        "    mlflow.log_param(\"meta_estimator\", \"random_forest\")\n",
        "    mlflow.log_param(\"passthrough\", False)\n",
        "    mlflow.log_param(\"cv\", 5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "235d3778",
      "metadata": {
        "id": "235d3778"
      },
      "source": [
        "### Justificativa para o Uso do Ensemble LightGBM + CatBoost\n",
        "\n",
        "A decisão por utilizar um Stacking com **LightGBM** e **CatBoost** foi baseada nos resultados individuais obtidos após tuning cuidadoso:\n",
        "\n",
        "- O **CatBoost FineTuned** obteve excelente performance, com **recall de 0.743 na classe 0 (Poor)** e uma média geral (`recall_macro`) de **0.732**, superando todos os modelos anteriores.\n",
        "- O **LightGBM FineTuned** também apresentou bom desempenho, com **boa cobertura da classe 2 (Good)** e um tempo de treinamento significativamente inferior.\n",
        "- Já o Stacking inicial com **três modelos (LightGBM, XGBoost e RandomForest)** teve desempenho muito abaixo do esperado, com recall da classe 0 em apenas 0.33 — sendo **descartado** por baixa eficácia e sobreposição de comportamento entre os modelos.\n",
        "- Ao combinar apenas **os dois melhores modelos (CatBoost e LightGBM)**, alcançamos um **recall da classe 0 de 0.842** e um **recall_macro de 0.794**, além de uma acurácia de **0.792**.\n",
        "\n",
        "Esse resultado evidencia que o ensemble entre esses dois algoritmos **potencializou os pontos fortes de cada um** e contribuiu para **uma classificação mais equilibrada entre as três classes**.\n",
        "\n",
        "Com isso, este modelo passa a ser o **candidato principal à produção**, e será submetido à validação cruzada externa antes de ser registrado no **MLflow Model Registry**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7fecb12",
      "metadata": {
        "id": "f7fecb12",
        "outputId": "f25da5c4-a996-418b-daf9-0f9c36c7917a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔎 Resultados da Validação Cruzada Externa (Stacking Final):\n",
            "\n",
            "accuracy          : 0.7810 ± 0.0033\n",
            "precision_macro   : 0.7641 ± 0.0040\n",
            "recall_macro      : 0.7801 ± 0.0047\n",
            "f1_macro          : 0.7712 ± 0.0043\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "# Métricas para avaliação externa\n",
        "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
        "\n",
        "# Aplicando validação cruzada externa ao modelo já ajustado\n",
        "cv_results = cross_validate(\n",
        "    estimator=stacking_clf,\n",
        "    X=X_train,\n",
        "    y=y_train,\n",
        "    cv=5,\n",
        "    scoring=scoring,\n",
        "    return_train_score=False,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Exibindo resultados médios e variabilidade\n",
        "print(\"🔎 Resultados da Validação Cruzada Externa (Stacking Final):\\n\")\n",
        "for metric in scoring:\n",
        "    media = cv_results[f'test_{metric}'].mean()\n",
        "    desvio = cv_results[f'test_{metric}'].std()\n",
        "    print(f\"{metric:<18}: {media:.4f} ± {desvio:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ec529a1",
      "metadata": {
        "id": "8ec529a1"
      },
      "source": [
        "### Validação Cruzada Externa – Stacking LightGBM + CatBoost\n",
        "\n",
        "Para garantir a robustez do ensemble construído com **LightGBM + CatBoost**, foi aplicada uma **validação cruzada externa (5-fold)** utilizando o `cross_validate` do `sklearn`.\n",
        "\n",
        "- Essa abordagem avalia o modelo com diferentes divisões do dataset, oferecendo uma visão mais confiável sobre sua **generalização**.\n",
        "- Foram calculadas as métricas: **accuracy**, **precision_macro**, **recall_macro** e **f1_macro**.\n",
        "- Os resultados obtidos confirmam a **estabilidade e eficácia do ensemble**, com variações pequenas entre os folds.\n",
        "\n",
        "###  Resultados da Validação Cruzada Externa (Stacking Final):\n",
        "\n",
        "- **Accuracy**: `0.7810 ± 0.0033`  \n",
        "- **Precision (Macro Avg)**: `0.7641 ± 0.0040`  \n",
        "- **Recall (Macro Avg)**: `0.7801 ± 0.0047`  \n",
        "- **F1-score (Macro Avg)**: `0.7712 ± 0.0043`\n",
        "\n",
        "Esses resultados reforçam a escolha do modelo como **candidato final para produção**, com excelente equilíbrio entre as classes, especialmente em cenários multiclasse com forte desbalanceamento.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2a42e0c",
      "metadata": {
        "id": "b2a42e0c"
      },
      "source": [
        "# Nova Experimentação treinamento para melhora do modelo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16466084",
      "metadata": {
        "id": "16466084"
      },
      "source": [
        "\n",
        "## Análise Resumida dos Modelos no DagsHub\n",
        "Esta cédula de código busca e compara os melhores modelos do seu experimento MLflow no DagsHub.\n",
        "\n",
        "O script carrega suas credenciais de forma segura do arquivo .env.\n",
        "\n",
        "Em seguida, classifica os modelos com base no recall da classe Poor, a métrica mais importante para o projeto.\n",
        "\n",
        "Por fim, ele extrai e exibe uma tabela com as métricas-chave (como acurácia de treino e teste) e os principais parâmetros para te ajudar a identificar o melhor modelo e a causa do overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "141b1e7d",
      "metadata": {
        "id": "141b1e7d",
        "outputId": "c18b7df5-18fb-4db2-87ba-2835794f29e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 7 Modelos por Recall da Classe 'Poor' no DagsHub\n",
            "------------------------------------------------------------\n",
            "| Modelo                                  |   Recall (Poor) |   Acurácia de Treino | Acurácia de Teste   | Parâmetros                                                                                                                                    |\n",
            "|:----------------------------------------|----------------:|---------------------:|:--------------------|:----------------------------------------------------------------------------------------------------------------------------------------------|\n",
            "| Stacking_LGBM_CatBoost_RFMeta           |        0.842249 |             0.980586 | N/A                 | {'learning_rate': 'N/A', 'n_estimators': 'N/A', 'num_leaves': 'N/A', 'depth': 'N/A', 'l2_leaf_reg': 'N/A', 'meta_estimator': 'random_forest'} |\n",
            "| LightGBM_Estimators_LearningRate_Tuning |        0.788984 |             0.996771 | N/A                 | {'learning_rate': 'N/A', 'n_estimators': 'N/A', 'num_leaves': 'N/A', 'depth': 'N/A', 'l2_leaf_reg': 'N/A', 'meta_estimator': 'N/A'}           |\n",
            "| LightGBM_FineTuning                     |        0.78569  |             0.996843 | N/A                 | {'learning_rate': '0.1', 'n_estimators': '500', 'num_leaves': '127', 'depth': 'N/A', 'l2_leaf_reg': 'N/A', 'meta_estimator': 'N/A'}           |\n",
            "| LightGBM_Classifier_RandomSearch        |        0.77774  |             0.970014 | N/A                 | {'learning_rate': '0.1', 'n_estimators': '300', 'num_leaves': '127', 'depth': 'N/A', 'l2_leaf_reg': 'N/A', 'meta_estimator': 'N/A'}           |\n",
            "| RandomForest_Classifier_RandomSearch    |        0.753663 |             0.934371 | N/A                 | {'learning_rate': 'N/A', 'n_estimators': '200', 'num_leaves': 'N/A', 'depth': 'N/A', 'l2_leaf_reg': 'N/A', 'meta_estimator': 'N/A'}           |\n",
            "| CatBoost_FineTuning                     |        0.74276  |             0.864386 | N/A                 | {'learning_rate': 'N/A', 'n_estimators': 'N/A', 'num_leaves': 'N/A', 'depth': 'N/A', 'l2_leaf_reg': 'N/A', 'meta_estimator': 'N/A'}           |\n",
            "| XGBoost_Classifier_RandomSearch         |        0.72686  |             0.834771 | N/A                 | {'learning_rate': '0.1', 'n_estimators': '100', 'num_leaves': 'N/A', 'depth': 'N/A', 'l2_leaf_reg': 'N/A', 'meta_estimator': 'N/A'}           |\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Encontra e carrega o arquivo .env, buscando a partir do diretório atual\n",
        "load_dotenv(find_dotenv())\n",
        "\n",
        "# Agora você pode acessar as variáveis de ambiente\n",
        "mlflow_user = os.environ.get('MLFLOW_TRACKING_USERNAME')\n",
        "mlflow_token = os.environ.get('MLFLOW_TRACKING_PASSWORD')\n",
        "\n",
        "# A URI de rastreamento segue o padrão: https://dagshub.com/<usuario>/<repo>.mlflow\n",
        "# O autolog já faz essa configuração para você, mas é bom ter o comando explícito aqui\n",
        "mlflow.set_tracking_uri(\"https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow\")\n",
        "# 2. Inicializa o cliente do MLflow\n",
        "client = MlflowClient()\n",
        "\n",
        "# Define o nome do experimento\n",
        "# Verifique o nome exato no seu Dashboard do DagsHub\n",
        "experiment_name = \"Default\" # Geralmente é 'Default', a menos que você tenha criado um nome específico\n",
        "\n",
        "try:\n",
        "    experiment = client.get_experiment_by_name(experiment_name)\n",
        "    if experiment is None:\n",
        "        raise ValueError(f\"Experiment with name '{experiment_name}' not found.\")\n",
        "\n",
        "    # Busca as 7 melhores execuções baseadas no recall da classe 0 (Poor)\n",
        "    runs = client.search_runs(\n",
        "        experiment_ids=[experiment.experiment_id],\n",
        "        order_by=[\"metrics.Recall_class_0_Poor DESC\"],\n",
        "        max_results=7\n",
        "    )\n",
        "\n",
        "    model_data = []\n",
        "\n",
        "    for run in runs:\n",
        "        model_name = run.data.tags.get('mlflow.runName', run.info.run_name)\n",
        "\n",
        "        metrics = run.data.metrics\n",
        "        recall_poor = metrics.get('Recall_class_0_Poor', 'N/A')\n",
        "\n",
        "        # O MLflow Autolog pode ter registrado a acurácia de treino e teste\n",
        "        training_accuracy = metrics.get('training_accuracy_score', 'N/A')\n",
        "        test_accuracy = metrics.get('accuracy', 'N/A')\n",
        "\n",
        "        params = run.data.params\n",
        "\n",
        "        relevant_params = {\n",
        "            'learning_rate': params.get('learning_rate', 'N/A'),\n",
        "            'n_estimators': params.get('n_estimators', 'N/A'),\n",
        "            'num_leaves': params.get('num_leaves', 'N/A'),\n",
        "            'depth': params.get('depth', 'N/A'),\n",
        "            'l2_leaf_reg': params.get('l2_leaf_reg', 'N/A'),\n",
        "            'meta_estimator': params.get('meta_estimator', 'N/A')\n",
        "        }\n",
        "\n",
        "        model_data.append({\n",
        "            'Modelo': model_name,\n",
        "            'Recall (Poor)': recall_poor,\n",
        "            'Acurácia de Treino': training_accuracy,\n",
        "            'Acurácia de Teste': test_accuracy,\n",
        "            'Parâmetros': relevant_params\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(model_data)\n",
        "\n",
        "    print(\"Top 7 Modelos por Recall da Classe 'Poor' no DagsHub\")\n",
        "    print(\"-\" * 60)\n",
        "    print(df.to_markdown(index=False))\n",
        "\n",
        "except ValueError as e:\n",
        "    print(f\"Erro: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"Ocorreu um erro ao conectar ou buscar no MLflow: {e}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1d62ba1",
      "metadata": {
        "id": "a1d62ba1"
      },
      "source": [
        "## Stacking LGBM + Catboost: Melhora do modelo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a330418",
      "metadata": {},
      "source": [
        "### Stacking (LGBM + CatBoost) com meta-learner Logístico e busca aleatória\n",
        "\n",
        "Estratégia: empilhar LGBM e CatBoost para capturar vieses complementares e reduzir erro sistemático por classe.\n",
        "O meta-learner é uma Regressão Logística multinomial, escolhida por simplicidade, regularização e boa calibração de decisão.\n",
        "Usamos RandomizedSearchCV para explorar hiperparâmetros-chave dos base learners e a regularização do meta, priorizando recall_macro.\n",
        "A validação cruzada (cv=3) acelera a descoberta de direções promissoras; vencedores devem ser confirmados depois com cv=5.\n",
        "O meta recebe apenas as previsões dos base models (passthrough=False), mitigando overfitting e focando a combinação das probabilidades.\n",
        "O MLflow registra melhores parâmetros/score, permitindo comparar versões e orientar próximos passos (calibração e thresholds por classe)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b301f7b0",
      "metadata": {
        "id": "b301f7b0",
        "outputId": "ce08cd1f-ec43-4b32-f36f-c818b7720af9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/08/27 16:09:01 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/08/28 02:07:28 INFO mlflow.sklearn.utils: Logging the 5 best runs, 45 runs will be omitted.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏃 View run stately-wasp-233 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/f8142d7ae9b94f12aa778a340a89fed2\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run enchanting-worm-126 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/6941e0afad7b4e95ad3ca7e78b43a2ee\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run handsome-fish-556 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/5b0cb52c5b6c48f5b6a4fa1d4872a592\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run puzzled-wasp-608 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/d74a40c585fe440797909380818f5635\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run awesome-gnu-200 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/f542683c545e4dca89137b194ec4a55f\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "Melhores parâmetros encontrados:\n",
            "{'lgbm__num_leaves': 63, 'lgbm__n_estimators': 900, 'lgbm__learning_rate': 0.2, 'final_estimator__C': 0.1, 'catboost__learning_rate': 0.01, 'catboost__l2_leaf_reg': 5, 'catboost__iterations': 100, 'catboost__depth': 10}\n",
            "Melhor pontuação (recall macro): 0.7353\n",
            "🏃 View run Stacking_RandomSearch_Pre_Scaled_Data at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/2dc10c1b7af1474b9c3f5691ad42ae4a\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/log-inputs\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/log-inputs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏃 View run bustling-hawk-256 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/cc878ab7d37c46fbaefa4689b06a1260\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏃 View run hilarious-bug-345 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/897ec702ca2d4e84bb48adc7c099f07a\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run wise-conch-344 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/9cbc6cbc4bc4426992d00bc41cc57196\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run bittersweet-cat-344 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/b34d53303ae0451281075ebee64f5d2d\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run youthful-deer-665 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/fcea06b95d1042758ed65b9b796d3a15\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run salty-ant-743 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/fddd492ae1c942e1b0f8bdb225e7e3b1\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/log-batch\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏃 View run big-dove-219 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/c8053fd442524b8c8e817dc96a51893c\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run judicious-sow-660 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/0c77e6092fab4da1927676de394e9bf0\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run welcoming-kite-36 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/ef39264abe31498e80332fcedb83d448\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run wise-wolf-760 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/bf4623ff36614220aa1e82b647f84990\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏃 View run big-foal-530 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/b980c5abd49c41ce9dc3529e551fd157\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run defiant-auk-482 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/1707741c355040c6989bf031ced3aabf\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run trusting-wren-927 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/cbb2eba8179c47ab85221f5dec905df0\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run burly-lamb-360 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/ca08dd4e3c9944339b21c2c15a8994fc\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run gaudy-fly-356 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/0049114304e54ef4b10aeb45fbbbea13\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/log-inputs\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/log-inputs\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/log-inputs\n"
          ]
        }
      ],
      "source": [
        "# Define os estimadores base\n",
        "estimators = [\n",
        "    (\"lgbm\", LGBMClassifier(random_state=42)),\n",
        "    (\"catboost\", CatBoostClassifier(verbose=0, random_state=42))\n",
        "]\n",
        "\n",
        "# Define o meta-modelo\n",
        "final_estimator = LogisticRegression(solver='lbfgs', multi_class='multinomial')\n",
        "\n",
        "# Define o modelo de Stacking\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=estimators,\n",
        "    final_estimator=final_estimator,\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Define a grade de parâmetros para a busca aleatória\n",
        "param_dist = {\n",
        "    'lgbm__n_estimators': np.arange(100, 1000, 100),\n",
        "    'lgbm__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'lgbm__num_leaves': [16, 31, 63, 127],\n",
        "    'catboost__iterations': np.arange(100, 1000, 100),\n",
        "    'catboost__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'catboost__depth': [4, 6, 8, 10],\n",
        "    'catboost__l2_leaf_reg': [1, 3, 5, 10],\n",
        "    'final_estimator__C': [0.1, 1.0, 10.0]\n",
        "}\n",
        "\n",
        "# Configura o RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=stacking_clf,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=50,\n",
        "    scoring='recall_macro',\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Inicia o run no MLflow e executa a busca\n",
        "with mlflow.start_run(run_name=\"Stacking_RandomSearch_Pre_Scaled_Data\"):\n",
        "    random_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Log dos melhores parâmetros e métricas no MLflow\n",
        "    mlflow.log_params(random_search.best_params_)\n",
        "    mlflow.log_metric(\"best_recall_macro_score\", random_search.best_score_)\n",
        "\n",
        "    # Exibe os melhores parâmetros e a melhor pontuação\n",
        "    print(\"Melhores parâmetros encontrados:\")\n",
        "    print(random_search.best_params_)\n",
        "    print(f\"Melhor pontuação (recall macro): {random_search.best_score_:.4f}\")\n",
        "\n",
        "    # Armazena o melhor modelo treinado\n",
        "    best_stacking_model = random_search.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe4892d4",
      "metadata": {
        "id": "fe4892d4"
      },
      "source": [
        "### Fixação do resultado pois deu erro no Log do MLFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a54f5d8",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "66ce0d6b6a774a5d85dd7caadb0b49c8"
          ]
        },
        "id": "8a54f5d8",
        "outputId": "91b3ea69-a447-406c-968c-af464b40acfb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n",
            "2025/08/28 11:08:52 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/get?run_uuid=55b2003a07654c12b99f81fe50641f8a&run_id=55b2003a07654c12b99f81fe50641f8a\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "66ce0d6b6a774a5d85dd7caadb0b49c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Avaliação do Modelo: Modelo_Final_Producao ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.791     0.764     0.778      8805\n",
            "           1      0.778     0.824     0.800     15873\n",
            "           2      0.769     0.676     0.720      5322\n",
            "\n",
            "    accuracy                          0.780     30000\n",
            "   macro avg      0.779     0.755     0.766     30000\n",
            "weighted avg      0.780     0.780     0.779     30000\n",
            "\n",
            "Recall da classe 0 (Poor): 0.764\n",
            "🏃 View run Best_Stacking_Model_Final at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/55b2003a07654c12b99f81fe50641f8a\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        }
      ],
      "source": [
        "# Início do experimento com MLflow para registrar o modelo final\n",
        "with mlflow.start_run(run_name=\"Best_Stacking_Model_Final\"):\n",
        "\n",
        "    # Define os melhores parâmetros encontrados na busca\n",
        "    best_params = {\n",
        "        'lgbm__num_leaves': 63,\n",
        "        'lgbm__n_estimators': 900,\n",
        "        'lgbm__learning_rate': 0.2,\n",
        "        'final_estimator__C': 0.1,\n",
        "        'catboost__learning_rate': 0.01,\n",
        "        'catboost__l2_leaf_reg': 5,\n",
        "        'catboost__iterations': 100,\n",
        "        'catboost__depth': 10\n",
        "    }\n",
        "\n",
        "    # Instancia os modelos base e o meta-modelo com os parâmetros otimizados\n",
        "    lgbm_params = {k.replace('lgbm__', ''): v for k, v in best_params.items() if 'lgbm__' in k}\n",
        "    catboost_params = {k.replace('catboost__', ''): v for k, v in best_params.items() if 'catboost__' in k}\n",
        "    final_estimator_params = {k.replace('final_estimator__', ''): v for k, v in best_params.items() if 'final_estimator__' in k}\n",
        "\n",
        "    lgbm = LGBMClassifier(**lgbm_params, random_state=42)\n",
        "    catboost = CatBoostClassifier(**catboost_params, verbose=0, random_state=42)\n",
        "    final_estimator = LogisticRegression(**final_estimator_params)\n",
        "\n",
        "    # Define o modelo de Stacking final\n",
        "    final_stacking_model = StackingClassifier(\n",
        "        estimators=[(\"lgbm\", lgbm), (\"catboost\", catboost)],\n",
        "        final_estimator=final_estimator,\n",
        "        cv=5,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    # Treinamento do modelo final no conjunto de treino completo e escalonado\n",
        "    final_stacking_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Log dos melhores hiperparâmetros\n",
        "    for param, value in best_params.items():\n",
        "        mlflow.log_param(param, value)\n",
        "\n",
        "    # Avaliação e log via sua função customizada\n",
        "    evaluate_and_log_model(\n",
        "        \"stacking\",\n",
        "        \"Modelo_Final_Producao\",\n",
        "        final_stacking_model,\n",
        "        X_test_scaled,\n",
        "        y_test\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "520b75fb",
      "metadata": {
        "id": "520b75fb"
      },
      "source": [
        "Resultado equilibrado: acc=0,780, recall_macro=0,755, F1_macro=0,766.\n",
        "Foco de negócio: recall da classe 0 (Poor)=0,764 — razoável, porém ainda com espaço para ganho.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cedab02a",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f8c8bbea",
      "metadata": {
        "id": "f8c8bbea"
      },
      "source": [
        "## Experimentação para diminuir o overfitting no modelo em produção"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b70e49b",
      "metadata": {
        "id": "6b70e49b"
      },
      "source": [
        "###  1 - Stacking com pré-ajuste via early stopping para reduzir overfitting (LGBM + CatBoost → RF meta)\n",
        "\n",
        "Esta cédula combate overfitting ajustando o número de iterações dos base learners por CV estratificada (k=5) com early stopping (paciência=50).\n",
        "Para o LGBM, busca-se best_iteration_ usando multi_logloss; para CatBoost, get_best_iteration() com TotalF1.\n",
        "Em cada fold, treinamos em treino e validamos no holdout do fold; a função suporta pandas/NumPy sem fricção.\n",
        "Agregamos os melhores por fold tomando a mediana (robusta) e recriamos os modelos com essas iterações “ótimas”.\n",
        "O empilhamento usa StackingClassifier com passthrough=False e RandomForest raso (max_depth=3) como meta-learner.\n",
        "Objetivo: reduzir a capacidade efetiva (menos árvores úteis), abaixar a acurácia de treino e fechar o gap treino–teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0515c00c",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "83d44d4ad28243d1a7cf933280422980"
          ]
        },
        "id": "0515c00c",
        "outputId": "43c438bd-f82c-460c-b909-a154d7e4efe6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005810 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2704\n",
            "[LightGBM] [Info] Number of data points in the train set: 56000, number of used features: 48\n",
            "[LightGBM] [Info] Start training from score -1.243184\n",
            "[LightGBM] [Info] Start training from score -0.629468\n",
            "[LightGBM] [Info] Start training from score -1.722267\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008432 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2707\n",
            "[LightGBM] [Info] Number of data points in the train set: 56000, number of used features: 48\n",
            "[LightGBM] [Info] Start training from score -1.243184\n",
            "[LightGBM] [Info] Start training from score -0.629468\n",
            "[LightGBM] [Info] Start training from score -1.722267\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005556 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2708\n",
            "[LightGBM] [Info] Number of data points in the train set: 56000, number of used features: 48\n",
            "[LightGBM] [Info] Start training from score -1.243184\n",
            "[LightGBM] [Info] Start training from score -0.629468\n",
            "[LightGBM] [Info] Start training from score -1.722267\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019091 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2708\n",
            "[LightGBM] [Info] Number of data points in the train set: 56000, number of used features: 48\n",
            "[LightGBM] [Info] Start training from score -1.243122\n",
            "[LightGBM] [Info] Start training from score -0.629502\n",
            "[LightGBM] [Info] Start training from score -1.722267\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005520 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2708\n",
            "[LightGBM] [Info] Number of data points in the train set: 56000, number of used features: 48\n",
            "[LightGBM] [Info] Start training from score -1.243122\n",
            "[LightGBM] [Info] Start training from score -0.629468\n",
            "[LightGBM] [Info] Start training from score -1.722367\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/log-parameter\n",
            "2025/08/28 12:08:24 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow-artifacts/artifacts/1bcdc4fa750b418bacafd99dfb9f17bf/a2bf38a68ba3447882634914df519bf9/artifacts/training_confusion_matrix.png\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83d44d4ad28243d1a7cf933280422980",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Avaliação do Modelo: Stacking LGBM+CatBoost (early-stop tuned) → RF meta ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.770     0.814     0.791      8805\n",
            "           1      0.815     0.780     0.797     15873\n",
            "           2      0.722     0.748     0.735      5322\n",
            "\n",
            "    accuracy                          0.784     30000\n",
            "   macro avg      0.769     0.780     0.774     30000\n",
            "weighted avg      0.785     0.784     0.784     30000\n",
            "\n",
            "Recall da classe 0 (Poor): 0.814\n",
            "🏃 View run Stacking_LGBM_CatBoost_RFMeta_EarlyStopTuned at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/a2bf38a68ba3447882634914df519bf9\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        }
      ],
      "source": [
        "def _best_iters_lgbm(X, y, base_params, n_splits=5, patience=50, random_state=42):\n",
        "    \"\"\"Descobre melhores n_estimators (best_iteration_) para LGBM via CV com early stopping.\n",
        "    Funciona com pandas DataFrame/Series OU NumPy arrays.\n",
        "    \"\"\"\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    best_iters = []\n",
        "\n",
        "    for tr_idx, va_idx in skf.split(X, y):\n",
        "        # Suporta pandas ou NumPy\n",
        "        if hasattr(X, \"iloc\"):\n",
        "            X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
        "        else:\n",
        "            X_tr, X_va = X[tr_idx], X[va_idx]\n",
        "\n",
        "        if hasattr(y, \"iloc\"):\n",
        "            y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
        "        else:\n",
        "            y_tr, y_va = y[tr_idx], y[va_idx]\n",
        "\n",
        "        lgbm = LGBMClassifier(**base_params)\n",
        "        lgbm.fit(\n",
        "            X_tr, y_tr,\n",
        "            eval_set=[(X_va, y_va)],\n",
        "            eval_metric=\"multi_logloss\",\n",
        "            callbacks=[lgb.early_stopping(stopping_rounds=patience, verbose=False)]\n",
        "        )\n",
        "\n",
        "        it = getattr(lgbm, \"best_iteration_\", None)\n",
        "        best_iters.append(int(it if it is not None else base_params.get(\"n_estimators\", 500)))\n",
        "\n",
        "    return int(np.median(best_iters))\n",
        "\n",
        "\n",
        "def _best_iters_catboost(X, y, base_params, n_splits=5, patience=50, random_state=42):\n",
        "    \"\"\"Descobre melhores iterations (get_best_iteration) para CatBoost via CV com early stopping.\n",
        "    Funciona com pandas DataFrame/Series OU NumPy arrays.\n",
        "    \"\"\"\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    best_iters = []\n",
        "\n",
        "    for tr_idx, va_idx in skf.split(X, y):\n",
        "        # Suporta pandas ou NumPy\n",
        "        if hasattr(X, \"iloc\"):\n",
        "            X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
        "        else:\n",
        "            X_tr, X_va = X[tr_idx], X[va_idx]\n",
        "\n",
        "        if hasattr(y, \"iloc\"):\n",
        "            y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
        "        else:\n",
        "            y_tr, y_va = y[tr_idx], y[va_idx]\n",
        "\n",
        "        cb = CatBoostClassifier(**base_params)\n",
        "        cb.fit(\n",
        "            X_tr, y_tr,\n",
        "            eval_set=(X_va, y_va),\n",
        "            verbose=False,\n",
        "            early_stopping_rounds=patience,\n",
        "            use_best_model=True\n",
        "        )\n",
        "\n",
        "        it = cb.get_best_iteration()\n",
        "        best_iters.append(int(it if it is not None and it > 0 else base_params.get(\"iterations\", 750)))\n",
        "\n",
        "    return int(np.median(best_iters))\n",
        "\n",
        "\n",
        "with mlflow.start_run(run_name=\"Stacking_LGBM_CatBoost_RFMeta_EarlyStopTuned\"):\n",
        "\n",
        "    # ---------------------------\n",
        "    # 1) Pré-ajuste com early stopping (não mexe no Stacking ainda)\n",
        "    # ---------------------------\n",
        "    lgbm_base_params = dict(\n",
        "        n_estimators=500,\n",
        "        learning_rate=0.1,\n",
        "        num_leaves=127,\n",
        "        max_depth=-1,\n",
        "        subsample=0.7,\n",
        "        colsample_bytree=1.0,\n",
        "        objective='multiclass',\n",
        "        num_class=3,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    cat_base_params = dict(\n",
        "        iterations=750,\n",
        "        learning_rate=0.05,\n",
        "        depth=10,\n",
        "        l2_leaf_reg=3,\n",
        "        border_count=64,\n",
        "        loss_function='MultiClass',\n",
        "        eval_metric='TotalF1',\n",
        "        verbose=0,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Descobrir melhores iterações por CV com early stopping\n",
        "    best_lgbm_iters = _best_iters_lgbm(\n",
        "        X_train, y_train,\n",
        "        base_params=lgbm_base_params,\n",
        "        n_splits=5,\n",
        "        patience=50,\n",
        "        random_state=42\n",
        "    )\n",
        "    best_cat_iters = _best_iters_catboost(\n",
        "        X_train, y_train,\n",
        "        base_params=cat_base_params,\n",
        "        n_splits=5,\n",
        "        patience=50,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Log dos melhores valores encontrados\n",
        "    mlflow.log_param(\"early_stop_search_cv\", 5)\n",
        "    mlflow.log_param(\"early_stop_patience\", 50)\n",
        "    mlflow.log_param(\"best_lgbm_n_estimators\", best_lgbm_iters)\n",
        "    mlflow.log_param(\"best_catboost_iterations\", best_cat_iters)\n",
        "\n",
        "    # ---------------------------\n",
        "    # 2) Recriar base learners com iterações reduzidas\n",
        "    # ---------------------------\n",
        "    lgbm_final = LGBMClassifier(\n",
        "        **{**lgbm_base_params, \"n_estimators\": best_lgbm_iters}\n",
        "    )\n",
        "\n",
        "    catboost_final = CatBoostClassifier(\n",
        "        **{**cat_base_params, \"iterations\": best_cat_iters}\n",
        "    )\n",
        "\n",
        "    estimators = [\n",
        "        (\"lgbm\", lgbm_final),\n",
        "        (\"catboost\", catboost_final)\n",
        "    ]\n",
        "\n",
        "    # ---------------------------\n",
        "    # 3) Meta-modelo e Stacking\n",
        "    # ---------------------------\n",
        "    final_estimator = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=3,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    stacking_clf = StackingClassifier(\n",
        "        estimators=estimators,\n",
        "        final_estimator=final_estimator,\n",
        "        cv=5,\n",
        "        n_jobs=-1,\n",
        "        passthrough=False\n",
        "    )\n",
        "\n",
        "    # Treinamento final do ensemble\n",
        "    stacking_clf.fit(X_train, y_train)\n",
        "\n",
        "    # ---------------------------\n",
        "    # 4) Avaliação + MLflow\n",
        "    # ---------------------------\n",
        "    evaluate_and_log_model(\n",
        "        \"stacking\",\n",
        "        \"Stacking LGBM+CatBoost (early-stop tuned) → RF meta\",\n",
        "        stacking_clf,\n",
        "        X_test, y_test\n",
        "    )\n",
        "\n",
        "    # Logs extras\n",
        "    mlflow.log_param(\"ensemble_method\", \"stacking\")\n",
        "    mlflow.log_param(\"meta_estimator\", \"random_forest\")\n",
        "    mlflow.log_param(\"passthrough\", False)\n",
        "    mlflow.log_param(\"cv\", 5)\n",
        "    mlflow.log_param(\"lgbm_learning_rate\", lgbm_base_params[\"learning_rate\"])\n",
        "    mlflow.log_param(\"lgbm_num_leaves\", lgbm_base_params[\"num_leaves\"])\n",
        "    mlflow.log_param(\"catboost_depth\", cat_base_params[\"depth\"])\n",
        "    mlflow.log_param(\"catboost_l2_leaf_reg\", cat_base_params[\"l2_leaf_reg\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f11abd37",
      "metadata": {
        "id": "f11abd37"
      },
      "source": [
        "### 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de0440e5",
      "metadata": {
        "id": "de0440e5"
      },
      "source": [
        "#### Stacking 2A — LGBM regularizado + early stopping retunado (CatBoost reutilizado) → RF meta\n",
        "\n",
        "Nesta cédula reforçamos o combate ao overfitting atuando no LGBM: reduzimos capacidade e adicionamos regularização explícita (num_leaves=95, max_depth=10, min_child_samples=60, reg_lambda=1.0, reg_alpha=0.1, min_split_gain=0.1, colsample_bytree=0.8, subsample=0.7, subsample_freq=1).\n",
        "O n_estimators do LGBM é recalibrado por CV (k=5) com early stopping (paciência=40), usando multi_logloss; adotamos a mediana dos best_iteration_ como valor final, visando estabilidade.\n",
        "O CatBoost é reaproveitado com as iterações já validadas (ou fallback 750), mantendo eval_metric=TotalF1 e learning_rate=0.05.\n",
        "Construímos o ensemble via StackingClassifier com passthrough=False, meta-learner RandomForest raso (max_depth=3), e CV=5 interna para as predições-meta.\n",
        "Objetivo: diminuir capacidade efetiva do LGBM e fechar o gap treino–teste sem alterar arquitetura, preservando recall por classe (especialmente classe 0 – Poor)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaa757a5",
      "metadata": {
        "id": "eaa757a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005338 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2704\n",
            "[LightGBM] [Info] Number of data points in the train set: 56000, number of used features: 48\n",
            "[LightGBM] [Info] Start training from score -1.243184\n",
            "[LightGBM] [Info] Start training from score -0.629468\n",
            "[LightGBM] [Info] Start training from score -1.722267\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2707\n",
            "[LightGBM] [Info] Number of data points in the train set: 56000, number of used features: 48\n",
            "[LightGBM] [Info] Start training from score -1.243184\n",
            "[LightGBM] [Info] Start training from score -0.629468\n",
            "[LightGBM] [Info] Start training from score -1.722267\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021609 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2708\n",
            "[LightGBM] [Info] Number of data points in the train set: 56000, number of used features: 48\n",
            "[LightGBM] [Info] Start training from score -1.243184\n",
            "[LightGBM] [Info] Start training from score -0.629468\n",
            "[LightGBM] [Info] Start training from score -1.722267\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015923 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2708\n",
            "[LightGBM] [Info] Number of data points in the train set: 56000, number of used features: 48\n",
            "[LightGBM] [Info] Start training from score -1.243122\n",
            "[LightGBM] [Info] Start training from score -0.629502\n",
            "[LightGBM] [Info] Start training from score -1.722267\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007369 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2708\n",
            "[LightGBM] [Info] Number of data points in the train set: 56000, number of used features: 48\n",
            "[LightGBM] [Info] Start training from score -1.243122\n",
            "[LightGBM] [Info] Start training from score -0.629468\n",
            "[LightGBM] [Info] Start training from score -1.722367\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/14 22:01:47 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ba20908f87a4fd084bd26e23430ad5b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Avaliação do Modelo: Stacking LGBM+CatBoost (LGBM regularizado + ES retuned) → RF meta ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.764     0.819     0.791      8805\n",
            "           1      0.819     0.777     0.797     15873\n",
            "           2      0.727     0.753     0.740      5322\n",
            "\n",
            "    accuracy                          0.785     30000\n",
            "   macro avg      0.770     0.783     0.776     30000\n",
            "weighted avg      0.787     0.785     0.785     30000\n",
            "\n",
            "Recall da classe 0 (Poor): 0.819\n",
            "Acurácia de Treino: 0.919\n",
            "🏃 View run Stacking_LGBM_CatBoost_RFMeta_LGBMReg_2A-Repeat at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/01fce9d091a5491d98d697da32e6f712\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏃 View run polite-rat-797 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/7cf0f2a3e19c47da9174a4321ca60d91\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run incongruous-ray-564 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/df1d544caa834158b5164b1a6ce0b2c0\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏃 View run powerful-gnu-951 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/10ee9a3c6e3f424cb93f8d3a82af862f\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        }
      ],
      "source": [
        "def _best_iters_lgbm(X, y, base_params, n_splits=5, patience=40, random_state=42):\n",
        "    \"\"\"Estimativa do melhor n_estimators para LGBM via CV com early stopping.\n",
        "    Funciona com pandas ou NumPy.\n",
        "    \"\"\"\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    best_iters = []\n",
        "    for tr_idx, va_idx in skf.split(X, y):\n",
        "        if hasattr(X, \"iloc\"):\n",
        "            X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
        "        else:\n",
        "            X_tr, X_va = X[tr_idx], X[va_idx]\n",
        "\n",
        "        if hasattr(y, \"iloc\"):\n",
        "            y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
        "        else:\n",
        "            y_tr, y_va = y[tr_idx], y[va_idx]\n",
        "\n",
        "        mdl = LGBMClassifier(**base_params)\n",
        "        mdl.fit(\n",
        "            X_tr, y_tr,\n",
        "            eval_set=[(X_va, y_va)],\n",
        "            eval_metric=\"multi_logloss\",\n",
        "            callbacks=[lgb.early_stopping(stopping_rounds=patience, verbose=False)]\n",
        "        )\n",
        "        it = getattr(mdl, \"best_iteration_\", None)\n",
        "        best_iters.append(int(it if it is not None else base_params.get(\"n_estimators\", 500)))\n",
        "    return int(np.median(best_iters))\n",
        "\n",
        "\n",
        "with mlflow.start_run(run_name=\"Stacking_LGBM_CatBoost_RFMeta_LGBMReg_2A-Repeat\"):\n",
        "    # ---------------------------\n",
        "    # 1) LGBM com regularização leve (apertos sugeridos)\n",
        "    # ---------------------------\n",
        "    lgbm_reg_params = dict(\n",
        "        # manter learning_rate e subsample base\n",
        "        learning_rate=0.1,\n",
        "        subsample=0.7,\n",
        "        subsample_freq=1,         # ativa bagging\n",
        "        colsample_bytree=0.8,     # feature_fraction\n",
        "        # capacidade/complexidade\n",
        "        num_leaves=95,            # ↓ de 127\n",
        "        max_depth=10,             # antes -1\n",
        "        min_child_samples=60,     # ↑ de 20\n",
        "        # regularização explícita\n",
        "        reg_lambda=1.0,           # L2\n",
        "        reg_alpha=0.1,            # L1\n",
        "        min_split_gain=0.1,\n",
        "        # demais\n",
        "        objective=\"multiclass\",\n",
        "        num_class=3,\n",
        "        random_state=42,\n",
        "        n_estimators=600          # valor provisório; será recalibrado via early stopping\n",
        "    )\n",
        "\n",
        "    # 2) Re-otimizar n_estimators do LGBM com ES (CV=5, patience=40)\n",
        "    best_lgbm_iters_2a = _best_iters_lgbm(\n",
        "        X_train, y_train,\n",
        "        base_params=lgbm_reg_params,\n",
        "        n_splits=5,\n",
        "        patience=40,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    mlflow.log_param(\"stage\", \"2A_LGBM_regularized\")\n",
        "    mlflow.log_param(\"early_stop_search_cv\", 5)\n",
        "    mlflow.log_param(\"early_stop_patience\", 40)\n",
        "    mlflow.log_param(\"best_lgbm_n_estimators_2A\", best_lgbm_iters_2a)\n",
        "\n",
        "    # ---------------------------\n",
        "    # 3) CatBoost reaproveitado (fallback para 750 se não foi definido antes)\n",
        "    # ---------------------------\n",
        "    try:\n",
        "        best_cat_iters  # se você definiu antes (ex.: best_cat_iters = 6XX)\n",
        "    except NameError:\n",
        "        best_cat_iters = 750  # fallback seguro\n",
        "\n",
        "    cat_params = dict(\n",
        "        iterations=best_cat_iters,\n",
        "        learning_rate=0.05,\n",
        "        depth=10,\n",
        "        l2_leaf_reg=3,\n",
        "        border_count=64,\n",
        "        loss_function=\"MultiClass\",\n",
        "        eval_metric=\"TotalF1\",\n",
        "        verbose=0,\n",
        "        random_state=42\n",
        "    )\n",
        "    mlflow.log_param(\"catboost_iterations_used\", best_cat_iters)\n",
        "\n",
        "    # ---------------------------\n",
        "    # 4) Montar ensemble e treinar\n",
        "    # ---------------------------\n",
        "    lgbm_final_2a = LGBMClassifier(**{**lgbm_reg_params, \"n_estimators\": best_lgbm_iters_2a})\n",
        "    catboost_final = CatBoostClassifier(**cat_params)\n",
        "\n",
        "    estimators = [\n",
        "        (\"lgbm\", lgbm_final_2a),\n",
        "        (\"catboost\", catboost_final)\n",
        "    ]\n",
        "\n",
        "    final_estimator = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=3,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    stacking_clf_2a = StackingClassifier(\n",
        "        estimators=estimators,\n",
        "        final_estimator=final_estimator,\n",
        "        cv=5,\n",
        "        n_jobs=-1,\n",
        "        passthrough=False\n",
        "    )\n",
        "\n",
        "    stacking_clf_2a.fit(X_train, y_train)\n",
        "\n",
        "    # ---------------------------\n",
        "    # 5) Avaliação + MLflow\n",
        "    # ---------------------------\n",
        "    evaluate_and_log_model(\n",
        "        \"stacking\",\n",
        "        \"Stacking LGBM+CatBoost (LGBM regularizado + ES retuned) → RF meta\",\n",
        "        stacking_clf_2a,\n",
        "        X_test, y_test\n",
        "    )\n",
        "\n",
        "    # Log dos hiperparâmetros chave do LGBM (para rastreio fácil)\n",
        "    mlflow.log_param(\"lgbm_num_leaves_2A\", lgbm_reg_params[\"num_leaves\"])\n",
        "    mlflow.log_param(\"lgbm_max_depth_2A\", lgbm_reg_params[\"max_depth\"])\n",
        "    mlflow.log_param(\"lgbm_min_child_samples_2A\", lgbm_reg_params[\"min_child_samples\"])\n",
        "    mlflow.log_param(\"lgbm_reg_lambda_2A\", lgbm_reg_params[\"reg_lambda\"])\n",
        "    mlflow.log_param(\"lgbm_reg_alpha_2A\", lgbm_reg_params[\"reg_alpha\"])\n",
        "    mlflow.log_param(\"lgbm_min_split_gain_2A\", lgbm_reg_params[\"min_split_gain\"])\n",
        "    mlflow.log_param(\"lgbm_colsample_bytree_2A\", lgbm_reg_params[\"colsample_bytree\"])\n",
        "    mlflow.log_param(\"lgbm_subsample_2A\", lgbm_reg_params[\"subsample\"])\n",
        "    mlflow.log_param(\"lgbm_subsample_freq_2A\", lgbm_reg_params[\"subsample_freq\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2abb87a7",
      "metadata": {
        "id": "2abb87a7"
      },
      "source": [
        "#### Stacking 2B — Random Search focal no LGBM (ao redor do 2A) + retune de iterações, CatBoost fixo (747) → RF meta\n",
        "\n",
        "Após o bom baseline do 2A (LGBM regularizado), este passo busca refinar só o LGBM com um RandomizedSearchCV enxuto (n_iter=12, cv=3) em torno do espaço que funcionou no 2A (num_leaves, max_depth, min_child_samples, reg_λ/α, colsample, subsample, min_split_gain, subsample_freq).\n",
        "Fixamos o CatBoost nas 747 iterações (resgatadas do MLflow) para isolar o efeito do LGBM, e incluímos scorers de recall_macro (principal) e recall_poor (secundário) na busca.\n",
        "Para evitar under/overfit por contagem de árvores, reestimamos n_estimators do LGBM vencedor via CV=5 com early stopping (paciência=35), usando a mediana do best_iteration como valor final estável.\n",
        "O ensemble final mantém o StackingClassifier com passthrough=False e RandomForest raso (max_depth=3) como meta-learner, preservando a generalização do nível meta.\n",
        "Tudo é rastreado no MLflow: hiperparâmetros do top-1, métricas da busca, iterações refinalizadas e avaliação de holdout, permitindo comparação direta com o 2A (inclusive foco em Recall_Poor).\n",
        "Estratégia: apertar o LGBM no ponto ótimo local com orçamento computacional contido, mantendo o CatBoost estável para medir o ganho incremental real no stack."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f28ee6b1",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "c4cf9850d05b4eae9ff3d3fdff0139dd"
          ]
        },
        "id": "f28ee6b1",
        "outputId": "b35a72ca-9b46-46dc-f7c4-a41859294e39"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n",
            "2025/08/28 18:51:42 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/08/28 18:58:51 WARNING mlflow.sklearn.utils: Failed to autolog metrics for RandomizedSearchCV. Logging error: This 'RandomizedSearchCV' has no attribute 'predict'\n",
            "2025/08/28 18:58:51 WARNING mlflow.sklearn.utils: _get_classifier_artifacts.<locals>.plot_confusion_matrix failed. The artifact training_confusion_matrix will not be recorded. Artifact error: This 'RandomizedSearchCV' has no attribute 'predict'\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/get?run_uuid=74733e4ed7c94616ad33400c8c834bc5&run_id=74733e4ed7c94616ad33400c8c834bc5\n",
            "2025/08/28 18:59:10 WARNING mlflow.sklearn.utils: BaseSearchCV.score failed. The 'training_score' metric will not be recorded. Scoring error: This RandomizedSearchCV instance was initialized with `refit=False`. score is available only after refitting on the best parameters. You can refit an estimator manually using the `best_params_` attribute\n",
            "2025/08/28 18:59:11 WARNING mlflow.sklearn: Failed to infer model signature: the trained model does not have a `predict` or `transform` function, which is required in order to infer the signature\n",
            "2025/08/28 18:59:11 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
            "2025/08/28 18:59:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2025/08/28 18:59:21 INFO mlflow.sklearn.utils: Logging the 5 best runs, 7 runs will be omitted.\n",
            "2025/08/28 19:03:22 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow-artifacts/artifacts/1bcdc4fa750b418bacafd99dfb9f17bf/74733e4ed7c94616ad33400c8c834bc5/artifacts/training_confusion_matrix.png\n",
            "2025/08/28 19:16:34 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 74733e4ed7c94616ad33400c8c834bc5. Failed operations: [RestException(\"INVALID_PARAMETER_VALUE: Response: {\\'error_code\\': \\'INVALID_PARAMETER_VALUE\\'}\")]')]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c4cf9850d05b4eae9ff3d3fdff0139dd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Avaliação do Modelo: Stacking LGBM+CatBoost (LGBM RandomSearch PlanA + ES retuned) → RF meta ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.768     0.821     0.793      8805\n",
            "           1      0.821     0.779     0.799     15873\n",
            "           2      0.730     0.759     0.744      5322\n",
            "\n",
            "    accuracy                          0.788     30000\n",
            "   macro avg      0.773     0.786     0.779     30000\n",
            "weighted avg      0.789     0.788     0.788     30000\n",
            "\n",
            "Recall da classe 0 (Poor): 0.821\n",
            "Acurácia de Treino: 0.938\n",
            "🏃 View run Stacking_LGBM_CatBoost_RFMeta_LGBMRandomSearch_2B_PlanA at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/74733e4ed7c94616ad33400c8c834bc5\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        }
      ],
      "source": [
        "# CatBoost: iterações fixadas a partir do MLflow (run \"Stacking_LGBM_CatBoost_RFMeta_EarlyStopTuned\" -> param \"best_catboost_iterations\" = 747)\n",
        "best_cat_iters = 747\n",
        "assert isinstance(best_cat_iters, int) and best_cat_iters > 0\n",
        "\n",
        "def _best_iters_lgbm(X, y, base_params, n_splits=5, patience=35, random_state=42):\n",
        "    \"\"\"Reestima o melhor n_estimators via CV com early stopping (suporta pandas/NumPy).\"\"\"\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    best_iters = []\n",
        "    for tr_idx, va_idx in skf.split(X, y):\n",
        "        X_tr, X_va = (X.iloc[tr_idx], X.iloc[va_idx]) if hasattr(X, \"iloc\") else (X[tr_idx], X[va_idx])\n",
        "        y_tr, y_va = (y.iloc[tr_idx], y.iloc[va_idx]) if hasattr(y, \"iloc\") else (y[tr_idx], y[va_idx])\n",
        "\n",
        "        mdl = LGBMClassifier(**base_params)\n",
        "        mdl.fit(\n",
        "            X_tr, y_tr,\n",
        "            eval_set=[(X_va, y_va)],\n",
        "            eval_metric=\"multi_logloss\",\n",
        "            callbacks=[lgb.early_stopping(stopping_rounds=patience, verbose=False)]\n",
        "        )\n",
        "        it = getattr(mdl, \"best_iteration_\", None)\n",
        "        best_iters.append(int(it if it is not None else base_params.get(\"n_estimators\", 350)))\n",
        "    return int(np.median(best_iters))\n",
        "\n",
        "def _recall_poor(y_true, y_pred):\n",
        "    \"\"\"Recall da classe 0 (Poor) para monitoramento secundário na busca.\"\"\"\n",
        "    per_class = recall_score(y_true, y_pred, labels=[0, 1, 2], average=None, zero_division=0)\n",
        "    return float(per_class[0])\n",
        "\n",
        "recall_macro_scorer = make_scorer(recall_score, average=\"macro\", zero_division=0)\n",
        "recall_poor_scorer  = make_scorer(_recall_poor)\n",
        "\n",
        "with mlflow.start_run(run_name=\"Stacking_LGBM_CatBoost_RFMeta_LGBMRandomSearch_2B_PlanA\"):\n",
        "    # Metadados e rastreabilidade\n",
        "    mlflow.log_param(\"stage\", \"2B_LGBM_random_search_PlanA\")\n",
        "    mlflow.log_param(\"budget_n_iter\", 12)\n",
        "    mlflow.log_param(\"budget_cv_search\", 3)\n",
        "    mlflow.log_param(\"budget_cv_es\", 5)\n",
        "    mlflow.set_tag(\"catboost_iters_source\", \"MLflow: Stacking_LGBM_CatBoost_RFMeta_EarlyStopTuned::best_catboost_iterations=747\")\n",
        "    mlflow.log_param(\"catboost_iterations_used\", best_cat_iters)\n",
        "\n",
        "    # Base do LGBM na busca (sem early stopping; n_estimators moderado para acelerar)\n",
        "    lgbm_base_fixed = dict(\n",
        "        learning_rate=0.1,\n",
        "        objective=\"multiclass\",\n",
        "        num_class=3,\n",
        "        random_state=42,\n",
        "        n_estimators=350,   # menor que 500 para reduzir custo por fit; será reotimizado depois\n",
        "        verbosity=-1\n",
        "    )\n",
        "\n",
        "    # Espaço de busca focado ao redor do 2.A\n",
        "    param_distributions = {\n",
        "        \"num_leaves\":        [80, 85, 90, 95, 100, 105, 110],\n",
        "        \"max_depth\":         [8, 9, 10, 11, 12],\n",
        "        \"min_child_samples\": [40, 50, 60, 70, 80],\n",
        "        \"reg_lambda\":        [0.5, 0.75, 1.0, 1.5, 2.0, 3.0],\n",
        "        \"reg_alpha\":         [0.05, 0.1, 0.2, 0.3, 0.5],\n",
        "        \"min_split_gain\":    [0.0, 0.05, 0.1, 0.15],\n",
        "        \"colsample_bytree\":  [0.75, 0.8, 0.85, 0.9],\n",
        "        \"subsample\":         [0.6, 0.65, 0.7, 0.75, 0.8],\n",
        "        \"subsample_freq\":    [1, 2, 3],\n",
        "    }\n",
        "\n",
        "    # Busca enxuta: 12 amostras x CV=3 = 36 fits\n",
        "    lgbm_search_model = LGBMClassifier(**lgbm_base_fixed)\n",
        "    skf_search = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    search = RandomizedSearchCV(\n",
        "        estimator=lgbm_search_model,\n",
        "        param_distributions=param_distributions,\n",
        "        n_iter=12,\n",
        "        scoring={\"recall_macro\": recall_macro_scorer, \"recall_poor\": recall_poor_scorer},\n",
        "        refit=False,               # evita 1 fit extra\n",
        "        cv=skf_search,\n",
        "        n_jobs=-1,\n",
        "        verbose=1,\n",
        "        random_state=42,\n",
        "        return_train_score=False\n",
        "    )\n",
        "    search.fit(X_train, y_train)\n",
        "\n",
        "    # Seleção manual do melhor por recall_macro e logging dos resultados\n",
        "    results_df = pd.DataFrame(search.cv_results_).copy()\n",
        "    results_df.sort_values(\"mean_test_recall_macro\", ascending=False, inplace=True)\n",
        "    best_idx = int(np.argmax(search.cv_results_[\"mean_test_recall_macro\"]))\n",
        "    best_recall_macro = float(search.cv_results_[\"mean_test_recall_macro\"][best_idx])\n",
        "    best_recall_poor  = float(search.cv_results_[\"mean_test_recall_poor\"][best_idx])\n",
        "    mlflow.log_metric(\"best_cv_recall_macro_2B\", best_recall_macro)\n",
        "    mlflow.log_metric(\"best_cv_recall_poor_2B\", best_recall_poor)\n",
        "\n",
        "    # Log dos melhores hiperparâmetros da busca\n",
        "    best_params_search = results_df.iloc[0][\"params\"]\n",
        "    for k, v in best_params_search.items():\n",
        "        mlflow.log_param(f\"lgbm_best_{k}_2B\", v)\n",
        "\n",
        "    # Artefatos: resultados completos e top-5\n",
        "    with tempfile.TemporaryDirectory() as tmpdir:\n",
        "        all_path  = os.path.join(tmpdir, \"lgbm_random_search_results_full.csv\")\n",
        "        top5_path = os.path.join(tmpdir, \"lgbm_random_search_top5.csv\")\n",
        "        results_df.to_csv(all_path, index=False)\n",
        "        results_df.head(5).to_csv(top5_path, index=False)\n",
        "        mlflow.log_artifact(all_path,  artifact_path=\"random_search\")\n",
        "        mlflow.log_artifact(top5_path, artifact_path=\"random_search\")\n",
        "\n",
        "    # Retune de n_estimators do LGBM com early stopping (CV=5; ~5 fits)\n",
        "    best_params = {**lgbm_base_fixed, **best_params_search, \"n_estimators\": 500}  # provisório para ES\n",
        "    best_lgbm_iters_2B = _best_iters_lgbm(\n",
        "        X_train, y_train,\n",
        "        base_params=best_params,\n",
        "        n_splits=5,\n",
        "        patience=35,\n",
        "        random_state=42\n",
        "    )\n",
        "    mlflow.log_param(\"best_lgbm_n_estimators_2B\", int(best_lgbm_iters_2B))\n",
        "\n",
        "    # Ensemble final: LGBM vencedor + CatBoost fixo + RF meta (Stacking CV=5; ~13 fits)\n",
        "    lgbm_final_2b = LGBMClassifier(**{**best_params, \"n_estimators\": int(best_lgbm_iters_2B)})\n",
        "    catboost_final = CatBoostClassifier(\n",
        "        iterations=best_cat_iters,\n",
        "        learning_rate=0.05,\n",
        "        depth=10,\n",
        "        l2_leaf_reg=3,\n",
        "        border_count=64,\n",
        "        loss_function=\"MultiClass\",\n",
        "        eval_metric=\"TotalF1\",\n",
        "        verbose=0,\n",
        "        random_state=42\n",
        "    )\n",
        "    estimators = [(\"lgbm\", lgbm_final_2b), (\"catboost\", catboost_final)]\n",
        "    final_estimator = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=42)\n",
        "\n",
        "    stacking_clf_2b = StackingClassifier(\n",
        "        estimators=estimators,\n",
        "        final_estimator=final_estimator,\n",
        "        cv=5,\n",
        "        n_jobs=-1,\n",
        "        passthrough=False\n",
        "    )\n",
        "    stacking_clf_2b.fit(X_train, y_train)\n",
        "\n",
        "    # Avaliação e logging no MLflow\n",
        "    evaluate_and_log_model(\n",
        "        \"stacking\",\n",
        "        \"Stacking LGBM+CatBoost (LGBM RandomSearch PlanA + ES retuned) → RF meta\",\n",
        "        stacking_clf_2b,\n",
        "        X_test, y_test\n",
        "    )\n",
        "\n",
        "    # Logging de parâmetros-chave do LGBM (para rastreabilidade)\n",
        "    for hp in [\"num_leaves\", \"max_depth\", \"min_child_samples\", \"reg_lambda\", \"reg_alpha\",\n",
        "               \"min_split_gain\", \"colsample_bytree\", \"subsample\", \"subsample_freq\"]:\n",
        "        mlflow.log_param(f\"lgbm_{hp}_2B_final\", getattr(lgbm_final_2b, hp))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2acfd60",
      "metadata": {},
      "source": [
        "Resultado global melhorou levemente: acc=0,788, recall_macro=0,786, F1_macro=0,779 (vs. 2A: 0,785/0,783/0,776).\n",
        "Classe 0 (Poor) subiu para recall=0,821 (↑ +0,2 p.p. vs. 2A), mantendo o foco de negócio.\n",
        "Classe 2 (Good) também melhora moderada (recall=0,759 vs. 0,753), indicando ganho de equilíbrio.\n",
        "Classe 1 estável (recall=0,779 vs. 0,777), sem regressão relevante.\n",
        "Sinal de overfitting aumentou: train acc=0,938 vs. test acc=0,788 (gap ~15,0 p.p.; em 2A era ~13,4 p.p.).\n",
        "Leitura: o Random Search em torno do 2A encontrou um ponto ligeiramente superior em holdout, ao custo de um pouco mais de ajuste no treino."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15ba17db",
      "metadata": {
        "id": "15ba17db"
      },
      "source": [
        "### Stacking 3A — CatBoost regularizado + early stopping (LGBM 2A fixo) → RF meta\n",
        "\n",
        "Nesta cédula, fixamos o LGBM do 2A e atuamos apenas no CatBoost para reduzir overfitting, mantendo foco em recall da classe 0 (Poor).\n",
        "O CatBoost recebe apertos de regularização: depth 10→8, l2_leaf_reg 3→8, rsm=0.85, subsample=0.8 com bootstrap_type='Bernoulli', random_strength=1.5, border_count=64, learning_rate=0.05.\n",
        "Estimamos o nº ótimo de iterações via CV estratificada k=5 com early stopping (patience=40), tomando a mediana do get_best_iteration() para estabilidade.\n",
        "O LGBM permanece com o pacote regularizado do 2A (num_leaves=95, max_depth=10, min_child_samples=60, reg_lambda=1.0, reg_alpha=0.1, min_split_gain=0.1, colsample_bytree=0.8, subsample=0.7).\n",
        "O ensemble é um StackingClassifier com passthrough=False e RandomForest raso (n_estimators=100, max_depth=3) como meta-learner, visando generalização no nível meta.\n",
        "Objetivo: reduzir a capacidade/variância do CatBoost para diminuir a acurácia de treino e fechar o gap treino–teste sem sacrificar recall_macro e Recall_Poor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "486575d6",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "58eaa7304529474d84f40da139dec8a8"
          ]
        },
        "id": "486575d6",
        "outputId": "6a4a0eda-4f79-41ab-b6d2-c58244aba38c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/log-parameter\n",
            "2025/08/29 14:35:22 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/get?run_uuid=960226a7f2844c4e80463e06a713ab72&run_id=960226a7f2844c4e80463e06a713ab72\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58eaa7304529474d84f40da139dec8a8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Avaliação do Modelo: Stacking LGBM(2A) + CatBoost(3A reg + ES) → RF meta ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.763     0.820     0.790      8805\n",
            "           1      0.823     0.771     0.796     15873\n",
            "           2      0.718     0.766     0.741      5322\n",
            "\n",
            "    accuracy                          0.784     30000\n",
            "   macro avg      0.768     0.785     0.776     30000\n",
            "weighted avg      0.787     0.784     0.785     30000\n",
            "\n",
            "Recall da classe 0 (Poor): 0.820\n",
            "Acurácia de Treino: 0.920\n",
            "🏃 View run Stacking_LGBM_CatBoost_RFMeta_CatBoostReg_3A at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/960226a7f2844c4e80463e06a713ab72\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        }
      ],
      "source": [
        "# === Passo 3A: CatBoost regularizado (aperto leve) + ES para melhor iterations | LGBM fixo do 2.A ===\n",
        "# Objetivo: reduzir overfit no base CatBoost mantendo Recall Poor alto, reaproveitando o LGBM do 2.A.\n",
        "\n",
        "\n",
        "def _best_iters_catboost(X, y, base_params, n_splits=5, patience=40, random_state=42):\n",
        "    \"\"\"Estimativa de iterations ótima para CatBoost via CV com early stopping (suporta pandas/NumPy).\"\"\"\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    best_iters = []\n",
        "    for tr_idx, va_idx in skf.split(X, y):\n",
        "        X_tr, X_va = (X.iloc[tr_idx], X.iloc[va_idx]) if hasattr(X, \"iloc\") else (X[tr_idx], X[va_idx])\n",
        "        y_tr, y_va = (y.iloc[tr_idx], y.iloc[va_idx]) if hasattr(y, \"iloc\") else (y[tr_idx], y[va_idx])\n",
        "\n",
        "        cb = CatBoostClassifier(**base_params)\n",
        "        cb.fit(\n",
        "            X_tr, y_tr,\n",
        "            eval_set=(X_va, y_va),\n",
        "            verbose=False,\n",
        "            early_stopping_rounds=patience,\n",
        "            use_best_model=True\n",
        "        )\n",
        "        it = cb.get_best_iteration()\n",
        "        best_iters.append(int(it if it is not None and it > 0 else base_params.get(\"iterations\", 800)))\n",
        "    return int(np.median(best_iters))\n",
        "\n",
        "\n",
        "with mlflow.start_run(run_name=\"Stacking_LGBM_CatBoost_RFMeta_CatBoostReg_3A\"):\n",
        "    # --- LGBM fixo (2.A) ---\n",
        "    lgbm_params_2a = dict(\n",
        "        learning_rate=0.1,\n",
        "        colsample_bytree=0.8,\n",
        "        min_split_gain=0.1,\n",
        "        subsample=0.7,\n",
        "        subsample_freq=1,\n",
        "        num_leaves=95,\n",
        "        max_depth=10,\n",
        "        min_child_samples=60,\n",
        "        reg_lambda=1.0,\n",
        "        reg_alpha=0.1,\n",
        "        objective=\"multiclass\",\n",
        "        num_class=3,\n",
        "        random_state=42,\n",
        "        n_estimators=408\n",
        "    )\n",
        "\n",
        "    # --- CatBoost 3A: regularização leve (aperto) ---\n",
        "    # depth↓, l2_leaf_reg↑, feature sampling (rsm), subsample + bootstrap Bernoulli, leve random_strength\n",
        "    cat_base_params_3a = dict(\n",
        "        iterations=900,                 # upper bound; ES definirá o ótimo\n",
        "        learning_rate=0.05,\n",
        "        depth=8,                        # de 10 -> 8\n",
        "        l2_leaf_reg=8,                  # de 3 -> 8\n",
        "        rsm=0.85,                       # feature sampling\n",
        "        subsample=0.8,                  # amostragem de registros\n",
        "        bootstrap_type=\"Bernoulli\",\n",
        "        random_strength=1.5,\n",
        "        border_count=64,\n",
        "        loss_function=\"MultiClass\",\n",
        "        eval_metric=\"TotalF1\",\n",
        "        verbose=0,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    mlflow.log_param(\"stage\", \"3A_CatBoost_regularized\")\n",
        "    for k, v in {**lgbm_params_2a}.items():\n",
        "        mlflow.log_param(f\"lgbm_2A_{k}\", v)\n",
        "    for k, v in {**cat_base_params_3a}.items():\n",
        "        if k != \"iterations\":\n",
        "            mlflow.log_param(f\"catboost_3A_{k}\", v)\n",
        "\n",
        "    # --- Early stopping só no CatBoost para achar melhor iterations ---\n",
        "    best_cat_iters_3a = _best_iters_catboost(\n",
        "        X_train, y_train,\n",
        "        base_params=cat_base_params_3a,\n",
        "        n_splits=5,\n",
        "        patience=40,\n",
        "        random_state=42\n",
        "    )\n",
        "    mlflow.log_param(\"best_catboost_iterations_3A\", int(best_cat_iters_3a))\n",
        "\n",
        "    # --- Montagem do ensemble (LGBM 2.A + CatBoost 3.A) ---\n",
        "    lgbm_final = LGBMClassifier(**lgbm_params_2a)\n",
        "    catboost_final = CatBoostClassifier(**{**cat_base_params_3a, \"iterations\": int(best_cat_iters_3a)})\n",
        "\n",
        "    estimators = [\n",
        "        (\"lgbm\", lgbm_final),\n",
        "        (\"catboost\", catboost_final)\n",
        "    ]\n",
        "\n",
        "    final_estimator = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=3,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    stacking_clf_3a = StackingClassifier(\n",
        "        estimators=estimators,\n",
        "        final_estimator=final_estimator,\n",
        "        cv=5,\n",
        "        n_jobs=-1,\n",
        "        passthrough=False\n",
        "    )\n",
        "\n",
        "    # --- Treino e avaliação ---\n",
        "    stacking_clf_3a.fit(X_train, y_train)\n",
        "\n",
        "    evaluate_and_log_model(\n",
        "        \"stacking\",\n",
        "        \"Stacking LGBM(2A) + CatBoost(3A reg + ES) → RF meta\",\n",
        "        stacking_clf_3a,\n",
        "        X_test, y_test\n",
        "    )\n",
        "\n",
        "    # Log dos principais hiperparâmetros finais (rastreabilidade)\n",
        "    mlflow.log_param(\"catboost_3A_iterations_final\", int(best_cat_iters_3a))\n",
        "    mlflow.log_param(\"lgbm_2A_n_estimators_final\", lgbm_params_2a[\"n_estimators\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f26ea80",
      "metadata": {
        "id": "9f26ea80"
      },
      "source": [
        "### Stacking 3B-1 — CatBoost agressivo (Bernoulli + subsample) com LGBM 2A fixo → RF meta\n",
        "\n",
        "Nesta cédula mantemos o LGBM do 2A fixo e tornamos o CatBoost mais conservador para cortar variância: depth=7 (árvores mais rasas), l2_leaf_reg=12 (L2 ↑), rsm=0.80 (amostragem de features), bootstrap_type='Bernoulli' com subsample=0.75 (amostragem de linhas), random_strength=2.5 (ruído controlado) e border_count=48 (menos bins).\n",
        "Estimamos o nº ótimo de iterações do CatBoost por CV k=5 com early stopping (patience=45) e adotamos a mediana do get_best_iteration() para estabilidade entre folds.\n",
        "O ensemble usa StackingClassifier com passthrough=False e RandomForest raso (n_estimators=100, max_depth=3) como meta-learner, privilegiando generalização no nível meta.\n",
        "Objetivo: reduzir overfitting do CatBoost (baixar train acc/encurtar gap) sem perder o recall macro e mantendo o recall da classe 0 (Poor) elevado.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25767fee",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "95aff333d74f47d6a354d1f37c913b47"
          ]
        },
        "id": "25767fee",
        "outputId": "efe78382-59ad-4872-edb5-d9522850444a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/log-parameter\n",
            "2025/08/29 15:15:15 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/get?run_uuid=bccfb26c333a41cf94facfc225cc8f2c&run_id=bccfb26c333a41cf94facfc225cc8f2c\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95aff333d74f47d6a354d1f37c913b47",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Avaliação do Modelo: Stacking LGBM(2A) + CatBoost(3B1 Bernoulli + ES) → RF meta ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.757     0.829     0.792      8805\n",
            "           1      0.828     0.763     0.795     15873\n",
            "           2      0.717     0.772     0.743      5322\n",
            "\n",
            "    accuracy                          0.784     30000\n",
            "   macro avg      0.768     0.788     0.777     30000\n",
            "weighted avg      0.788     0.784     0.785     30000\n",
            "\n",
            "Recall da classe 0 (Poor): 0.829\n",
            "Acurácia de Treino: 0.925\n",
            "🏃 View run Stacking_LGBM_CatBoost_RFMeta_CatBoostReg_3B1 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/bccfb26c333a41cf94facfc225cc8f2c\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        }
      ],
      "source": [
        "# === Passo 3B-1: CatBoost mais agressivo (Bernoulli + subsample) + LGBM fixo (2.A) + meta RF ===\n",
        "# Objetivo: reduzir overfit do CatBoost mantendo/ganhando Recall Poor e macro, isolando o efeito no base learner.\n",
        "\n",
        "def _best_iters_catboost(X, y, base_params, n_splits=5, patience=45, random_state=42):\n",
        "    \"\"\"Reestima o melhor 'iterations' para CatBoost via CV + early stopping (compatível com pandas/NumPy).\"\"\"\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    best_iters = []\n",
        "    for tr_idx, va_idx in skf.split(X, y):\n",
        "        X_tr, X_va = (X.iloc[tr_idx], X.iloc[va_idx]) if hasattr(X, \"iloc\") else (X[tr_idx], X[va_idx])\n",
        "        y_tr, y_va = (y.iloc[tr_idx], y.iloc[va_idx]) if hasattr(y, \"iloc\") else (y[tr_idx], y[va_idx])\n",
        "\n",
        "        cb = CatBoostClassifier(**base_params)\n",
        "        cb.fit(\n",
        "            X_tr, y_tr,\n",
        "            eval_set=(X_va, y_va),\n",
        "            verbose=False,\n",
        "            early_stopping_rounds=patience,\n",
        "            use_best_model=True\n",
        "        )\n",
        "        it = cb.get_best_iteration()\n",
        "        best_iters.append(int(it if it is not None and it > 0 else base_params.get(\"iterations\", 1200)))\n",
        "    return int(sorted(best_iters)[len(best_iters)//2])  # mediana\n",
        "\n",
        "with mlflow.start_run(run_name=\"Stacking_LGBM_CatBoost_RFMeta_CatBoostReg_3B1\"):\n",
        "    # LGBM fixo (2.A)\n",
        "    lgbm_params_2a = dict(\n",
        "        learning_rate=0.1,\n",
        "        colsample_bytree=0.8,\n",
        "        min_split_gain=0.1,\n",
        "        subsample=0.7,\n",
        "        subsample_freq=1,\n",
        "        num_leaves=95,\n",
        "        max_depth=10,\n",
        "        min_child_samples=60,\n",
        "        reg_lambda=1.0,\n",
        "        reg_alpha=0.1,\n",
        "        objective=\"multiclass\",\n",
        "        num_class=3,\n",
        "        random_state=42,\n",
        "        n_estimators=408\n",
        "    )\n",
        "\n",
        "    # CatBoost 3B-1 (Bernoulli + subsample)\n",
        "    cat_base_params_3b1 = dict(\n",
        "        iterations=1200,              # upper bound; ES definirá o ótimo\n",
        "        learning_rate=0.05,\n",
        "        depth=7,                      # ↓ profundidade\n",
        "        l2_leaf_reg=12,               # ↑ regularização L2\n",
        "        rsm=0.80,                     # feature sampling\n",
        "        bootstrap_type=\"Bernoulli\",   # usa subsample (não usar bagging_temperature)\n",
        "        subsample=0.75,               # amostragem de linhas\n",
        "        random_strength=2.5,          # ruído controlado nos splits\n",
        "        border_count=48,              # menos bins -> menor variância\n",
        "        loss_function=\"MultiClass\",\n",
        "        eval_metric=\"TotalF1\",\n",
        "        verbose=0,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Logging de estágio e parâmetros\n",
        "    mlflow.log_param(\"stage\", \"3B1_CatBoost_Bernoulli_RFMeta\")\n",
        "    for k, v in lgbm_params_2a.items():\n",
        "        mlflow.log_param(f\"lgbm_2A_{k}\", v)\n",
        "    for k, v in cat_base_params_3b1.items():\n",
        "        if k != \"iterations\":\n",
        "            mlflow.log_param(f\"catboost_3B1_{k}\", v)\n",
        "\n",
        "    # Early stopping do CatBoost (recalibra iterations)\n",
        "    best_cat_iters_3b1 = _best_iters_catboost(\n",
        "        X_train, y_train,\n",
        "        base_params=cat_base_params_3b1,\n",
        "        n_splits=5,\n",
        "        patience=45,\n",
        "        random_state=42\n",
        "    )\n",
        "    mlflow.log_param(\"best_catboost_iterations_3B1\", int(best_cat_iters_3b1))\n",
        "\n",
        "    # Ensemble final: LGBM (2.A) + CatBoost (3B-1) + meta RF\n",
        "    lgbm_final = LGBMClassifier(**lgbm_params_2a)\n",
        "    catboost_final = CatBoostClassifier(**{**cat_base_params_3b1, \"iterations\": int(best_cat_iters_3b1)})\n",
        "\n",
        "    estimators = [\n",
        "        (\"lgbm\", lgbm_final),\n",
        "        (\"catboost\", catboost_final)\n",
        "    ]\n",
        "\n",
        "    final_estimator = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=3,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    stacking_clf_3b1 = StackingClassifier(\n",
        "        estimators=estimators,\n",
        "        final_estimator=final_estimator,\n",
        "        cv=5,\n",
        "        n_jobs=-1,\n",
        "        passthrough=False\n",
        "    )\n",
        "\n",
        "    stacking_clf_3b1.fit(X_train, y_train)\n",
        "\n",
        "    evaluate_and_log_model(\n",
        "        \"stacking\",\n",
        "        \"Stacking LGBM(2A) + CatBoost(3B1 Bernoulli + ES) → RF meta\",\n",
        "        stacking_clf_3b1,\n",
        "        X_test, y_test\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82730373",
      "metadata": {
        "id": "82730373"
      },
      "source": [
        "#### Stacking 3B-2 — CatBoost com Bayesian bootstrap + meta LogReg (L2), LGBM 2A fixo\n",
        "\n",
        "Nesta cédula mantemos o LGBM do 2A fixo e tornamos o CatBoost mais regularizado usando bootstrap_type=\"Bayesian\" com bagging_temperature=1.8, além de depth=7, l2_leaf_reg=12, rsm=0.80, border_count=48 e random_strength=2.5 para reduzir variância.\n",
        "Estimamos o nº ótimo de iterações do CatBoost via CV estratificada k=5 com early stopping (paciência=45) e adotamos a mediana do get_best_iteration().\n",
        "No topo, trocamos o meta-learner para LogisticRegression (L2, lbfgs), favorecendo um agregador linear, parcimonioso e estável sobre as previsões dos bases (passthrough=False).\n",
        "Objetivo: diminuir overfitting sem perder recall_macro e mantendo o recall da classe 0 (Poor) competitivo, isolando o impacto do CatBoost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92f89057",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "91a091959f954407aeff05da1d5df997"
          ]
        },
        "id": "92f89057",
        "outputId": "aede7101-1920-43b0-ebee-e5a1c7c7de5c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n",
            "2025/08/29 15:00:01 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/get?run_uuid=39e4123ca6bc4f7a9380b94577015a65&run_id=39e4123ca6bc4f7a9380b94577015a65\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91a091959f954407aeff05da1d5df997",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Avaliação do Modelo: Stacking LGBM(2A) + CatBoost(3B2 Bayesian + ES) → Meta LR(L2) ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.785     0.758     0.771      8805\n",
            "           1      0.774     0.821     0.797     15873\n",
            "           2      0.770     0.672     0.718      5322\n",
            "\n",
            "    accuracy                          0.776     30000\n",
            "   macro avg      0.776     0.751     0.762     30000\n",
            "weighted avg      0.776     0.776     0.775     30000\n",
            "\n",
            "Recall da classe 0 (Poor): 0.758\n",
            "Acurácia de Treino: 0.949\n",
            "🏃 View run Stacking_LGBM_CatBoost_LogRegMeta_CatBoostReg_3B2 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/39e4123ca6bc4f7a9380b94577015a65\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        }
      ],
      "source": [
        "# === Passo 3B-2: CatBoost mais agressivo (Bayesian bootstrap) + meta LogisticRegression (L2) ===\n",
        "# Objetivo: reduzir overfit mantendo/ganhando Recall Poor e macro; LGBM fixo (2.A), CatBoost mais regularizado.\n",
        "# Orçamento aproximado: ~18 fits (ES CatBoost CV=5 ≈ 5 + Stacking CV=5 ≈ 13).\n",
        "\n",
        "\n",
        "def _best_iters_catboost(X, y, base_params, n_splits=5, patience=45, random_state=42):\n",
        "    \"\"\"Estimativa de iterations ótima para CatBoost via CV com early stopping (compatível com pandas/NumPy).\"\"\"\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    best_iters = []\n",
        "    for tr_idx, va_idx in skf.split(X, y):\n",
        "        X_tr, X_va = (X.iloc[tr_idx], X.iloc[va_idx]) if hasattr(X, \"iloc\") else (X[tr_idx], X[va_idx])\n",
        "        y_tr, y_va = (y.iloc[tr_idx], y.iloc[va_idx]) if hasattr(y, \"iloc\") else (y[tr_idx], y[va_idx])\n",
        "\n",
        "        cb = CatBoostClassifier(**base_params)\n",
        "        cb.fit(\n",
        "            X_tr, y_tr,\n",
        "            eval_set=(X_va, y_va),\n",
        "            verbose=False,\n",
        "            early_stopping_rounds=patience,\n",
        "            use_best_model=True\n",
        "        )\n",
        "        it = cb.get_best_iteration()\n",
        "        best_iters.append(int(it if it is not None and it > 0 else base_params.get(\"iterations\", 1200)))\n",
        "    # Mediana para robustez entre folds\n",
        "    return int(sorted(best_iters)[len(best_iters)//2])\n",
        "\n",
        "with mlflow.start_run(run_name=\"Stacking_LGBM_CatBoost_LogRegMeta_CatBoostReg_3B2\"):\n",
        "    # --- LGBM fixo (2.A) ---\n",
        "    lgbm_params_2a = dict(\n",
        "        learning_rate=0.1,\n",
        "        colsample_bytree=0.8,\n",
        "        min_split_gain=0.1,\n",
        "        subsample=0.7,\n",
        "        subsample_freq=1,\n",
        "        num_leaves=95,\n",
        "        max_depth=10,\n",
        "        min_child_samples=60,\n",
        "        reg_lambda=1.0,\n",
        "        reg_alpha=0.1,\n",
        "        objective=\"multiclass\",\n",
        "        num_class=3,\n",
        "        random_state=42,\n",
        "        n_estimators=408\n",
        "    )\n",
        "\n",
        "    # --- CatBoost 3B-2: Bayesian bootstrap (sem subsample), mais regularização ---\n",
        "    cat_base_params_3b2 = dict(\n",
        "        iterations=1200,              # upper bound; ES definirá o ótimo\n",
        "        learning_rate=0.05,\n",
        "        depth=7,                      # ↓ profundidade\n",
        "        l2_leaf_reg=12,               # ↑ regularização L2\n",
        "        rsm=0.80,                     # feature sampling\n",
        "        bootstrap_type=\"Bayesian\",    # usa bagging_temperature (sem subsample)\n",
        "        bagging_temperature=1.8,\n",
        "        random_strength=2.5,\n",
        "        border_count=48,              # menos bins -> menor variância\n",
        "        loss_function=\"MultiClass\",\n",
        "        eval_metric=\"TotalF1\",\n",
        "        verbose=0,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # --- Meta-estimador: LogisticRegression (L2) no topo do stacking ---\n",
        "    meta_lr_params = dict(\n",
        "        penalty=\"l2\",\n",
        "        C=1.0,\n",
        "        solver=\"lbfgs\",\n",
        "        max_iter=500,\n",
        "        multi_class=\"auto\",\n",
        "        n_jobs=None\n",
        "    )\n",
        "\n",
        "    # --- Logging de estágio e parâmetros base ---\n",
        "    mlflow.log_param(\"stage\", \"3B2_CatBoost_Bayesian_LogRegMeta\")\n",
        "    for k, v in lgbm_params_2a.items():\n",
        "        mlflow.log_param(f\"lgbm_2A_{k}\", v)\n",
        "    for k, v in cat_base_params_3b2.items():\n",
        "        if k != \"iterations\":\n",
        "            mlflow.log_param(f\"catboost_3B2_{k}\", v)\n",
        "    for k, v in meta_lr_params.items():\n",
        "        mlflow.log_param(f\"meta_lr_{k}\", v)\n",
        "\n",
        "    # --- Early stopping do CatBoost (recalibra iterations) ---\n",
        "    best_cat_iters_3b2 = _best_iters_catboost(\n",
        "        X_train, y_train,\n",
        "        base_params=cat_base_params_3b2,\n",
        "        n_splits=5,\n",
        "        patience=45,\n",
        "        random_state=42\n",
        "    )\n",
        "    mlflow.log_param(\"best_catboost_iterations_3B2\", int(best_cat_iters_3b2))\n",
        "\n",
        "    # --- Montagem do ensemble (LGBM 2.A + CatBoost 3B-2) ---\n",
        "    lgbm_final = LGBMClassifier(**lgbm_params_2a)\n",
        "    catboost_final = CatBoostClassifier(**{**cat_base_params_3b2, \"iterations\": int(best_cat_iters_3b2)})\n",
        "\n",
        "    estimators = [\n",
        "        (\"lgbm\", lgbm_final),\n",
        "        (\"catboost\", catboost_final)\n",
        "    ]\n",
        "\n",
        "    final_estimator = LogisticRegression(**meta_lr_params)\n",
        "\n",
        "    stacking_clf_3b2 = StackingClassifier(\n",
        "        estimators=estimators,\n",
        "        final_estimator=final_estimator,\n",
        "        cv=5,\n",
        "        n_jobs=-1,\n",
        "        passthrough=False\n",
        "    )\n",
        "\n",
        "    # --- Treino e avaliação ---\n",
        "    stacking_clf_3b2.fit(X_train, y_train)\n",
        "\n",
        "    evaluate_and_log_model(\n",
        "        \"stacking\",\n",
        "        \"Stacking LGBM(2A) + CatBoost(3B2 Bayesian + ES) → Meta LR(L2)\",\n",
        "        stacking_clf_3b2,\n",
        "        X_test, y_test\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "b90e717b",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/log-parameter\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando o treinamento do StackingClassifier...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/15 16:29:26 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/get?run_uuid=ca7b04fddf744f22861df1b200e05abf&run_id=ca7b04fddf744f22861df1b200e05abf\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Treinamento concluído.\n",
            "Avaliando o modelo final...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0f9ccfc06a14437be5564d4d09b792a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Avaliação do Modelo: Stacking LGBM(2A) + CatBoost(H1 + ES) -> RF meta ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.763     0.819     0.790      8805\n",
            "           1      0.820     0.774     0.796     15873\n",
            "           2      0.723     0.758     0.740      5322\n",
            "\n",
            "    accuracy                          0.784     30000\n",
            "   macro avg      0.769     0.784     0.776     30000\n",
            "weighted avg      0.786     0.784     0.785     30000\n",
            "\n",
            "Recall da classe 0 (Poor): 0.819\n",
            "Acurácia de Treino: 0.919\n",
            "🏃 View run Stacking_LGBM_CatBoostH1_RFMeta at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/ca7b04fddf744f22861df1b200e05abf\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "\n",
            "Processo finalizado.\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# === FUNÇÃO HELPER PARA OTIMIZAÇÃO DE ITERAÇÕES ================================\n",
        "# ==============================================================================\n",
        "\n",
        "def _best_iters_catboost(X, y, base_params, n_splits=5, patience=45, random_state=42):\n",
        "    \"\"\"Reestima o melhor 'iterations' para CatBoost via CV + early stopping.\"\"\"\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    best_iters = []\n",
        "    for tr_idx, va_idx in skf.split(X, y):\n",
        "        X_tr, X_va = (X.iloc[tr_idx], X.iloc[va_idx]) if hasattr(X, \"iloc\") else (X[tr_idx], X[va_idx])\n",
        "        y_tr, y_va = (y.iloc[tr_idx], y.iloc[va_idx]) if hasattr(y, \"iloc\") else (y[tr_idx], y[va_idx])\n",
        "\n",
        "        cb = CatBoostClassifier(**base_params)\n",
        "        cb.fit(\n",
        "            X_tr, y_tr,\n",
        "            eval_set=(X_va, y_va),\n",
        "            verbose=False,\n",
        "            early_stopping_rounds=patience,\n",
        "            use_best_model=True\n",
        "        )\n",
        "        it = cb.get_best_iteration()\n",
        "        best_iters.append(int(it if it is not None and it > 0 else base_params.get(\"iterations\", 1200)))\n",
        "    # Retorna a mediana para um resultado mais robusto\n",
        "    return int(sorted(best_iters)[len(best_iters)//2])\n",
        "\n",
        "# ==============================================================================\n",
        "# === PIPELINE DE STACKING =====================================================\n",
        "# ==============================================================================\n",
        "\n",
        "RUN_NAME = \"Stacking_LGBM_CatBoostH1_RFMeta\"\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "with mlflow.start_run(run_name=RUN_NAME):\n",
        "\n",
        "    # --- 1. Definição dos Parâmetros dos Modelos Base ---\n",
        "\n",
        "    # LGBM fixo (parâmetros do modelo 2.A do script de referência)\n",
        "    lgbm_params_2a = dict(\n",
        "        learning_rate=0.1,\n",
        "        colsample_bytree=0.8,\n",
        "        min_split_gain=0.1,\n",
        "        subsample=0.7,\n",
        "        subsample_freq=1,\n",
        "        num_leaves=95,\n",
        "        max_depth=10,\n",
        "        min_child_samples=60,\n",
        "        reg_lambda=1.0,\n",
        "        reg_alpha=0.1,\n",
        "        objective=\"multiclass\",\n",
        "        num_class=3,\n",
        "        random_state=RANDOM_STATE,\n",
        "        n_estimators=408  # Valor fixo do script de referência\n",
        "    )\n",
        "\n",
        "    # CatBoost com os parâmetros que você solicitou (do seu modelo H1)\n",
        "    cat_params_h1 = dict(\n",
        "        loss_function='MultiClass',\n",
        "        eval_metric='TotalF1',\n",
        "        depth=8,\n",
        "        l2_leaf_reg=10.0,\n",
        "        rsm=0.8,\n",
        "        bagging_temperature=0.5,\n",
        "        random_strength=1.8,\n",
        "        border_count=32,\n",
        "        learning_rate=0.05,\n",
        "        random_state=RANDOM_STATE,\n",
        "        verbose=0,\n",
        "        thread_count=-1,\n",
        "        # Adicionado para compatibilidade com a lógica de ES\n",
        "        bootstrap_type='Bayesian' # Assumido, pois usa bagging_temperature\n",
        "    )\n",
        "\n",
        "    # --- 2. Otimização e Logging ---\n",
        "\n",
        "    mlflow.log_param(\"stage\", \"Stacking_LGBM_2A_vs_CatBoost_H1_RFMeta\")\n",
        "    mlflow.log_params({f\"lgbm_2A_{k}\": v for k, v in lgbm_params_2a.items()})\n",
        "    mlflow.log_params({f\"catboost_H1_{k}\": v for k, v in cat_params_h1.items()})\n",
        "\n",
        "    # Early stopping do CatBoost para encontrar as iterações ótimas\n",
        "    cat_params_for_es = cat_params_h1.copy()\n",
        "    cat_params_for_es['iterations'] = 2000 # Teto alto para o ES\n",
        "    best_cat_iters_h1 = _best_iters_catboost(\n",
        "        X_train, y_train,\n",
        "        base_params=cat_params_for_es,\n",
        "        n_splits=5,\n",
        "        patience=45,\n",
        "        random_state=RANDOM_STATE\n",
        "    )\n",
        "    mlflow.log_param(\"best_catboost_iterations_H1\", int(best_cat_iters_h1))\n",
        "\n",
        "    # --- 3. Construção e Treinamento do Stacking ---\n",
        "\n",
        "    # Define os estimadores finais com os parâmetros corretos\n",
        "    lgbm_final = LGBMClassifier(**lgbm_params_2a)\n",
        "    catboost_final = CatBoostClassifier(**{**cat_params_h1, \"iterations\": int(best_cat_iters_h1)})\n",
        "\n",
        "    estimators = [\n",
        "        (\"lgbm\", lgbm_final),\n",
        "        (\"catboost\", catboost_final)\n",
        "    ]\n",
        "\n",
        "    # Define o meta-learner, conforme o script de referência\n",
        "    final_estimator = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=3,\n",
        "        random_state=RANDOM_STATE,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    # Cria e treina o StackingClassifier\n",
        "    stacking_clf = StackingClassifier(\n",
        "        estimators=estimators,\n",
        "        final_estimator=final_estimator,\n",
        "        cv=5,\n",
        "        n_jobs=-1,\n",
        "        passthrough=False,\n",
        "        stack_method='predict_proba'\n",
        "    )\n",
        "\n",
        "    print(\"Iniciando o treinamento do StackingClassifier...\")\n",
        "    stacking_clf.fit(X_train, y_train)\n",
        "    print(\"Treinamento concluído.\")\n",
        "\n",
        "    # --- 4. Avaliação Final ---\n",
        "\n",
        "    print(\"Avaliando o modelo final...\")\n",
        "    evaluate_and_log_model(\n",
        "        \"stacking\",\n",
        "        \"Stacking LGBM(2A) + CatBoost(H1 + ES) -> RF meta\",\n",
        "        stacking_clf,\n",
        "        X_test, y_test\n",
        "    )\n",
        "\n",
        "print(\"\\nProcesso finalizado.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3389b0fc",
      "metadata": {
        "id": "3389b0fc"
      },
      "source": [
        "### Conclusão (fechamento da fase atual)\n",
        "\n",
        "Champion para seguir: Stacking com LGBM (2A) + CatBoost (3B1) + meta RF.\n",
        "\n",
        "Por quê: melhorou Recall Poor (0,829 vs 0,818) e macro recall (0,788 vs 0,783) com pequeno custo em overfit (train 0,925 vs 0,919).\n",
        "\n",
        "2A segue como baseline robusto (gap menor), útil para comparação.\n",
        "\n",
        "3B2 foi descartado (queda forte no Recall Poor).\n",
        "\n",
        "Sendo um modelo de stacking, sua complexidade é maior. No entanto, o ganho de performance justifica essa complexidade. A combinação de LightGBM, CatBoost e Random Forest como meta-learner parece ter criado um ensemble poderoso e generalista.\n",
        "Em resumo, este modelo oferece a maior segurança de que tomará as decisões corretas na maior parte do tempo, minimizando tanto o risco de conceder crédito a maus pagadores quanto a perda de oportunidade ao negar crédito a bons pagadores."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdc7d2a5",
      "metadata": {
        "id": "cdc7d2a5"
      },
      "source": [
        "## Otimizar XGBoost para empilhar\n",
        "\n",
        "Objetivo: obter um XGB parcimonioso e complementar (árvores rasas, subsampling, L1/L2), não “bater” LGBM/CatBoost sozinho.\n",
        "\n",
        "Método (Passo A): early stopping via CV para calibrar n_estimators.\n",
        "\n",
        "Critérios de aceite (solo): Recall Poor ~0,78–0,80, treino ≤ 0,92, boa diversidade vs. LGBM/CatBoost.\n",
        "\n",
        "Depois (Passo B opcional): random search pequeno (12×CV=3), refazendo ES no vencedor.\n",
        "\n",
        "Empilhamento: incluir XGB como 3º base e reavaliar; depois calibração + thresholds.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a64d6482",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "3afff0eab81849a3aa50766c098d70da"
          ]
        },
        "id": "a64d6482",
        "outputId": "cba3d3a3-3484-47fc-b206-0b98935b617e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n",
            "2025/08/29 17:03:58 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/get?run_uuid=3284af96eb7e4d7d880d2a24bd3fef9f&run_id=3284af96eb7e4d7d880d2a24bd3fef9f\n",
            "2025/08/29 17:09:37 INFO mlflow.sklearn.utils: Logging the 5 best runs, 7 runs will be omitted.\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/log-parameter\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3afff0eab81849a3aa50766c098d70da",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Avaliação do Modelo: XGBoost_2Stage_RS3_Top3CV5_CVbest ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.788     0.783     0.785      8805\n",
            "           1      0.793     0.816     0.804     15873\n",
            "           2      0.760     0.702     0.730      5322\n",
            "\n",
            "    accuracy                          0.786     30000\n",
            "   macro avg      0.780     0.767     0.773     30000\n",
            "weighted avg      0.785     0.786     0.785     30000\n",
            "\n",
            "Recall da classe 0 (Poor): 0.783\n",
            "Acurácia de Treino: 0.959\n",
            "🏃 View run XGB_2Stage_RS3_Top3CV5_CVbest at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/3284af96eb7e4d7d880d2a24bd3fef9f\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        }
      ],
      "source": [
        "# === XGBoost 2-estágios (com MLflow): RS CV=3 → rechecagem top-3 CV=5 → xgb.cv p/ n_estimators → fit final ===\n",
        "# Objetivo: obter XGB parcimonioso e diverso, pronto para entrar no stack. Mantém rastreamento no MLflow.\n",
        "\n",
        "\n",
        "\n",
        "# ---------- Configs ----------\n",
        "RANDOM_STATE = 42\n",
        "N_CLASSES = 3\n",
        "N_ITER_RS = 12          # RS enxuto (CV=3)\n",
        "CV_RS = 3               # 1º estágio\n",
        "CV_CHECK = 5            # rechecagem dos top-3\n",
        "ES_ROUNDS = 40          # early stopping no xgb.cv\n",
        "MAX_BOOST_ROUNDS = 1000\n",
        "\n",
        "# Scorer principal\n",
        "recall_macro_scorer = make_scorer(recall_score, average=\"macro\", zero_division=0)\n",
        "\n",
        "# Histórico do seu XGB anterior (para rastreio no MLflow)\n",
        "prev_best = dict(max_depth=9, min_child_weight=3, subsample=1.0,\n",
        "                 colsample_bytree=0.8, learning_rate=0.1, n_estimators=100)\n",
        "\n",
        "# Estimador base (regularizado/diverso vs. anterior) — n_estimators moderado p/ RS\n",
        "xgb_base_fixed = XGBClassifier(\n",
        "    objective=\"multi:softprob\",\n",
        "    eval_metric=\"mlogloss\",\n",
        "    tree_method=\"hist\",\n",
        "    learning_rate=0.08,     # antigo: 0.10\n",
        "    max_depth=6,            # antigo: 9\n",
        "    min_child_weight=8,     # antigo: 3\n",
        "    subsample=0.8,          # antigo: 1.0\n",
        "    colsample_bytree=0.8,   # igual\n",
        "    reg_lambda=2.0,         # L2\n",
        "    reg_alpha=0.1,          # L1 leve\n",
        "    gamma=0.05,             # ganho mínimo\n",
        "    n_estimators=350,       # moderado; o ótimo virá do xgb.cv\n",
        "    random_state=RANDOM_STATE,\n",
        "    n_jobs=-1,\n",
        "    verbosity=0\n",
        ")\n",
        "\n",
        "# Espaço de busca (pequeno e focado)\n",
        "param_distributions = {\n",
        "    \"max_depth\":         [4, 5, 6, 7],\n",
        "    \"min_child_weight\":  [6, 8, 10, 12],\n",
        "    \"subsample\":         [0.7, 0.8, 0.9],\n",
        "    \"colsample_bytree\":  [0.7, 0.8, 0.9],\n",
        "    \"learning_rate\":     [0.05, 0.08, 0.10],\n",
        "    \"reg_lambda\":        [1.0, 2.0, 3.0, 5.0],\n",
        "    \"reg_alpha\":         [0.0, 0.1, 0.2, 0.4],\n",
        "    \"gamma\":             [0.0, 0.05, 0.1, 0.2],\n",
        "}\n",
        "\n",
        "with mlflow.start_run(run_name=\"XGB_2Stage_RS3_Top3CV5_CVbest\"):\n",
        "    # Metadados gerais\n",
        "    mlflow.log_param(\"stage\", \"XGB_2Stage_RS3_TOP3CV5_CVbest\")\n",
        "    mlflow.log_param(\"rs_n_iter\", N_ITER_RS)\n",
        "    mlflow.log_param(\"rs_cv\", CV_RS)\n",
        "    mlflow.log_param(\"check_cv\", CV_CHECK)\n",
        "    mlflow.log_param(\"xgbcv_es_rounds\", ES_ROUNDS)\n",
        "    for k, v in prev_best.items():\n",
        "        mlflow.log_param(f\"xgb_prev_best_{k}\", v)\n",
        "\n",
        "    # ---------- Estágio 1: RandomizedSearchCV (CV=3) ----------\n",
        "    skf_rs = StratifiedKFold(n_splits=CV_RS, shuffle=True, random_state=RANDOM_STATE)\n",
        "    rs = RandomizedSearchCV(\n",
        "        estimator=xgb_base_fixed,\n",
        "        param_distributions=param_distributions,\n",
        "        n_iter=N_ITER_RS,\n",
        "        scoring=recall_macro_scorer,\n",
        "        cv=skf_rs,\n",
        "        random_state=RANDOM_STATE,\n",
        "        n_jobs=-1,\n",
        "        verbose=1,\n",
        "        refit=True,                 # refit com n_estimators=350\n",
        "        return_train_score=False\n",
        "    )\n",
        "    rs.fit(X_train, y_train)\n",
        "\n",
        "    # Log básicos do RS\n",
        "    mlflow.log_metric(\"rs_cv3_best_recall_macro\", float(rs.best_score_))\n",
        "    for k, v in rs.best_params_.items():\n",
        "        mlflow.log_param(f\"rs_cv3_best_{k}\", v)\n",
        "\n",
        "    # Artefatos: resultados completos do RS\n",
        "    rs_df = pd.DataFrame(rs.cv_results_).sort_values(\"mean_test_score\", ascending=False)\n",
        "    rs_top3 = rs_df.head(3).copy()\n",
        "    rs_all_path = \"xgb_rs_cv3_results.csv\"\n",
        "    rs_top3_path = \"xgb_rs_cv3_top3.csv\"\n",
        "    rs_df.to_csv(rs_all_path, index=False)\n",
        "    rs_top3.to_csv(rs_top3_path, index=False)\n",
        "    mlflow.log_artifact(rs_all_path, artifact_path=\"random_search\")\n",
        "    mlflow.log_artifact(rs_top3_path, artifact_path=\"random_search\")\n",
        "\n",
        "    # ---------- Estágio 2: Rechecagem dos top-3 com CV=5 ----------\n",
        "    skf_check = StratifiedKFold(n_splits=CV_CHECK, shuffle=True, random_state=RANDOM_STATE)\n",
        "    top3_params = [row[\"params\"] for _, row in rs_top3.iterrows()]\n",
        "    cv5_scores = []\n",
        "    for i, p in enumerate(top3_params, start=1):\n",
        "        cand = XGBClassifier(**xgb_base_fixed.get_params())\n",
        "        cand.set_params(**p)\n",
        "        score = cross_val_score(\n",
        "            cand, X_train, y_train,\n",
        "            cv=skf_check,\n",
        "            scoring=recall_macro_scorer,\n",
        "            n_jobs=-1\n",
        "        ).mean()\n",
        "        cv5_scores.append(score)\n",
        "        mlflow.log_metric(f\"top{i}_cv5_recall_macro\", float(score))\n",
        "\n",
        "    best_idx = int(np.argmax(cv5_scores))\n",
        "    best_params_cv5 = top3_params[best_idx]\n",
        "    mlflow.log_param(\"selected_from_top3_idx\", best_idx + 1)\n",
        "    for k, v in best_params_cv5.items():\n",
        "        mlflow.log_param(f\"cv5_selected_{k}\", v)\n",
        "\n",
        "    # ---------- Estágio 3: xgboost.cv para n_estimators ótimo ----------\n",
        "    # Mapeia hiperparâmetros do melhor candidato para o formato do booster\n",
        "    best_full = {**xgb_base_fixed.get_params(), **best_params_cv5}\n",
        "    booster_params = {\n",
        "        \"objective\": \"multi:softprob\",\n",
        "        \"num_class\": N_CLASSES,\n",
        "        \"eval_metric\": \"mlogloss\",\n",
        "        \"eta\": best_full[\"learning_rate\"],\n",
        "        \"max_depth\": best_full[\"max_depth\"],\n",
        "        \"min_child_weight\": best_full[\"min_child_weight\"],\n",
        "        \"subsample\": best_full[\"subsample\"],\n",
        "        \"colsample_bytree\": best_full[\"colsample_bytree\"],\n",
        "        \"lambda\": best_full[\"reg_lambda\"],\n",
        "        \"alpha\": best_full[\"reg_alpha\"],\n",
        "        \"gamma\": best_full[\"gamma\"],\n",
        "        \"tree_method\": best_full.get(\"tree_method\", \"hist\"),\n",
        "        \"verbosity\": 0,\n",
        "        \"seed\": RANDOM_STATE,\n",
        "    }\n",
        "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "    cv_res = xgb.cv(\n",
        "        params=booster_params,\n",
        "        dtrain=dtrain,\n",
        "        num_boost_round=MAX_BOOST_ROUNDS,\n",
        "        nfold=CV_CHECK,\n",
        "        early_stopping_rounds=ES_ROUNDS,\n",
        "        stratified=True,\n",
        "        verbose_eval=False,\n",
        "        seed=RANDOM_STATE\n",
        "    )\n",
        "    best_rounds = int(cv_res[\"test-mlogloss-mean\"].idxmin() + 1)\n",
        "    mlflow.log_param(\"xgbcv_best_n_estimators\", best_rounds)\n",
        "\n",
        "    # ---------- Estágio 4: Fit final e avaliação ----------\n",
        "    # Evitar duplicatas: use todos os params do best_full e só substitua n_estimators\n",
        "    xgb_final_params = {**best_full, \"n_estimators\": int(best_rounds)}\n",
        "    xgb_final = XGBClassifier(**xgb_final_params)\n",
        "    xgb_final.fit(X_train, y_train, verbose=False)\n",
        "\n",
        "    evaluate_and_log_model(\n",
        "        kind=\"xgboost\",\n",
        "        model_name=\"XGBoost_2Stage_RS3_Top3CV5_CVbest\",\n",
        "        model=xgb_final,\n",
        "        X_test=X_test,\n",
        "        y_test=y_test\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "595333b9",
      "metadata": {
        "id": "595333b9"
      },
      "source": [
        "\n",
        "### XGBoost — Regra do 1-SE no xgb.cv e refit parcimonioso (para uso no stacking)\n",
        "\n",
        "Aplicamos xgb.cv (cv=5, early stopping=40) para obter a curva de mlogloss e selecionar o n_estimators pelo critério 1-SE: escolhe-se o primeiro round cujo erro está dentro de (mínimo + desvio-padrão), priorizando generalização sobre ajuste fino.\n",
        "O modelo usa objective=\"multi:softprob\" (multi-classe), tree_method=\"hist\" e os melhores hiperparâmetros atuais; apenas n_estimators é recalibrado pelo 1-SE.\n",
        "Em seguida, fazemos o refit final com esse número de árvores mais parsimonioso, reduzindo a variância e o risco de overfitting sem alterar a arquitetura.\n",
        "Todo o processo é rastreado no MLflow: parâmetros prévios, rounds mínimo e 1-SE, curva de CV (CSV/PNG) e métricas de avaliação no holdout.\n",
        "A saída é um XGB mais enxuto e estável, pronto para entrar como base learner em um stacking (ou para comparação direta com outras variantes) mantendo foco em recall macro e classe Poor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89d013a8",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "3fea4c37e3bb49db82dbd7b8f4048181"
          ]
        },
        "id": "89d013a8",
        "outputId": "f36958e1-31c8-4252-e368-0ee8629fe3fc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/log-parameter\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3fea4c37e3bb49db82dbd7b8f4048181",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Avaliação do Modelo: XGBoost_CV_1SE_Refit ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.786     0.778     0.782      8805\n",
            "           1      0.791     0.816     0.803     15873\n",
            "           2      0.759     0.699     0.728      5322\n",
            "\n",
            "    accuracy                          0.784     30000\n",
            "   macro avg      0.778     0.764     0.771     30000\n",
            "weighted avg      0.784     0.784     0.783     30000\n",
            "\n",
            "Recall da classe 0 (Poor): 0.778\n",
            "Acurácia de Treino: 0.944\n",
            "[xgb.cv] min_rounds=999, min_logloss=0.550428, std=0.002408\n",
            "[xgb.cv] 1-SE rounds=840, threshold=0.552835 (usar este)\n",
            "🏃 View run XGB_CV_1SE_Refit at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/8fd73cf2e21047b1b39ce1092c9ad13c\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        }
      ],
      "source": [
        "# === XGBoost | Passo 1: aplicar regra do 1-SE no xgb.cv e refazer o fit final com menos árvores ===\n",
        "# Objetivo: reduzir overfit escolhendo um n_estimators mais parcimonioso (≤ melhor round + 1 desvio-padrão).\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "N_CLASSES = 3\n",
        "ES_ROUNDS = 40\n",
        "MAX_BOOST_ROUNDS = 1000\n",
        "\n",
        "# Hiperparâmetros do melhor XGB atual (selecionados na etapa anterior)\n",
        "best_full = dict(\n",
        "    objective=\"multi:softprob\",\n",
        "    eval_metric=\"mlogloss\",\n",
        "    tree_method=\"hist\",\n",
        "    learning_rate=0.1,\n",
        "    max_depth=7,\n",
        "    min_child_weight=6,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.7,\n",
        "    reg_lambda=5.0,\n",
        "    reg_alpha=0.0,\n",
        "    gamma=0.05,\n",
        "    n_estimators=999,   # round mínimo anterior (cv); será substituído pelo 1-SE\n",
        "    random_state=RANDOM_STATE,\n",
        "    n_jobs=-1,\n",
        "    verbosity=0\n",
        ")\n",
        "\n",
        "with mlflow.start_run(run_name=\"XGB_CV_1SE_Refit\"):\n",
        "    mlflow.log_param(\"stage\", \"XGB_CV_1SE_refit\")\n",
        "    for k, v in best_full.items():\n",
        "        mlflow.log_param(f\"xgb_prevsel_{k}\", v)\n",
        "\n",
        "    # 1) xgboost.cv para obter curva de mlogloss e aplicar 1-SE\n",
        "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "    booster_params = {\n",
        "        \"objective\": best_full[\"objective\"],\n",
        "        \"num_class\": N_CLASSES,\n",
        "        \"eval_metric\": best_full[\"eval_metric\"],\n",
        "        \"eta\": best_full[\"learning_rate\"],\n",
        "        \"max_depth\": best_full[\"max_depth\"],\n",
        "        \"min_child_weight\": best_full[\"min_child_weight\"],\n",
        "        \"subsample\": best_full[\"subsample\"],\n",
        "        \"colsample_bytree\": best_full[\"colsample_bytree\"],\n",
        "        \"lambda\": best_full[\"reg_lambda\"],\n",
        "        \"alpha\": best_full[\"reg_alpha\"],\n",
        "        \"gamma\": best_full[\"gamma\"],\n",
        "        \"tree_method\": best_full[\"tree_method\"],\n",
        "        \"verbosity\": 0,\n",
        "        \"seed\": RANDOM_STATE,\n",
        "    }\n",
        "    cv_res = xgb.cv(\n",
        "        params=booster_params,\n",
        "        dtrain=dtrain,\n",
        "        num_boost_round=MAX_BOOST_ROUNDS,\n",
        "        nfold=5,\n",
        "        early_stopping_rounds=ES_ROUNDS,\n",
        "        stratified=True,\n",
        "        verbose_eval=False,\n",
        "        seed=RANDOM_STATE\n",
        "    )\n",
        "\n",
        "    # Índice (0-based) do menor logloss e valores\n",
        "    min_idx = int(cv_res[\"test-mlogloss-mean\"].idxmin())\n",
        "    min_mean = float(cv_res[\"test-mlogloss-mean\"].iloc[min_idx])\n",
        "    min_std  = float(cv_res[\"test-mlogloss-std\"].iloc[min_idx])\n",
        "    threshold = min_mean + min_std\n",
        "\n",
        "    # Regra 1-SE: primeiro round cujo mean ≤ threshold\n",
        "    one_se_idx = int(np.where(cv_res[\"test-mlogloss-mean\"].values <= threshold)[0][0])\n",
        "    # Converter para 1-based (n_estimators)\n",
        "    min_rounds   = min_idx + 1\n",
        "    one_se_rounds = one_se_idx + 1\n",
        "\n",
        "    mlflow.log_param(\"xgbcv_min_rounds\",   min_rounds)\n",
        "    mlflow.log_param(\"xgbcv_min_logloss\",  round(min_mean, 6))\n",
        "    mlflow.log_param(\"xgbcv_min_std\",      round(min_std, 6))\n",
        "    mlflow.log_param(\"xgbcv_1se_rounds\",   one_se_rounds)\n",
        "    mlflow.log_param(\"xgbcv_1se_threshold\", round(threshold, 6))\n",
        "\n",
        "    # Artefatos: curva do CV (csv + png)\n",
        "    with tempfile.TemporaryDirectory() as tmpdir:\n",
        "        curve_path = os.path.join(tmpdir, \"xgb_cv_curve.csv\")\n",
        "        cv_res.to_csv(curve_path, index=True)\n",
        "        mlflow.log_artifact(curve_path, artifact_path=\"xgb_cv\")\n",
        "\n",
        "        plt.figure(figsize=(7,4))\n",
        "        plt.plot(cv_res[\"test-mlogloss-mean\"].values, label=\"test-mlogloss-mean\")\n",
        "        plt.fill_between(\n",
        "            range(len(cv_res)),\n",
        "            cv_res[\"test-mlogloss-mean\"].values - cv_res[\"test-mlogloss-std\"].values,\n",
        "            cv_res[\"test-mlogloss-mean\"].values + cv_res[\"test-mlogloss-std\"].values,\n",
        "            alpha=0.2\n",
        "        )\n",
        "        plt.axvline(min_idx, color=\"tab:orange\", linestyle=\"--\", label=f\"min @ {min_rounds}\")\n",
        "        plt.axvline(one_se_idx, color=\"tab:green\", linestyle=\"--\", label=f\"1-SE @ {one_se_rounds}\")\n",
        "        plt.title(\"xgboost.cv — mlogloss (mean ± std)\")\n",
        "        plt.xlabel(\"round\")\n",
        "        plt.ylabel(\"mlogloss\")\n",
        "        plt.legend()\n",
        "        png_path = os.path.join(tmpdir, \"xgb_cv_curve.png\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(png_path, dpi=120)\n",
        "        plt.close()\n",
        "        mlflow.log_artifact(png_path, artifact_path=\"xgb_cv\")\n",
        "\n",
        "    # 2) Fit final com n_estimators = 1-SE (mais parcimonioso)\n",
        "    xgb_final_params = {**best_full, \"n_estimators\": int(one_se_rounds)}\n",
        "    xgb_final = XGBClassifier(**xgb_final_params)\n",
        "    xgb_final.fit(X_train, y_train, verbose=False)\n",
        "\n",
        "    # 3) Avaliação + logging usando sua função padrão\n",
        "    evaluate_and_log_model(\n",
        "        kind=\"xgboost\",\n",
        "        model_name=\"XGBoost_CV_1SE_Refit\",\n",
        "        model=xgb_final,\n",
        "        X_test=X_test,\n",
        "        y_test=y_test\n",
        "    )\n",
        "\n",
        "    # Prints úteis no console\n",
        "    print(f\"[xgb.cv] min_rounds={min_rounds}, min_logloss={min_mean:.6f}, std={min_std:.6f}\")\n",
        "    print(f\"[xgb.cv] 1-SE rounds={one_se_rounds}, threshold={threshold:.6f} (usar este)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36db200f",
      "metadata": {},
      "source": [
        "Resultados com alto overfit "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43b0ad20",
      "metadata": {
        "id": "43b0ad20"
      },
      "source": [
        "## Xgboost como alvo ,nao para stack"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3NfaZSuAa6Ui",
      "metadata": {
        "id": "3NfaZSuAa6Ui"
      },
      "source": [
        "###  XGBoost alvo — Rodada 1/2 (gbtree) com RandomizedSearchCV enxuto\n",
        "\n",
        "Estratégia: tratar XGBoost como modelo-alvo (não para empilhar) e explorar um baseline gbtree com espaço pequeno porém “extremo” para captar direções claras.\n",
        "Orçamento: 3 configs × CV=5 = 15 fits, priorizando recall_macro (negócio) e observando o recall da classe 0 (Poor)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GsX41AwsaSez",
      "metadata": {
        "id": "GsX41AwsaSez"
      },
      "outputs": [],
      "source": [
        "# === XGBoost alvo — Rodada 1/2 (gbtree apenas): RandomizedSearchCV enxuto (n_iter=3, CV=5) ===\n",
        "# Objetivo: 3 configs × 5 folds = 15 fits. Espaço pequeno, porém “extremo”, só para gbtree.\n",
        "\n",
        "\n",
        "with mlflow.start_run(run_name=\"XGB_Target_Round1_gbtree_RS3_CV5\"):\n",
        "    mlflow.log_param(\"stage\", \"XGB_target_round1_gbtree\")\n",
        "    mlflow.log_param(\"search_n_iter\", 3)\n",
        "    mlflow.log_param(\"search_cv\", 5)\n",
        "\n",
        "    xgb_base = XGBClassifier(\n",
        "        objective=\"multi:softprob\",\n",
        "        num_class=3,\n",
        "        tree_method=\"hist\",\n",
        "        eval_metric=\"mlogloss\",\n",
        "        booster=\"gbtree\",         # sem DART nesta rodada\n",
        "        grow_policy=\"depthwise\",  # sem lossguide nesta rodada\n",
        "        n_jobs=-1,\n",
        "        random_state=42,\n",
        "        verbosity=0,\n",
        "    )\n",
        "\n",
        "    # Espaço direcional (extremos úteis), sem DART/lossguide\n",
        "    param_distributions = {\n",
        "        \"max_depth\":        [5, 7],\n",
        "        \"min_child_weight\": [8, 12],\n",
        "        \"gamma\":            [0.0, 0.20],\n",
        "        \"reg_lambda\":       [3.0, 8.0],\n",
        "        \"reg_alpha\":        [0.0, 0.4],\n",
        "        \"subsample\":        [0.65, 0.85],\n",
        "        \"colsample_bytree\": [0.65, 0.85],\n",
        "        \"learning_rate\":    [0.05, 0.08],\n",
        "        \"n_estimators\":     [400, 800],\n",
        "    }\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    search = RandomizedSearchCV(\n",
        "        estimator=xgb_base,\n",
        "        param_distributions=param_distributions,\n",
        "        n_iter=3,                   # 15 fits no total\n",
        "        scoring=\"recall_macro\",\n",
        "        cv=skf,\n",
        "        n_jobs=-1,\n",
        "        verbose=1,\n",
        "        random_state=42,\n",
        "        refit=True,                 # refita no treino completo com o melhor set\n",
        "        return_train_score=False,\n",
        "    )\n",
        "\n",
        "    search.fit(X_train, y_train)\n",
        "\n",
        "    # Logging do melhor resultado e grade completa\n",
        "    mlflow.log_metric(\"best_cv_recall_macro\", float(search.best_score_))\n",
        "    for k, v in search.best_params_.items():\n",
        "        mlflow.log_param(f\"best_{k}\", v)\n",
        "\n",
        "    cv_df = pd.DataFrame(search.cv_results_).sort_values(\"mean_test_score\", ascending=False)\n",
        "    cv_df_path = \"xgb_round1_gbtree_rs3_cv5_results.csv\"\n",
        "    cv_df.to_csv(cv_df_path, index=False)\n",
        "    mlflow.log_artifact(cv_df_path, artifact_path=\"round1_results\")\n",
        "\n",
        "    # Avaliação final padronizada no teste\n",
        "    best_model = search.best_estimator_\n",
        "    evaluate_and_log_model(\n",
        "        kind=\"xgboost\",\n",
        "        model_name=\"XGB_Target_Round1_gbtree_RS3_CV5_Best\",\n",
        "        model=best_model,\n",
        "        X_test=X_test,\n",
        "        y_test=y_test\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2UYob3YaO2z",
      "metadata": {
        "id": "d2UYob3YaO2z"
      },
      "source": [
        "### XGBoost alvo — DART “single shot” (treino direto, sem CV/ES)\n",
        "\n",
        "Estratégia rápida para medir ganho potencial do DART no recall (especialmente classe 0 – Poor) sem custo alto de busca.\n",
        "Usa dropout de árvores (booster=\"dart\", rate_drop, skip_drop, normalize_type=\"tree\") para reduzir correlações entre árvores e variância.\n",
        "Limitação consciente: sem CV/ES → resultado mais ruidoso; se promissor, evoluir para CV + early stopping antes de consolidar.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dfc38b7",
      "metadata": {
        "id": "3dfc38b7"
      },
      "outputs": [],
      "source": [
        "# === XGBoost alvo — DART “single shot” (sem CV/ES): treino direto e avaliação ===\n",
        "# Objetivo: testar rapidamente se DART entrega ganho em Recall da classe 0 sem custar tempo excessivo.\n",
        "\n",
        "\n",
        "with mlflow.start_run(run_name=\"XGB_DART_SingleShot_Directional\"):\n",
        "    mlflow.log_param(\"stage\", \"XGB_dart_single_shot\")\n",
        "\n",
        "    # Configuração direcional (ajustes focados em generalização)\n",
        "    dart_params = dict(\n",
        "        objective=\"multi:softprob\",\n",
        "        num_class=3,\n",
        "        eval_metric=\"mlogloss\",\n",
        "        tree_method=\"hist\",     # Se estiver com GPU disponível, pode alternar para \"gpu_hist\"\n",
        "        booster=\"dart\",\n",
        "        normalize_type=\"tree\",\n",
        "        rate_drop=0.15,\n",
        "        skip_drop=0.50,\n",
        "        # Capacidade/regularização\n",
        "        max_depth=7,\n",
        "        min_child_weight=10,\n",
        "        gamma=0.10,\n",
        "        reg_lambda=6.0,\n",
        "        reg_alpha=0.3,\n",
        "        # Amostragem\n",
        "        subsample=0.75,\n",
        "        colsample_bytree=0.75,\n",
        "        # Regime de treino\n",
        "        learning_rate=0.08,\n",
        "        n_estimators=400,       # 350–500 sugerido; começamos com 400 para rapidez\n",
        "        # Misc\n",
        "        n_jobs=-1,\n",
        "        random_state=42,\n",
        "        verbosity=0,\n",
        "    )\n",
        "\n",
        "    # Log dos parâmetros para rastreabilidade\n",
        "    mlflow.log_params({f\"dart_{k}\": v for k, v in dart_params.items()})\n",
        "\n",
        "    # Treino direto (sem early stopping / sem CV)\n",
        "    xgb_dart = XGBClassifier(**dart_params)\n",
        "    xgb_dart.fit(X_train, y_train)\n",
        "\n",
        "    # Avaliação padronizada + logging (inclui training_accuracy_score_manual e artefatos)\n",
        "    evaluate_and_log_model(\n",
        "        kind=\"xgboost\",\n",
        "        model_name=\"XGB_DART_SingleShot\",\n",
        "        model=xgb_dart,\n",
        "        X_test=X_test,\n",
        "        y_test=y_test\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "n9wF7z_zaff5",
      "metadata": {
        "id": "n9wF7z_zaff5"
      },
      "source": [
        "### XGBoost alvo — lossGUIDE “probe” (RS n=1, CV=5) para direção de generalização\n",
        "\n",
        "Exploramos grow_policy=lossguide (crescimento por nó com controle por max_leaves) como alternativa ao depthwise, visando reduzir variância mantendo capacidade de separar Poor.\n",
        "Orçamento mínimo: 1 amostra × CV=5 = 5 fits (apenas um “ponto” na grade), suficiente para testar a direção sem custo alto; refit=True reentreina no treino completo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "p4PSwTDFadzS",
      "metadata": {
        "id": "p4PSwTDFadzS"
      },
      "outputs": [],
      "source": [
        "# === XGBoost alvo — Rodada 2 (parte 2): lossGUIDE-only (n_iter=1, CV=5) ===\n",
        "\n",
        "with mlflow.start_run(run_name=\"XGB_Target_Round2_LOSSGUIDE_RS1_CV5\"):\n",
        "    mlflow.log_param(\"stage\", \"XGB_target_round2_lossguide_only\")\n",
        "    mlflow.log_param(\"search_n_iter\", 1)\n",
        "    mlflow.log_param(\"search_cv\", 5)\n",
        "\n",
        "    xgb_loss = XGBClassifier(\n",
        "        objective=\"multi:softprob\",\n",
        "        num_class=3,\n",
        "        tree_method=\"hist\",\n",
        "        eval_metric=\"mlogloss\",\n",
        "        booster=\"gbtree\",\n",
        "        grow_policy=\"lossguide\",\n",
        "        n_jobs=-1,\n",
        "        random_state=42,\n",
        "        verbosity=0,\n",
        "    )\n",
        "\n",
        "    param_distributions = {\n",
        "        \"n_estimators\":     [400, 600],\n",
        "        \"learning_rate\":    [0.05, 0.08],\n",
        "        \"max_leaves\":       [32, 64],\n",
        "        \"max_depth\":        [7, 8],\n",
        "        \"min_child_weight\": [8, 12],\n",
        "        \"gamma\":            [0.10, 0.20],\n",
        "        \"reg_lambda\":       [5.0, 8.0],\n",
        "        \"reg_alpha\":        [0.2, 0.4],\n",
        "        \"subsample\":        [0.70, 0.85],\n",
        "        \"colsample_bytree\": [0.70, 0.85],\n",
        "    }\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    search = RandomizedSearchCV(\n",
        "        estimator=xgb_loss,\n",
        "        param_distributions=param_distributions,\n",
        "        n_iter=1,                  # 1 x 5 = 5 fits\n",
        "        scoring=\"recall_macro\",\n",
        "        cv=skf,\n",
        "        n_jobs=-1,\n",
        "        verbose=1,\n",
        "        random_state=42,\n",
        "        refit=True,\n",
        "        return_train_score=False,\n",
        "    )\n",
        "    search.fit(X_train, y_train)\n",
        "\n",
        "    mlflow.log_metric(\"lossguide_best_cv_recall_macro\", float(search.best_score_))\n",
        "    for k, v in search.best_params_.items():\n",
        "        mlflow.log_param(f\"lossguide_best_{k}\", v)\n",
        "\n",
        "    df = pd.DataFrame(search.cv_results_).sort_values(\"mean_test_score\", ascending=False)\n",
        "    csv_path = \"round2_lossguide_rs_results.csv\"\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    mlflow.log_artifact(csv_path, artifact_path=\"round2_lossguide_only\")\n",
        "\n",
        "    best_model = search.best_estimator_\n",
        "    evaluate_and_log_model(\n",
        "        kind=\"xgboost\",\n",
        "        model_name=\"XGB_Target_Round2_LOSSGUIDE_RS1_CV5_Best\",\n",
        "        model=best_model,\n",
        "        X_test=X_test,\n",
        "        y_test=y_test\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qzzZFMHWjZ76",
      "metadata": {
        "id": "qzzZFMHWjZ76"
      },
      "source": [
        "### Avaliando Resultados\n",
        "\n",
        "Conclusão  XGBoost como alvo/stack base\n",
        "\n",
        "Resumo por variante\n",
        "\n",
        "gbtree (Round1): Recall Poor 0,731, F1_macro 0,732, treino 0,838 → razoável, porém abaixo do necessário para o caso de uso.\n",
        "\n",
        "lossguide: Recall Poor 0,712, F1_macro 0,721, treino 0,807 → intermediário; não supera gbtree.\n",
        "\n",
        "DART: Recall Poor 0,700, F1_macro 0,708, treino 0,789 → mais fraco, tendência a subajuste.\n",
        "\n",
        "Comparativo com baseline\n",
        "\n",
        "Stack LGBM+CatBoost entrega Recall Poor ~0,818–0,821 com macro e accuracy superiores — margem clara sobre todos os XGB testados.\n",
        "\n",
        "Leitura\n",
        "\n",
        "Os XGB avaliados exibem viés alto na classe 0 e não atingem o patamar do stack atual.\n",
        "\n",
        "Como base no stacking, só fariam sentido se agregassem diversidade útil (probabilidades pouco correlacionadas) sem degradar; com Recall Poor baixo, a chance de ganho é pequena.\n",
        "\n",
        "Decisão prática\n",
        "\n",
        "Depriorizar XGB como alvo e como base do stack neste momento."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "T8rm7Pg6nHVS",
      "metadata": {
        "id": "T8rm7Pg6nHVS"
      },
      "source": [
        "## Catboost como alvo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "m4NQx46anQZR",
      "metadata": {
        "id": "m4NQx46anQZR"
      },
      "source": [
        "### CatBoost alvo — C1: baseline anti-overfit com early stopping (eval_set) e autolog ON\n",
        "\n",
        "Objetivo: testar o CatBoost como modelo-alvo com configuração parcimoniosa para conter overfitting, mantendo bom recall (especialmente classe 0 — Poor).\n",
        "Técnica: split interno 90/10 do treino para eval_set e early stopping (od_type=\"Iter\", od_wait=40, use_best_model=True), registrando a melhor iteração encontrada.\n",
        "Regularização estrutural: depth=8 (árvores mais rasas) e l2_leaf_reg=8.0 (L2 ↑) para reduzir variância.\n",
        "Bagging/robustez: bootstrap_type=\"Bayesian\" com bagging_temperature=1.0 e rsm=0.8 (amostragem de colunas); random_strength=1.8 injeta ruído leve nos splits.\n",
        "Regime de treino: iterations=1200, learning_rate=0.05; o ES escolhe o ponto ótimo antes do limite para evitar supertreino."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "iboaOuffnQA5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iboaOuffnQA5",
        "outputId": "2c3e5894-da3b-44ad-a47c-48763b332847"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Avaliação do Modelo: CatBoost Target C1 AntiOverfit ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.756     0.690     0.721      8805\n",
            "           1      0.733     0.796     0.763     15873\n",
            "           2      0.659     0.584     0.619      5322\n",
            "\n",
            "    accuracy                          0.727     30000\n",
            "   macro avg      0.716     0.690     0.701     30000\n",
            "weighted avg      0.727     0.727     0.725     30000\n",
            "\n",
            "Recall da classe 0 (Poor): 0.690\n",
            "Acurácia de Treino: 0.772\n",
            "🏃 View run CatBoost_Target_C1_AntiOverfit_Baseline at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/cb194197453c4127bd96ffe62f1d9480\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        }
      ],
      "source": [
        "# === CatBoost alvo — C1: baseline anti-overfit (ES via eval_set), autolog ON ===\n",
        "\n",
        "\n",
        "with mlflow.start_run(run_name=\"CatBoost_Target_C1_AntiOverfit_Baseline\"):\n",
        "    mlflow.log_param(\"stage\", \"CatBoost_C1_anti_overfit\")\n",
        "\n",
        "    # Split interno p/ early stopping (leve, estratificado)\n",
        "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "        X_train, y_train, test_size=0.1, stratify=y_train, random_state=42\n",
        "    )\n",
        "\n",
        "    # Setup anti-overfit (capacidade ↓, regularização ↑, bagging/colsample)\n",
        "    cb_params = dict(\n",
        "        loss_function=\"MultiClass\",\n",
        "        eval_metric=\"TotalF1\",\n",
        "        iterations=1200,\n",
        "        learning_rate=0.05,\n",
        "        depth=8,                 # ↓ de 10 → 8\n",
        "        l2_leaf_reg=8.0,         # ↑ de 3 → 8\n",
        "        bootstrap_type=\"Bayesian\",\n",
        "        bagging_temperature=1.0,\n",
        "        rsm=0.8,                 # column subsampling\n",
        "        # subsample=0.8,         # (opcional; ignorado em Bayesian, manter comentado)\n",
        "        random_strength=1.8,     # ruído leve p/ robustez\n",
        "        od_type=\"Iter\",\n",
        "        od_wait=40,              # early stopping patience\n",
        "        use_best_model=True,\n",
        "        random_state=42,\n",
        "        verbose=0\n",
        "    )\n",
        "    mlflow.log_params({f\"C1_{k}\": v for k, v in cb_params.items()})\n",
        "\n",
        "    model = CatBoostClassifier(**cb_params)\n",
        "    model.fit(X_tr, y_tr, eval_set=(X_val, y_val), verbose=0)\n",
        "\n",
        "    # Log da melhor iteração encontrada pelo ES (quando disponível)\n",
        "    try:\n",
        "        best_iters = int(model.get_best_iteration())\n",
        "    except Exception:\n",
        "        best_iters = int(getattr(model, \"tree_count_\", 0) or 0)\n",
        "    mlflow.log_param(\"C1_best_iterations\", best_iters)\n",
        "\n",
        "    # Avaliação padronizada (inclui training_accuracy_score_manual)\n",
        "    evaluate_and_log_model(\n",
        "        kind=\"catboost\",\n",
        "        model_name=\"CatBoost Target C1 AntiOverfit\",\n",
        "        model=model,\n",
        "        X_test=X_test,\n",
        "        y_test=y_test\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "T1t4dFgnpJE8",
      "metadata": {
        "id": "T1t4dFgnpJE8"
      },
      "source": [
        "### CatBoost alvo — C2: C1 + class_weights para puxar Recall da classe 0 (anti-overfit, autolog ON)\n",
        "\n",
        "Extensão do C1 adicionando pesos de classe class_weights = [1.8, 1.0, 1.0] para favorecer a classe 0 (Poor) sem alterar a base anti-overfit.\n",
        "Mantém regularização estrutural (depth=8, l2_leaf_reg=8.0), amostragem (bootstrap_type=\"Bayesian\", bagging_temperature=1.0, rsm=0.8) e ruído controlado (random_strength=1.8).\n",
        "Treino com ES em holdout interno 90/10 (od_type=\"Iter\", od_wait=40, use_best_model=True) para parar antes do supertreino; iterations=1200 como teto.\n",
        "Otimização por eval_metric=\"TotalF1\"; avaliação padronizada no holdout final foca Recall_macro e Recall da classe 0.\n",
        "MLflow registra estágio, hiperparâmetros efetivos, C2_best_iterations e métricas/artefatos para comparação direta C1 ↔ C2.\n",
        "Expectativa: elevar Recall_Poor com potencial trade-off moderado em precisão das demais classes, sob controle do pacote anti-overfit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "BlrThxddpH2S",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlrThxddpH2S",
        "outputId": "13eb6f0d-a32e-4b76-d30f-738a889fc303"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Avaliação do Modelo: CatBoost Target C2 AntiOverfit + ClassWeights ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.702     0.812     0.753      8805\n",
            "           1      0.773     0.738     0.755     15873\n",
            "           2      0.682     0.598     0.637      5322\n",
            "\n",
            "    accuracy                          0.735     30000\n",
            "   macro avg      0.719     0.716     0.715     30000\n",
            "weighted avg      0.736     0.735     0.734     30000\n",
            "\n",
            "Recall da classe 0 (Poor): 0.812\n",
            "Acurácia de Treino: 0.792\n",
            "🏃 View run CatBoost_Target_C2_AntiOverfit_ClassWeights at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/fd6658dcc4c8448db17a0cbed5369aee\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        }
      ],
      "source": [
        "# === CatBoost alvo — C2: C1 + class_weights para puxar Recall da classe 0, autolog ON ===\n",
        "\n",
        "with mlflow.start_run(run_name=\"CatBoost_Target_C2_AntiOverfit_ClassWeights\"):\n",
        "    mlflow.log_param(\"stage\", \"CatBoost_C2_anti_overfit_class_weights\")\n",
        "\n",
        "    # Split interno p/ early stopping (mesmo do C1)\n",
        "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "        X_train, y_train, test_size=0.1, stratify=y_train, random_state=42\n",
        "    )\n",
        "\n",
        "    # Mesmos hiperparâmetros do C1 + pesos de classe para favorecer a classe 0 (Poor)\n",
        "    class_weights = [1.8, 1.0, 1.0]  # 0→1.8, 1→1.0, 2→1.0\n",
        "    cb_params = dict(\n",
        "        loss_function=\"MultiClass\",\n",
        "        eval_metric=\"TotalF1\",\n",
        "        iterations=1200,\n",
        "        learning_rate=0.05,\n",
        "        depth=8,\n",
        "        l2_leaf_reg=8.0,\n",
        "        bootstrap_type=\"Bayesian\",\n",
        "        bagging_temperature=1.0,\n",
        "        rsm=0.8,\n",
        "        random_strength=1.8,\n",
        "        od_type=\"Iter\",\n",
        "        od_wait=40,\n",
        "        use_best_model=True,\n",
        "        class_weights=class_weights,\n",
        "        random_state=42,\n",
        "        verbose=0\n",
        "    )\n",
        "    mlflow.log_params({f\"C2_{k}\": v for k, v in cb_params.items() if k != \"class_weights\"})\n",
        "    mlflow.log_param(\"C2_class_weights\", \"0:1.8,1:1.0,2:1.0\")\n",
        "\n",
        "    model = CatBoostClassifier(**cb_params)\n",
        "    model.fit(X_tr, y_tr, eval_set=(X_val, y_val), verbose=0)\n",
        "\n",
        "    # Log da melhor iteração do ES\n",
        "    try:\n",
        "        best_iters = int(model.get_best_iteration())\n",
        "    except Exception:\n",
        "        best_iters = int(getattr(model, \"tree_count_\", 0) or 0)\n",
        "    mlflow.log_param(\"C2_best_iterations\", best_iters)\n",
        "\n",
        "    # Avaliação padronizada (inclui training_accuracy_score_manual)\n",
        "    evaluate_and_log_model(\n",
        "        kind=\"catboost\",\n",
        "        model_name=\"CatBoost Target C2 AntiOverfit + ClassWeights\",\n",
        "        model=model,\n",
        "        X_test=X_test,\n",
        "        y_test=y_test\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UuCzPhM7t8_a",
      "metadata": {
        "id": "UuCzPhM7t8_a"
      },
      "source": [
        "### CatBoost alvo — H1: busca leve ao redor do C2 (anti-overfit fino, RS=6, CV=5)\n",
        "\n",
        "Explora um RandomizedSearchCV enxuto (n_iter=6, cv=5) em torno do C2 (com class_weights=[1.8,1.0,1.0]) para ajuste fino de regularização.\n",
        "Treino com early stopping em eval_set fixo (split 90/10), teto iterations=1500 e od_wait=50 para parar antes do supertreino.\n",
        "Espaço “direcional”: depth {7,8}, l2_leaf_reg {6,8,10,12}, rsm {0.7,0.8,0.9}, bagging_temperature {0.5,1.0,1.5,2.0}, random_strength {1.2,1.8,2.4}, border_count {32,64}, learning_rate {0.04,0.05}.\n",
        "Configuração base: loss_function=MultiClass, eval_metric=TotalF1, bootstrap_type=Bayesian, rsm=0.8 (varrido), random_state=42, threads livres.\n",
        "refit=True reaprende no treino completo com o melhor conjunto mantendo o mesmo eval_set para comparabilidade."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mB-a8CZZt8Tl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB-a8CZZt8Tl",
        "outputId": "0acbf7f4-e524-45b7-e5ab-e0f4f362fe1f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n",
            "2025/09/03 13:16:48 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/get?run_uuid=76bae20797d64a4787cc0e618f8872ad&run_id=76bae20797d64a4787cc0e618f8872ad\n",
            "2025/09/03 13:50:38 INFO mlflow.sklearn.utils: Logging the 5 best runs, one run will be omitted.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏃 View run intrigued-cub-238 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/f1f4a037b2ca4d7686922eb599df112b\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run zealous-stork-320 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/e365879efa0443b9b88db3f0b2bd70a7\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run unequaled-quail-6 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/0f867c24dfb14471864643d992ae9f22\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run omniscient-conch-778 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/5584fe845af44e9bbd141acaf62ae5b1\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run shivering-lynx-443 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/bd816efbb9f74602b3b80b228aef4989\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "=== Avaliação do Modelo: CatBoost_Target_H1_Best ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.716     0.825     0.767      8805\n",
            "           1      0.786     0.753     0.769     15873\n",
            "           2      0.710     0.621     0.663      5322\n",
            "\n",
            "    accuracy                          0.751     30000\n",
            "   macro avg      0.738     0.733     0.733     30000\n",
            "weighted avg      0.752     0.751     0.750     30000\n",
            "\n",
            "Recall da classe 0 (Poor): 0.825\n",
            "Acurácia de Treino: 0.818\n",
            "🏃 View run CatBoost_Target_H1_AroundC2_RS6_CV5 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/76bae20797d64a4787cc0e618f8872ad\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        }
      ],
      "source": [
        "# === CatBoost alvo — H1: busca leve ao redor do C2 (anti-overfit fino, CV=5, n_iter=6 ≈ 30 fits) ===\n",
        "\n",
        "with mlflow.start_run(run_name=\"CatBoost_Target_H1_AroundC2_RS6_CV5\"):\n",
        "    mlflow.log_param(\"stage\", \"CatBoost_H1_around_C2\")\n",
        "\n",
        "    # Split interno fixo para ES (comparabilidade)\n",
        "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "        X_train, y_train, test_size=0.10, stratify=y_train, random_state=42\n",
        "    )\n",
        "\n",
        "    # Base = C2 (classe 0 com peso 1.8) + anti-overfit\n",
        "    cb_base = CatBoostClassifier(\n",
        "        loss_function=\"MultiClass\",\n",
        "        eval_metric=\"TotalF1\",\n",
        "        iterations=1500,          # teto; ES escolhe melhor\n",
        "        learning_rate=0.05,       # pode variar na busca\n",
        "        depth=8,                  # pode variar (7,8)\n",
        "        l2_leaf_reg=8.0,          # será varrido\n",
        "        bootstrap_type=\"Bayesian\",\n",
        "        bagging_temperature=1.0,  # será varrido\n",
        "        rsm=0.8,                  # será varrido\n",
        "        random_strength=1.8,      # será varrido\n",
        "        od_type=\"Iter\",\n",
        "        od_wait=50,               # ES um pouco mais paciente\n",
        "        use_best_model=True,\n",
        "        class_weights=[1.8, 1.0, 1.0],\n",
        "        random_state=42,\n",
        "        verbose=0,\n",
        "        thread_count=-1,\n",
        "    )\n",
        "\n",
        "    # Espaço enxuto, “direcional”, ao redor do C2\n",
        "    param_distributions = {\n",
        "        \"depth\": [7, 8],\n",
        "        \"l2_leaf_reg\": [6.0, 8.0, 10.0, 12.0],\n",
        "        \"rsm\": [0.7, 0.8, 0.9],\n",
        "        \"bagging_temperature\": [0.5, 1.0, 1.5, 2.0],\n",
        "        \"random_strength\": [1.2, 1.8, 2.4],\n",
        "        \"border_count\": [32, 64],\n",
        "        \"learning_rate\": [0.04, 0.05],\n",
        "    }\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    search = RandomizedSearchCV(\n",
        "        estimator=cb_base,\n",
        "        param_distributions=param_distributions,\n",
        "        n_iter=6,                 # 6 x 5 = 30 fits\n",
        "        scoring=\"recall_macro\",\n",
        "        cv=skf,\n",
        "        n_jobs=-1,\n",
        "        verbose=1,\n",
        "        random_state=42,\n",
        "        refit=True,               \n",
        "        return_train_score=False,\n",
        "    )\n",
        "\n",
        "    # Passa eval_set para ES em cada fit (treino e refit)\n",
        "    search.fit(X_tr, y_tr, eval_set=(X_val, y_val), verbose=False)\n",
        "\n",
        "    # Log da busca\n",
        "    mlflow.log_metric(\"H1_best_cv_recall_macro\", float(search.best_score_))\n",
        "    for k, v in search.best_params_.items():\n",
        "        mlflow.log_param(f\"H1_best_{k}\", v)\n",
        "\n",
        "    pd.DataFrame(search.cv_results_).sort_values(\"mean_test_score\", ascending=False)\\\n",
        "        .to_csv(\"catboost_H1_rs6_cv5_results.csv\", index=False)\n",
        "    mlflow.log_artifact(\"catboost_H1_rs6_cv5_results.csv\", artifact_path=\"H1_search\")\n",
        "\n",
        "    # Avaliação final no teste (usa seu helper, que também loga training_accuracy_score_manual)\n",
        "    best_model = search.best_estimator_\n",
        "    evaluate_and_log_model(\n",
        "        kind=\"catboost\",\n",
        "        model_name=\"CatBoost_Target_H1_Best\",\n",
        "        model=best_model,\n",
        "        X_test=X_test,\n",
        "        y_test=y_test\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d0e7593",
      "metadata": {},
      "source": [
        "### CatBoost alvo — H2: ajuste fino do peso da classe 0 (Grid 3×, CV=5)\n",
        "\n",
        "Extensão direta do H1: congelamos os hiperparâmetros vencedores e varremos apenas class_weights para priorizar a classe 0 (Poor) sem reabrir o espaço todo.\n",
        "Configuração: GridSearchCV com 3 pesos ([1.6,1.0,1.2], [1.8,1.0,1.2], [1.6,1.0,1.4]) × CV=5 = 15 fits, scoring em recall_macro.\n",
        "Treino usa early stopping em eval_set fixo (split 90/10) com od_wait=50, garantindo comparabilidade e corte de supertreino.\n",
        "Base anti-overfit (de H1): depth=8, l2_leaf_reg=10, bootstrap_type=Bayesian, bagging_temperature=0.5, rsm=0.8, random_strength=1.8, lr=0.05."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "IpNmg_DF3786",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpNmg_DF3786",
        "outputId": "4ed5ac11-cd44-4823-dab1-862df96319cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/15 10:59:50 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/get?run_uuid=5fc7f3ec254b47f19de8ce50241bf58c&run_id=5fc7f3ec254b47f19de8ce50241bf58c\n",
            "2025/09/15 11:23:53 INFO mlflow.sklearn.utils: Logging the 5 best runs, no runs will be omitted.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏃 View run abundant-perch-722 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/b0281c6432134a278e808582bd79bb0e\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "🏃 View run invincible-jay-225 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/9dcc60945de340409023533c1a31f881\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d9f1e1c5b5f4bedaf6bdad4a5d8e3a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Avaliação do Modelo: CatBoost_Target_H2_Best ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.724     0.800     0.760      8805\n",
            "           1      0.803     0.725     0.762     15873\n",
            "           2      0.642     0.718     0.678      5322\n",
            "\n",
            "    accuracy                          0.746     30000\n",
            "   macro avg      0.723     0.748     0.733     30000\n",
            "weighted avg      0.751     0.746     0.747     30000\n",
            "\n",
            "Recall da classe 0 (Poor): 0.800\n",
            "Acurácia de Treino: 0.803\n",
            "🏃 View run CatBoost_Target_H2_ClassWeights_CV5-Correct at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/5fc7f3ec254b47f19de8ce50241bf58c\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏃 View run selective-moose-347 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/05d33001cc05417595e82ad3975122a8\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/log-batch\n"
          ]
        }
      ],
      "source": [
        "# === CatBoost alvo — H2: ajuste fino do peso da classe 0 (Grid 3x, CV=5 = 15 fits) ===\n",
        "\n",
        "\n",
        "with mlflow.start_run(run_name=\"CatBoost_Target_H2_ClassWeights_CV5-Correct\"):\n",
        "    mlflow.log_param(\"stage\", \"CatBoost_H2_class_weights\")\n",
        "\n",
        "    # Mesmo split para ES\n",
        "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "        X_train, y_train, test_size=0.10, stratify=y_train, random_state=42\n",
        "    )\n",
        "\n",
        "    # Base: copie os melhores do H1 manualmente se quiser “congelar” tudo, exceto o peso.\n",
        "    cb_base = CatBoostClassifier(\n",
        "        loss_function=\"MultiClass\",\n",
        "        eval_metric=\"TotalF1\",\n",
        "        iterations=1500,\n",
        "        learning_rate=0.05,   \n",
        "        depth=8,              \n",
        "        l2_leaf_reg=10.0,      \n",
        "        bootstrap_type=\"Bayesian\",\n",
        "        bagging_temperature= 0.5,\n",
        "        rsm=0.8,\n",
        "        random_strength=1.8,\n",
        "        od_type=\"Iter\",\n",
        "        od_wait=50,\n",
        "        use_best_model=True,\n",
        "        random_state=42,\n",
        "        verbose=0,\n",
        "        thread_count=-1,\n",
        "    )\n",
        "\n",
        "    # Varre apenas o peso da classe 0 (garante 3 x 5 = 15 fits)\n",
        "    param_grid = {\n",
        "        \"class_weights\": [\n",
        "            [1.6, 1.0, 1.2],\n",
        "            [1.8, 1.0, 1.2],\n",
        "            [1.6, 1.0, 1.4],\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    grid = GridSearchCV(\n",
        "        estimator=cb_base,\n",
        "        param_grid=param_grid,\n",
        "        scoring=\"recall_macro\",\n",
        "        cv=skf,\n",
        "        n_jobs=-1,\n",
        "        verbose=1,\n",
        "        refit=True,\n",
        "        return_train_score=False,\n",
        "    )\n",
        "\n",
        "    grid.fit(X_tr, y_tr, eval_set=(X_val, y_val), verbose=False)\n",
        "\n",
        "    # Log da busca\n",
        "    mlflow.log_metric(\"H2_best_cv_recall_macro\", float(grid.best_score_))\n",
        "    mlflow.log_param(\"H2_best_class_weights\", str(grid.best_params_[\"class_weights\"]))\n",
        "\n",
        "    pd.DataFrame(grid.cv_results_).sort_values(\"mean_test_score\", ascending=False)\\\n",
        "        .to_csv(\"catboost_H2_classweights_cv5_results.csv\", index=False)\n",
        "    mlflow.log_artifact(\"catboost_H2_classweights_cv5_results.csv\", artifact_path=\"H2_search\")\n",
        "\n",
        "    # Avaliação final\n",
        "    best_model = grid.best_estimator_\n",
        "    evaluate_and_log_model(\n",
        "        kind=\"catboost\",\n",
        "        model_name=\"CatBoost_Target_H2_Best\",\n",
        "        model=best_model,\n",
        "        X_test=X_test,\n",
        "        y_test=y_test\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e77938db",
      "metadata": {},
      "source": [
        "### CatBoost alvo — HL1: busca “heavy light” ao redor de H1/H2 (RS=15, CV=5) com foco em generalização\n",
        "\n",
        "A cédula amplia levemente o espaço em torno do que funcionou em H1/H2 para subir recall_macro sem perder o ganho em Recall_Poor e sem aumentar a acurácia de treino.\n",
        "Usamos RandomizedSearchCV (n_iter=15, cv=5) com early stopping em eval_set fixo (split 90/10) para encontrar um ponto estável de iterações (teto=1600, od_wait=50).\n",
        "Mantemos a linha anti-overfit: depth∈{7,8}, l2_leaf_reg∈{8,10,12,14}, min_data_in_leaf∈{20,50,100}, Bayesian bootstrap com bagging_temperature∈{0.5,1.0,1.5}, rsm∈{0.70,0.80,0.90}.\n",
        "Incluímos quantização (border_count∈{32,48,64}) e **lr∈{0.04,0.05}para modular capacidade, mantendoclass_weights=[1.6,1.0,1.4](H2). O *refit* usa o **mesmo eval_set** para comparabilidade;random_state=42garante reprodutibilidade. Todo o processo é **rastreado no MLflow**: melhores hiperparâmetros, tabela completa da busca e avaliação em *holdout* viaevaluate_and_log_model`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "GVWwviIXRs_5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVWwviIXRs_5",
        "outputId": "296805af-1e9a-4bfa-9403-173de21dfb17"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/03 15:51:56 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/03 17:24:05 INFO mlflow.sklearn.utils: Logging the 5 best runs, 10 runs will be omitted.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Avaliação do Modelo: CatBoost_Target_HL1_Best ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.713     0.790     0.749      8805\n",
            "           1      0.795     0.713     0.752     15873\n",
            "           2      0.625     0.706     0.663      5322\n",
            "\n",
            "    accuracy                          0.734     30000\n",
            "   macro avg      0.711     0.736     0.721     30000\n",
            "weighted avg      0.741     0.734     0.735     30000\n",
            "\n",
            "Recall da classe 0 (Poor): 0.790\n",
            "Acurácia de Treino: 0.786\n",
            "🏃 View run CatBoost_Target_HL1_RS15_CV5 at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/191a454cecf94841904f13b651897c35\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n"
          ]
        }
      ],
      "source": [
        "# === CatBoost alvo — HL1: busca “heavy light” ao redor do H1/H2 (CV=5, n_iter=15 ≈ 75 fits) ===\n",
        "# Foco: ↑ recall_macro SEM perder o ganho de Recall Poor e SEM subir a acurácia de treino.\n",
        "\n",
        "\n",
        "with mlflow.start_run(run_name=\"CatBoost_Target_HL1_RS15_CV5\"):\n",
        "    mlflow.log_param(\"stage\", \"CatBoost_HL1_heavy_light\")\n",
        "    mlflow.log_param(\"hl1_n_iter\", 15)\n",
        "    mlflow.log_param(\"hl1_cv_splits\", 5)\n",
        "\n",
        "    # Split interno fixo para ES (comparável a H1/H2)\n",
        "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "        X_train, y_train, test_size=0.10, stratify=y_train, random_state=42\n",
        "    )\n",
        "\n",
        "    # Base (partindo do que funcionou em H1/H2) + ES\n",
        "    cb_base = CatBoostClassifier(\n",
        "        loss_function=\"MultiClass\",\n",
        "        eval_metric=\"TotalF1\",\n",
        "        iterations=1600,          # teto; ES escolhe o melhor\n",
        "        learning_rate=0.05,       # pode variar no espaço\n",
        "        depth=8,                  # pode variar (7, 8)\n",
        "        l2_leaf_reg=10.0,         # será varrido\n",
        "        bootstrap_type=\"Bayesian\",\n",
        "        bagging_temperature=0.5,  # será varrido\n",
        "        rsm=0.8,                  # será varrido\n",
        "        random_strength=1.8,      # será varrido\n",
        "        border_count=32,          # será varrido\n",
        "        # regularização estrutural adicional\n",
        "        # (varremos min_data_in_leaf no espaço abaixo)\n",
        "        od_type=\"Iter\",\n",
        "        od_wait=50,               # ES um pouco mais paciente\n",
        "        use_best_model=True,\n",
        "        class_weights=[1.6, 1.0, 1.4],  # melhor do H2\n",
        "        random_state=42,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Espaço “direcional” (enxuto, porém mais amplo que H1)\n",
        "    param_distributions = {\n",
        "        # capacidade / regularização\n",
        "        \"depth\": [7, 8],\n",
        "        \"l2_leaf_reg\": [8.0, 10.0, 12.0, 14.0],\n",
        "        \"min_data_in_leaf\": [20, 50, 100],\n",
        "        \"random_strength\": [1.2, 1.8, 2.4],\n",
        "        # amostragem / colunas\n",
        "        \"bagging_temperature\": [0.5, 1.0, 1.5],\n",
        "        \"rsm\": [0.70, 0.80, 0.90],\n",
        "        # quantização e passo\n",
        "        \"border_count\": [32, 48, 64],\n",
        "        \"learning_rate\": [0.04, 0.05],\n",
        "    }\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    search = RandomizedSearchCV(\n",
        "        estimator=cb_base,\n",
        "        param_distributions=param_distributions,\n",
        "        n_iter=15,                 # 15 x 5 = ~75 fits\n",
        "        scoring=\"recall_macro\",\n",
        "        cv=skf,\n",
        "        n_jobs=-1,\n",
        "        verbose=1,\n",
        "        random_state=42,\n",
        "        refit=True,                # refita com o melhor set (com mesmo eval_set)\n",
        "        return_train_score=False,\n",
        "    )\n",
        "\n",
        "    # Muito importante: passar eval_set para que o ES funcione nos folds e no refit\n",
        "    search.fit(X_tr, y_tr, eval_set=(X_val, y_val), verbose=False)\n",
        "\n",
        "    # Logging do melhor resultado e da tabela completa\n",
        "    mlflow.log_metric(\"HL1_best_cv_recall_macro\", float(search.best_score_))\n",
        "    for k, v in search.best_params_.items():\n",
        "        mlflow.log_param(f\"HL1_best_{k}\", v)\n",
        "\n",
        "    cv_df = pd.DataFrame(search.cv_results_).sort_values(\"mean_test_score\", ascending=False)\n",
        "    csv_path = \"catboost_HL1_rs15_cv5_results.csv\"\n",
        "    cv_df.to_csv(csv_path, index=False)\n",
        "    mlflow.log_artifact(csv_path, artifact_path=\"HL1_search\")\n",
        "\n",
        "    # Avaliação final no teste com seu helper (inclui training_accuracy_score_manual + artefatos)\n",
        "    best_model = search.best_estimator_\n",
        "    evaluate_and_log_model(\n",
        "        kind=\"catboost\",\n",
        "        model_name=\"CatBoost_Target_HL1_Best\",\n",
        "        model=best_model,\n",
        "        X_test=X_test,\n",
        "        y_test=y_test\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db89af81",
      "metadata": {},
      "source": [
        "##"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e6d4449",
      "metadata": {},
      "source": [
        "##  Seleção do Modelo Final para Produção"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19187faa",
      "metadata": {},
      "source": [
        "### 1. Modelo Selecionado\n",
        "\n",
        "Após uma série de experimentos rigorosos, incluindo a otimização de modelos base e a avaliação de diferentes arquiteturas de ensemble, o modelo selecionado para ser o candidato principal à produção é:\n",
        "\n",
        "**`Stacking LGBM(2A) + CatBoost(3B1 Bernoulli + ES) → RF meta`**\n",
        "\n",
        "Este modelo demonstrou a melhor combinação de performance, robustez e alinhamento com os objetivos de negócio, superando os demais candidatos em métricas críticas.\n",
        "\n",
        "### 2. Análise de Performance e Justificativa Técnica\n",
        "\n",
        "A superioridade deste modelo não se baseia em uma única métrica, mas em uma análise holística de seu comportamento, especialmente em comparação com seu concorrente mais próximo (a versão com CatBoost H1).\n",
        "\n",
        "#### Prós e Vantagens Competitivas:\n",
        "\n",
        "1.  **Performance Superior nas Métricas de Negócio:**\n",
        "    *   **Recall da Classe \"Poor\" (Risco):** Com um **Recall de 0.829** para a classe 0, este modelo é o mais eficaz em identificar clientes de alto risco, cumprindo o principal objetivo de um sistema de prevenção de perdas.\n",
        "    *   **Recall Macro (Equilíbrio):** Atingiu o maior **Recall Macro (0.788)**, indicando que ele possui o melhor equilíbrio na identificação correta de *todas* as classes (Poor, Standard e Good). Isso significa que, além de mitigar o risco, ele também minimiza a perda de oportunidades ao não negar crédito indevidamente a bons clientes.\n",
        "    *   **Recall da Classe \"Good\" (Oportunidade):** Com **0.772**, também se mostrou o mais competente em reconhecer os clientes de baixo risco, reforçando sua capacidade de segmentação em todo o espectro de clientes.\n",
        "\n",
        "2.  **Arquitetura de Ensemble Robusta:**\n",
        "    *   **Diversidade dos Modelos Base:** O modelo combina a força do **LightGBM** (com seu crescimento de árvore *leaf-wise*) e do **CatBoost** (com suas árvores simétricas e tratamento de categóricas). A versão \"3B1\" do CatBoost, que utiliza `bootstrap_type='Bernoulli'` e `subsample`, introduziu uma camada adicional de regularização e amostragem, criando um modelo base mais generalista e, paradoxalmente, mais poderoso dentro do ensemble.\n",
        "    *   **Meta-Learner Simples e Eficaz:** O uso de um `RandomForestClassifier` de baixa complexidade (`max_depth=3`) como meta-learner provou ser extremamente eficaz. Ele aprende a combinar as previsões dos modelos base de forma não-linear, mas sem a complexidade excessiva que poderia levar a um overfitting na segunda camada do stacking.\n",
        "\n",
        "#### Análise do Overfitting: A Diferença entre Treino e Teste\n",
        "\n",
        "Observou-se uma diferença entre a performance de treino e a de teste:\n",
        "\n",
        "*   **Acurácia de Treino:** 0.925\n",
        "*   **Acurácia de Teste:** 0.784\n",
        "\n",
        "Embora a diferença de ~14 pontos percentuais possa parecer um sinal de alerta para overfitting, ela deve ser interpretada dentro do contexto de modelos de stacking de alta performance.\n",
        "\n",
        "**Argumentação sobre a Qualidade do Modelo:**\n",
        "\n",
        "1.  **Overfitting Esperado e Controlado:** Modelos de Gradient Boosting, e especialmente ensembles de stacking, são projetados para ter uma capacidade de aprendizado extremamente alta. É natural e esperado que eles se ajustem quase perfeitamente aos dados de treino. O verdadeiro teste de um modelo não é a ausência de overfitting, mas sua **capacidade de generalização**, ou seja, sua performance em dados nunca vistos (o conjunto de teste).\n",
        "\n",
        "2.  **A Generalização é o que Importa:** O que define a qualidade do modelo para o negócio é sua performance no teste. Com um **Recall Macro de 0.788** e um **Recall \"Poor\" de 0.829**, este modelo prova que, apesar de ter aprendido os dados de treino em detalhes, ele conseguiu extrair padrões que generalizam de forma eficaz e entregam um valor comercial tangível e superior aos outros candidatos.\n",
        "\n",
        "3.  **Complexidade que se Traduz em Performance:** A maior acurácia de treino do modelo vencedor (0.925 vs. 0.919 do concorrente) indica que a configuração do CatBoost \"3B1\" permitiu um aprendizado mais profundo. O ponto crucial é que essa capacidade de aprendizado adicional **se traduziu diretamente em melhores métricas de teste**, validando que o modelo não estava apenas memorizando ruído, mas sim capturando uma representação mais rica e útil dos dados.\n",
        "\n",
        "### 3. Conclusão\n",
        "\n",
        "O modelo `Stacking LGBM(2A) + CatBoost(3B1)` representa o ápice de nossa experimentação. Ele oferece o melhor equilíbrio entre a mitigação de risco (maior Recall \"Poor\") e a maximização de oportunidades (maior Recall \"Good\" e \"Macro\"), tornando-o a escolha técnica mais sólida e segura para avançar para as próximas etapas de validação e implantação em produção.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70072299",
      "metadata": {},
      "source": [
        "### Validação cruzada externa do ensemble vencedor (Stacking LGBM(2A) + CatBoost(3B1) → RF meta)\n",
        "\n",
        "Executamos uma CV externa estratificada k=5 para estimar generalização e variância por fold, evitando viés do holdout único. Em cada fold externo, reajustamos apenas iterations do CatBoost via um early stopping leve (paciente=45) usando um único split interno do treino do próprio fold, reduzindo custo sem vazamento. O LGBM fica fixo com os hiperparâmetros do passo 2A, e treinamos um StackingClassifier com stack_method='predict_proba' e RF raso como meta-learner. Medimos em cada validação externa recall_macro, recall da classe 0 (Poor) e f1_macro, agregando média ± desvio-padrão para robustez. Registramos no MLflow: parâmetros do pipeline, métricas agregadas, e CSV por fold (rastreabilidade). Objetivo: confirmar estabilidade do ganho em Poor e detectar overfitting (ex.: training drift) antes de promover o modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "a828414c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando Validação Cruzada Externa com 5 folds...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Processando Fold Externo 1/5 ---\n",
            "Fold 1: Iterações ótimas para CatBoost estimadas em 1130\n",
            "Fold 1: Treinando o StackingClassifier...\n",
            "Fold 1: Recall Macro = 0.7993, Recall Poor = 0.8520\n",
            "\n",
            "--- Processando Fold Externo 2/5 ---\n",
            "Fold 2: Iterações ótimas para CatBoost estimadas em 1997\n",
            "Fold 2: Treinando o StackingClassifier...\n",
            "Fold 2: Recall Macro = 0.7955, Recall Poor = 0.8343\n",
            "\n",
            "--- Processando Fold Externo 3/5 ---\n",
            "Fold 3: Iterações ótimas para CatBoost estimadas em 1738\n",
            "Fold 3: Treinando o StackingClassifier...\n",
            "Fold 3: Recall Macro = 0.7936, Recall Poor = 0.8371\n",
            "\n",
            "--- Processando Fold Externo 4/5 ---\n",
            "Fold 4: Iterações ótimas para CatBoost estimadas em 761\n",
            "Fold 4: Treinando o StackingClassifier...\n",
            "Fold 4: Recall Macro = 0.8013, Recall Poor = 0.8540\n",
            "\n",
            "--- Processando Fold Externo 5/5 ---\n",
            "Fold 5: Iterações ótimas para CatBoost estimadas em 1571\n",
            "Fold 5: Treinando o StackingClassifier...\n",
            "Fold 5: Recall Macro = 0.7899, Recall Poor = 0.8378\n",
            "\n",
            "\n",
            "============================================================\n",
            "=== RESULTADO DA VALIDAÇÃO CRUZADA EXTERNA ===\n",
            "============================================================\n",
            " fold  recall_macro  recall_poor  f1_macro\n",
            "    1        0.7993       0.8520    0.7878\n",
            "    2        0.7955       0.8343    0.7846\n",
            "    3        0.7936       0.8371    0.7833\n",
            "    4        0.8013       0.8540    0.7841\n",
            "    5        0.7899       0.8378    0.7783\n",
            "\n",
            "--- Estatísticas Agregadas ---\n",
            "Recall Macro: 0.7959 ± 0.0045\n",
            "Recall Poor:  0.8430 ± 0.0092\n",
            "F1 Macro:     0.7836 ± 0.0034\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /estrellacouto05/quantum-finance-credit-score.mlflow/api/2.0/mlflow/runs/create\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏃 View run ExternalCV_Stacking_LGBM_CatBoost3B1_RFMeta at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0/runs/5325f20a2ed24546bfcd60ae7eee7673\n",
            "🧪 View experiment at: https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow/#/experiments/0\n",
            "\n",
            "Processo de validação externa concluído e resultados logados no MLflow.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/15 18:32:37 INFO mlflow.tracking.fluent: Autologging successfully enabled for lightgbm.\n",
            "2025/09/15 18:32:37 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
            "2025/09/15 18:32:38 INFO mlflow.tracking.fluent: Autologging successfully enabled for xgboost.\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# === HELPER: estima 'iterations' do CatBoost com ES em um fold interno rápido ==\n",
        "# ==============================================================================\n",
        "\n",
        "def _best_iters_catboost(X, y, base_params, n_splits=5, patience=45, random_state=42):\n",
        "    \"\"\"Estima 'iterations' para CatBoost via uma CV interna simples (rápida).\n",
        "    Usa apenas o 1º fold para não aninhar CVs completas.\n",
        "    \"\"\"\n",
        "    skf_inner = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    tr_idx, va_idx = next(iter(skf_inner.split(X, y)))\n",
        "    X_tr, X_va = (X.iloc[tr_idx], X.iloc[va_idx]) if hasattr(X, \"iloc\") else (X[tr_idx], X[va_idx])\n",
        "    y_tr, y_va = (y.iloc[tr_idx], y.iloc[va_idx]) if hasattr(y, \"iloc\") else (y[tr_idx], y[va_idx])\n",
        "\n",
        "    cb = CatBoostClassifier(**base_params)\n",
        "    cb.fit(X_tr, y_tr, eval_set=(X_va, y_va), verbose=False,\n",
        "           early_stopping_rounds=patience, use_best_model=True)\n",
        "    it = cb.get_best_iteration()\n",
        "    return int(it if it is not None and it > 0 else base_params.get(\"iterations\", 1200))\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# === PIPELINE DE VALIDAÇÃO CRUZADA EXTERNA ====================================\n",
        "# ==============================================================================\n",
        "\n",
        "RUN_NAME = \"ExternalCV_Stacking_LGBM_CatBoost3B1_RFMeta\"\n",
        "RANDOM_STATE = 42\n",
        "N_SPLITS_EXTERNO = 5  # folds da validação externa\n",
        "\n",
        "# 1) Parâmetros base (modelo ganhador)\n",
        "lgbm_params_2a = {\n",
        "    'learning_rate': 0.1, 'colsample_bytree': 0.8, 'min_split_gain': 0.1,\n",
        "    'subsample': 0.7, 'subsample_freq': 1, 'num_leaves': 95, 'max_depth': 10,\n",
        "    'min_child_samples': 60, 'reg_lambda': 1.0, 'reg_alpha': 0.1,\n",
        "    'objective': \"multiclass\", 'num_class': 3, 'random_state': RANDOM_STATE,\n",
        "    'n_estimators': 408\n",
        "}\n",
        "cat_base_params_3b1 = {\n",
        "    'learning_rate': 0.05, 'depth': 7, 'l2_leaf_reg': 12, 'rsm': 0.80,\n",
        "    'bootstrap_type': \"Bernoulli\", 'subsample': 0.75, 'random_strength': 2.5,\n",
        "    'border_count': 48, 'loss_function': \"MultiClass\", 'eval_metric': \"TotalF1\",\n",
        "    'verbose': 0, 'random_state': RANDOM_STATE\n",
        "}\n",
        "\n",
        "# 2) Desliga autolog durante a CV externa (evita runs/fits internos no MLflow)\n",
        "try:\n",
        "    mlflow.autolog(disable=True)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "skf_externo = StratifiedKFold(n_splits=N_SPLITS_EXTERNO, shuffle=True, random_state=RANDOM_STATE)\n",
        "fold_metrics = []\n",
        "\n",
        "print(f\"Iniciando Validação Cruzada Externa com {N_SPLITS_EXTERNO} folds...\")\n",
        "\n",
        "for fold_num, (train_idx, val_idx) in enumerate(skf_externo.split(X, y), 1):\n",
        "    print(f\"\\n--- Processando Fold Externo {fold_num}/{N_SPLITS_EXTERNO} ---\")\n",
        "\n",
        "    # Split do fold\n",
        "    X_train_fold = X.iloc[train_idx] if hasattr(X, \"iloc\") else X[train_idx]\n",
        "    y_train_fold = y.iloc[train_idx] if hasattr(y, \"iloc\") else y[train_idx]\n",
        "    X_val_fold   = X.iloc[val_idx]   if hasattr(X, \"iloc\") else X[val_idx]\n",
        "    y_val_fold   = y.iloc[val_idx]   if hasattr(y, \"iloc\") else y[val_idx]\n",
        "\n",
        "    # CatBoost: estima iterations com ES usando apenas dados de treino do fold\n",
        "    cat_params_for_es = {**cat_base_params_3b1, 'iterations': 2000}\n",
        "    best_cat_iters = _best_iters_catboost(\n",
        "        X_train_fold, y_train_fold,\n",
        "        base_params=cat_params_for_es,\n",
        "        n_splits=3, patience=45, random_state=RANDOM_STATE\n",
        "    )\n",
        "    print(f\"Fold {fold_num}: Iterações ótimas para CatBoost estimadas em {best_cat_iters}\")\n",
        "\n",
        "    # Estimadores finais do fold\n",
        "    lgbm_final = LGBMClassifier(**lgbm_params_2a)\n",
        "    catboost_final = CatBoostClassifier(**{**cat_base_params_3b1, \"iterations\": best_cat_iters})\n",
        "    estimators = [(\"lgbm\", lgbm_final), (\"catboost\", catboost_final)]\n",
        "\n",
        "    # CV do Stacking: usar StratifiedKFold embaralhada para reprodutibilidade\n",
        "    skf_stack = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
        "\n",
        "    final_estimator = RandomForestClassifier(\n",
        "        n_estimators=100, max_depth=3, random_state=RANDOM_STATE, n_jobs=-1\n",
        "    )\n",
        "    stacking_clf_fold = StackingClassifier(\n",
        "        estimators=estimators,\n",
        "        final_estimator=final_estimator,\n",
        "        cv=skf_stack,              # <= ajuste 1: CV estratificada e embaralhada\n",
        "        n_jobs=-1,\n",
        "        passthrough=False,\n",
        "        stack_method='predict_proba'\n",
        "    )\n",
        "\n",
        "    print(f\"Fold {fold_num}: Treinando o StackingClassifier...\")\n",
        "    stacking_clf_fold.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Predição no holdout do fold\n",
        "    y_pred_fold = stacking_clf_fold.predict(X_val_fold)\n",
        "\n",
        "    # Métricas por fold\n",
        "    per_class_recall = recall_score(\n",
        "        y_val_fold, y_pred_fold, labels=[0, 1, 2], average=None, zero_division=0\n",
        "    )\n",
        "    recall_poor = float(per_class_recall[0])  # <= ajuste 2: recall explícito da classe 0\n",
        "    recall_macro = float(recall_score(y_val_fold, y_pred_fold, average='macro', zero_division=0))\n",
        "    f1_macro = float(f1_score(y_val_fold, y_pred_fold, average='macro', zero_division=0))\n",
        "\n",
        "    fold_metrics.append({\n",
        "        \"fold\": fold_num,\n",
        "        \"recall_macro\": recall_macro,\n",
        "        \"recall_poor\": recall_poor,\n",
        "        \"f1_macro\": f1_macro\n",
        "    })\n",
        "    print(f\"Fold {fold_num}: Recall Macro = {recall_macro:.4f}, Recall Poor = {recall_poor:.4f}\")\n",
        "\n",
        "# 3) Agregação e logging único no MLflow\n",
        "metrics_df = pd.DataFrame(fold_metrics)\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"=== RESULTADO DA VALIDAÇÃO CRUZADA EXTERNA ===\")\n",
        "print(\"=\"*60)\n",
        "print(metrics_df.round(4).to_string(index=False))\n",
        "\n",
        "print(\"\\n--- Estatísticas Agregadas ---\")\n",
        "mean_metrics = metrics_df.mean(numeric_only=True)\n",
        "std_metrics = metrics_df.std(numeric_only=True)\n",
        "print(f\"Recall Macro: {mean_metrics['recall_macro']:.4f} ± {std_metrics['recall_macro']:.4f}\")\n",
        "print(f\"Recall Poor:  {mean_metrics['recall_poor']:.4f} ± {std_metrics['recall_poor']:.4f}\")\n",
        "print(f\"F1 Macro:     {mean_metrics['f1_macro']:.4f} ± {std_metrics['f1_macro']:.4f}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "with mlflow.start_run(run_name=RUN_NAME):\n",
        "    mlflow.log_param(\"model_name\", \"Stacking_LGBM_CatBoost3B1_RFMeta\")\n",
        "    mlflow.log_param(\"external_cv_folds\", N_SPLITS_EXTERNO)\n",
        "\n",
        "    mlflow.log_metric(\"mean_recall_macro\", float(mean_metrics['recall_macro']))\n",
        "    mlflow.log_metric(\"std_recall_macro\", float(std_metrics['recall_macro']))\n",
        "    mlflow.log_metric(\"mean_recall_poor\", float(mean_metrics['recall_poor']))\n",
        "    mlflow.log_metric(\"std_recall_poor\", float(std_metrics['recall_poor']))\n",
        "    mlflow.log_metric(\"mean_f1_macro\", float(mean_metrics['f1_macro']))\n",
        "    mlflow.log_metric(\"std_f1_macro\", float(std_metrics['f1_macro']))\n",
        "\n",
        "    metrics_df.to_csv(\"external_cv_results.csv\", index=False)\n",
        "    mlflow.log_artifact(\"external_cv_results.csv\")\n",
        "\n",
        "print(\"\\nProcesso de validação externa concluído e resultados logados no MLflow.\")\n",
        "\n",
        "# 4) Reativa autolog para os próximos experimentos\n",
        "try:\n",
        "    mlflow.autolog(disable=False)\n",
        "except Exception:\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba28871b",
      "metadata": {},
      "source": [
        "### Validação cruzada externa — confirmação dos resultados (k=5)\n",
        "\n",
        "Ensemble avaliado: Stacking LGBM(2A) + CatBoost(3B1) → RF meta, com recalibração de iterations do CatBoost por fold via ES. Os números ficaram coerentes e estáveis entre os folds, indicando boa generalização e baixo risco de overfit adicional.\n",
        "Métricas agregadas (média ± desvio): Recall Macro 0,7959 ± 0,0045, Recall Poor 0,8430 ± 0,0092, F1 Macro 0,7836 ± 0,0034.\n",
        "Por fold, o Recall Poor ficou de 0,8343 a 0,8540, mantendo-se acima do patamar-alvo; o Recall Macro variou pouco (0,7899–0,8013).\n",
        "Embora as iterações ótimas do CatBoost tenham variado (761–1997), a performance permaneceu estável — bom sinal de robustez do ensemble."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46ab5ea8",
      "metadata": {
        "id": "46ab5ea8"
      },
      "source": [
        "# Registro de Modelo em Produção"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dfac46c",
      "metadata": {
        "id": "4dfac46c"
      },
      "source": [
        "Após treinar e avaliar o modelo, podemos registrá-lo oficialmente no **Model Registry do MLflow**.  \n",
        "Isso permite versionar o modelo, promovê-lo para produção e gerenciar futuras atualizações.  \n",
        "\n",
        "- Usamos o **run_id** obtido no link do MLflow (na interface Dagshub).\n",
        "- Escolhemos um nome amigável e consistente para o modelo, neste caso: `credit-score-model`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "ec613860",
      "metadata": {
        "id": "ec613860",
        "outputId": "f0fdb104-83d4-487f-a8f4-5ed1f02f629d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Registered model 'credit-score-model' already exists. Creating a new version of this model...\n",
            "2025/09/17 12:16:42 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: credit-score-model, version 3\n",
            "Created version '3' of model 'credit-score-model'.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Modelo registrado como 'credit-score-model' (run_id: bccfb26c333a41cf94facfc225cc8f2c)\n"
          ]
        }
      ],
      "source": [
        "run_id = \"bccfb26c333a41cf94facfc225cc8f2c\"\n",
        "\n",
        "mlflow.register_model(\n",
        "    model_uri=f\"runs:/{run_id}/model\",\n",
        "    name=\"credit-score-model\"\n",
        ")\n",
        "\n",
        "print(f\" Modelo registrado como 'credit-score-model' (run_id: {run_id})\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv (3.11.3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4687d75d06ab4d1e84c5024bf006058f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51a2e8248c794ef789fa7511ee4e0d48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76355c4f832446b5aa9df0267d41ac4e": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_51a2e8248c794ef789fa7511ee4e0d48",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠧</span> Waiting for authorization\n</pre>\n",
                  "text/plain": "\u001b[32m⠧\u001b[0m Waiting for authorization\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ],
            "tabbable": null,
            "tooltip": null
          }
        },
        "9036a9a78fca4681940d2aacb603ac39": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_4687d75d06ab4d1e84c5024bf006058f",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠧</span> Downloading metadata... <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">━</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">━</span><span style=\"color: #613545; text-decoration-color: #613545\">━</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">━</span><span style=\"color: #993056; text-decoration-color: #993056\">━</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">━</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">━</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">━</span><span style=\"color: #f42670; text-decoration-color: #f42670\">━</span><span style=\"color: #f92672; text-decoration-color: #f92672\">━</span><span style=\"color: #f42670; text-decoration-color: #f42670\">━</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">━</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">━</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">━</span><span style=\"color: #993056; text-decoration-color: #993056\">━</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">━</span><span style=\"color: #613545; text-decoration-color: #613545\">━</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">━</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">━</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">━</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">━</span><span style=\"color: #613545; text-decoration-color: #613545\">━</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">━</span><span style=\"color: #993056; text-decoration-color: #993056\">━</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">━</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">━</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">━</span><span style=\"color: #f42670; text-decoration-color: #f42670\">━</span><span style=\"color: #f92672; text-decoration-color: #f92672\">━</span><span style=\"color: #f42670; text-decoration-color: #f42670\">━</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">━</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">━</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">━</span><span style=\"color: #993056; text-decoration-color: #993056\">━</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">━</span><span style=\"color: #613545; text-decoration-color: #613545\">━</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">━</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">━</span>   <span style=\"color: #008000; text-decoration-color: #008000\">1/?</span>\n</pre>\n",
                  "text/plain": "\u001b[32m⠧\u001b[0m Downloading metadata... \u001b[38;2;58;58;58m━\u001b[0m\u001b[38;2;62;57;59m━\u001b[0m\u001b[38;2;76;56;63m━\u001b[0m\u001b[38;2;97;53;69m━\u001b[0m\u001b[38;2;123;51;77m━\u001b[0m\u001b[38;2;153;48;86m━\u001b[0m\u001b[38;2;183;44;94m━\u001b[0m\u001b[38;2;209;42;102m━\u001b[0m\u001b[38;2;230;39;108m━\u001b[0m\u001b[38;2;244;38;112m━\u001b[0m\u001b[38;2;249;38;114m━\u001b[0m\u001b[38;2;244;38;112m━\u001b[0m\u001b[38;2;230;39;108m━\u001b[0m\u001b[38;2;209;42;102m━\u001b[0m\u001b[38;2;183;44;94m━\u001b[0m\u001b[38;2;153;48;86m━\u001b[0m\u001b[38;2;123;51;77m━\u001b[0m\u001b[38;2;97;53;69m━\u001b[0m\u001b[38;2;76;56;63m━\u001b[0m\u001b[38;2;62;57;59m━\u001b[0m\u001b[38;2;58;58;58m━\u001b[0m\u001b[38;2;62;57;59m━\u001b[0m\u001b[38;2;76;56;63m━\u001b[0m\u001b[38;2;97;53;69m━\u001b[0m\u001b[38;2;123;51;77m━\u001b[0m\u001b[38;2;153;48;86m━\u001b[0m\u001b[38;2;183;44;94m━\u001b[0m\u001b[38;2;209;42;102m━\u001b[0m\u001b[38;2;230;39;108m━\u001b[0m\u001b[38;2;244;38;112m━\u001b[0m\u001b[38;2;249;38;114m━\u001b[0m\u001b[38;2;244;38;112m━\u001b[0m\u001b[38;2;230;39;108m━\u001b[0m\u001b[38;2;209;42;102m━\u001b[0m\u001b[38;2;183;44;94m━\u001b[0m\u001b[38;2;153;48;86m━\u001b[0m\u001b[38;2;123;51;77m━\u001b[0m\u001b[38;2;97;53;69m━\u001b[0m\u001b[38;2;76;56;63m━\u001b[0m\u001b[38;2;62;57;59m━\u001b[0m   \u001b[32m1/?\u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ],
            "tabbable": null,
            "tooltip": null
          }
        },
        "9de5be7324e8430fba6952fd2d7c3438": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_c373c6608ef64c55a98a97ee3df8a530",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Downloading metadata... <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> <span style=\"color: #008000; text-decoration-color: #008000\">100/100</span>\n</pre>\n",
                  "text/plain": "  Downloading metadata... \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[32m100/100\u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ],
            "tabbable": null,
            "tooltip": null
          }
        },
        "c373c6608ef64c55a98a97ee3df8a530": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
