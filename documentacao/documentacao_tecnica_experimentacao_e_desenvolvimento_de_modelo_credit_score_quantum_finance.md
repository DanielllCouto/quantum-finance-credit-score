# Documenta√ß√£o T√©cnica : Experimenta√ß√£o e Desenvolvimento de Modelo para Previs√£o de Score de Cr√©dito - Quantum Finance

**Autor:** Daniel Estrella Couto  

**Projeto:** Quantum Finance - Credit Score Prediction  

**Notebook:** desenvolvimento-modelo.ipynb

---

## 1. Introdu√ß√£o e Contexto do Projeto

Esta documenta√ß√£o apresenta uma an√°lise t√©cnica abrangente e c√©lula por c√©lula do processo de experimenta√ß√£o e desenvolvimento de modelos de machine learning para previs√£o de score de cr√©dito. O projeto foi estruturado em **duas √©pocas distintas de experimenta√ß√£o**, cada uma com objetivos espec√≠ficos e estrat√©gias progressivamente mais sofisticadas.

A documenta√ß√£o detalha o caminho completo da experimenta√ß√£o, desde os primeiros modelos individuais at√© o desenvolvimento de ensembles avan√ßados com t√©cnicas de regulariza√ß√£o, culminando na identifica√ß√£o do **modelo campe√£o final**. O foco principal √© a maximiza√ß√£o do **recall da classe 0 (Poor)**, que representa clientes com alto risco de inadimpl√™ncia - a m√©trica de neg√≥cio mais cr√≠tica para o projeto.

### 1.1. Objetivos de Neg√≥cio

O principal desafio de neg√≥cio √© identificar corretamente clientes com score de cr√©dito "Poor", minimizando falsos negativos que poderiam resultar em perdas financeiras significativas. Um cliente classificado incorretamente como "Good" ou "Standard" quando na verdade √© "Poor" representa um risco muito maior do que o erro inverso.

### 1.2. Estrutura da Experimenta√ß√£o

O processo foi dividido em duas √©pocas principais:

- **Primeira √âpoca:** Modelos individuais + Primeiro Ensemble (Stacking LightGBM + CatBoost)

- **Segunda √âpoca:** Refinamento e otimiza√ß√£o do ensemble com foco em redu√ß√£o de overfitting

### 1.3. Decis√µes-Chave e M√©tricas Registradas (Vis√£o Executiva)

| √âpoca | Modelo/Estrat√©gia | M√©tricas-Chave | Status |
| --- | --- | --- | --- |
| **√âpoca 1** | CatBoost FineTuned | Recall classe 0 = 0.743; Recall_macro = 0.732 | Melhor individual |
| **√âpoca 1** | Stack 3 bases (LGBM+XGB+RF) | Recall classe 0 ‚âà 0.33 | **Descartado** |
| **√âpoca 1** | **Stack 2 bases (LGBM + CatBoost)** | **Recall classe 0 = 0.842; Recall_macro = 0.794** | **Vencedor da √©poca 1** |
| **√âpoca 2** | Refinos do Stack + meta LogisticRegression | Recall classe 0 ‚âà 0.84; Recall_macro ‚âà 0.79‚Äì0.80 | **Vencedor final** |

---

## 2. Configura√ß√£o do Ambiente e Infraestrutura MLOps

### 2.1. Stack Tecnol√≥gico

A experimenta√ß√£o foi conduzida utilizando uma infraestrutura robusta de MLOps que garantiu reprodutibilidade, versionamento e rastreabilidade completa:

**Versionamento de Dados:**

- **DVC (Data Version Control):** Controle de vers√£o dos datasets

- **Dagshub:** Plataforma integrada para versionamento e colabora√ß√£o

- **Dagshub Data Engine:** API para acesso program√°tico aos dados versionados

**Rastreamento de Experimentos:**

- **MLflow:** Plataforma central para logging de experimentos

- **MLflow Autolog:** Captura autom√°tica de par√¢metros e m√©tricas

- **MLflow Model Registry:** Versionamento e gest√£o de modelos

**Bibliotecas de Machine Learning:**

- **Scikit-learn:** Modelos tradicionais e m√©tricas

- **XGBoost:** Gradient boosting otimizado

- **LightGBM:** Gradient boosting eficiente

- **CatBoost:** Gradient boosting para dados categ√≥ricos

### 2.2. Carregamento de Dados Versionados

O dataset processado foi carregado diretamente do reposit√≥rio versionado, garantindo consist√™ncia entre experimentos:

```python
# Acesso via Dagshub Data Engine
ds = datasources.get('estrellacouto05/quantum-finance-credit-score', 'processed')
dataset_url = ds.head()[0].download_url

# Download autenticado com token
headers = {"Authorization": f"Bearer {dagshub_token}"}
response = requests.get(dataset_url, headers=headers)
df = pd.read_csv(io.StringIO(response.text))
```

**Coment√°rio T√©cnico:** Esta abordagem garante que todos os experimentos utilizem exatamente a mesma vers√£o dos dados, eliminando variabilidade relacionada a diferen√ßas no dataset e permitindo compara√ß√µes justas entre modelos.

### 2.3. Configura√ß√£o do MLflow

O MLflow foi configurado para capturar automaticamente todos os aspectos dos experimentos:

```python
mlflow.autolog()  # Ativa logging autom√°tico
mlflow.set_tracking_uri("https://dagshub.com/estrellacouto05/quantum-finance-credit-score.mlflow")
```

**Coment√°rio T√©cnico:** A integra√ß√£o MLflow + DagsHub permite rastreamento completo de experimentos com versionamento de c√≥digo, dados e modelos em uma √∫nica plataforma, facilitando reprodutibilidade e colabora√ß√£o.

---

## 3. Prepara√ß√£o dos Dados para Modelagem

### 3.1. Estrutura do Dataset Final

O dataset processado continha:

- **100.000 registros** (sem perda de dados)

- **48 features** ap√≥s engenharia de vari√°veis

- **Vari√°vel alvo:** `score_credito` (0: Poor, 1: Standard, 2: Good)

### 3.2. Separa√ß√£o de Features e Target

```python
X = df.drop('score_credito', axis=1)  # 48 features
y = df['score_credito']               # Target (0, 1, 2)
```

**Coment√°rio T√©cnico:** A separa√ß√£o clara entre features e target organiza o dataset para os modelos de Machine Learning, que aprender√£o a prever o target com base nas features de forma supervisionada.

### 3.3. Divis√£o Treino/Teste

```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)
# Resultado: 70.000 treino, 30.000 teste
```

**Coment√°rio T√©cnico:** A divis√£o 70/30 com estratifica√ß√£o garante que a distribui√ß√£o das classes seja mantida em ambos os conjuntos, evitando vi√©s na avalia√ß√£o e permitindo estimativas mais confi√°veis da performance em produ√ß√£o.

### 3.4. Escalonamento com RobustScaler

A escolha do `RobustScaler` foi estrat√©gica para lidar com outliers identificados na fase de EDA:

```python
scaler = RobustScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
```

**Coment√°rio T√©cnico:** O `RobustScaler` utiliza mediana e IQR em vez de m√©dia e desvio padr√£o, sendo menos sens√≠vel a outliers que poderiam distorcer a escala das features. Esta escolha √© particularmente importante em dados financeiros, onde outliers s√£o comuns e informativos.

---

## 4. Fun√ß√£o de Avalia√ß√£o Padronizada

### 4.1. Desenvolvimento da Fun√ß√£o `evaluate_and_log_model`

Para garantir consist√™ncia na avalia√ß√£o, foi desenvolvida uma fun√ß√£o centralizada que automatiza:

1. **C√°lculo de m√©tricas completas** por classe e agregadas

1. **Logging autom√°tico no MLflow** de todas as m√©tricas

1. **Gera√ß√£o e salvamento da matriz de confus√£o**

1. **Registro do modelo** com assinatura apropriada

```python
def evaluate_and_log_model(kind, model_name, model, X_test, y_test):
    predictions = model.predict(X_test)
    
    # M√©tricas por classe
    precision, recall, f1, _ = precision_recall_fscore_support(
        y_test, predictions, labels=[0,1,2], zero_division=0
    )
    
    # Destaque para classe 0 (Poor)
    mlflow.log_metric("Recall_class_0_Poor", recall[0])
    mlflow.log_metric("Precision_class_0_Poor", precision[0])
    mlflow.log_metric("F1_class_0_Poor", f1[0])
    
    # Matriz de confus√£o como artefato
    cm = confusion_matrix(y_test, predictions, labels=[0,1,2])
    # ... c√≥digo para salvar e logar matriz
```

**Coment√°rio T√©cnico:** Esta fun√ß√£o padronizada elimina inconsist√™ncias na avalia√ß√£o entre experimentos, garantindo que todas as m√©tricas sejam calculadas da mesma forma e registradas automaticamente no MLflow para compara√ß√£o posterior.

### 4.2. M√©tricas Priorizadas

- **Recall Classe 0 (Poor):** M√©trica principal de neg√≥cio

- **Recall Macro:** M√©dia do recall entre todas as classes

- **F1-Score Macro:** Harm√¥nica entre precision e recall

- **Acur√°cia de Treino:** Para monitorar overfitting

**Coment√°rio T√©cnico:** O foco no recall da classe 0 reflete a realidade de neg√≥cio onde falsos negativos (clientes Poor classificados como Good/Standard) t√™m custo muito maior que falsos positivos.

---

## 5. PRIMEIRA √âPOCA DE EXPERIMENTA√á√ÉO

### 5.1. Estrat√©gia da Primeira √âpoca

A primeira √©poca focou na avalia√ß√£o de modelos individuais com otimiza√ß√£o de hiperpar√¢metros via `RandomizedSearchCV`, seguida pela constru√ß√£o do primeiro ensemble. O objetivo era estabelecer baselines s√≥lidos e identificar a melhor combina√ß√£o de algoritmos.

**Coment√°rio T√©cnico:** O uso de `RandomizedSearchCV` (n_iter‚âà30, cv=5) equilibra custo/benef√≠cio, permitindo explorar regi√µes promissoras do hiper-espa√ßo com foco em recall_macro sem custo computacional excessivo.

### 5.2. Experimento 1: XGBoost Classifier

**Configura√ß√£o:**

- `RandomizedSearchCV` com 30 itera√ß√µes

- Valida√ß√£o cruzada com 5 folds

- M√©trica de otimiza√ß√£o: `recall_macro`

**Espa√ßo de Hiperpar√¢metros:**

```python
param_distributions = {
    'n_estimators': [50, 100, 200, 300],
    'max_depth': [3, 5, 7, 9],
    'learning_rate': [0.01, 0.05, 0.1],
    'subsample': [0.7, 0.8, 1.0],
    'colsample_bytree': [0.7, 0.8, 1.0],
    'min_child_weight': [1, 3, 5]
}
```

**Resultados:**

- **Recall Classe 0 (Poor):** 0.727

- **F1-Score Macro:** 0.727

- **Acur√°cia:** 0.748

**Coment√°rio T√©cnico:** O XGBoost foi avaliado com RandomizedSearchCV (cv=5), focando em par√¢metros como n_estimators, max_depth, learning_rate, subsample, colsample_bytree e min_child_weight, com objetivo de maximizar o recall_macro. Os resultados estabeleceram um baseline s√≥lido.

### 5.3. Experimento 2: LightGBM Classifier

**Configura√ß√£o:**

- `RandomizedSearchCV` com 30 itera√ß√µes

- Foco em hiperpar√¢metros espec√≠ficos do LightGBM

**Espa√ßo de Hiperpar√¢metros:**

```python
param_distributions = {
    'n_estimators': [50, 100, 200, 300],
    'max_depth': [3, 5, 7, 9, -1],
    'learning_rate': [0.01, 0.05, 0.1],
    'num_leaves': [15, 31, 63, 127],
    'subsample': [0.7, 0.8, 1.0],
    'colsample_bytree': [0.7, 0.8, 1.0]
}
```

**Resultados:**

- **Recall Classe 0 (Poor):** 0.778

- **F1-Score Macro:** 0.766

- **Acur√°cia:** 0.780

**Coment√°rio T√©cnico:** O LightGBM foi submetido a busca ampla seguida de refino com foco em regulariza√ß√£o (reg_alpha/reg_lambda), num_leaves e amostragem (subsample/colsample_bytree), com tuning voltado a recall_macro e estabilidade entre classes. Superou o XGBoost em todas as m√©tricas.

### 5.4. Experimento 3: Random Forest Classifier

**Configura√ß√£o:**

- `RandomizedSearchCV` com 50 itera√ß√µes (espa√ßo maior)

- Foco em controle de overfitting

**Espa√ßo de Hiperpar√¢metros:**

```python
param_distributions = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 15, 20],  # Sem None para evitar overfitting
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['auto', 'sqrt', 'log2'],
    'bootstrap': [True, False],
    'criterion': ['gini', 'entropy']
}
```

**Resultados:**

- **Recall Classe 0 (Poor):** 0.754

- **F1-Score Macro:** 0.751

- **Acur√°cia:** 0.768

**Coment√°rio T√©cnico:** O Random Forest serviu como baseline forte de ensemble tradicional; ainda assim, mesmo com espa√ßo de busca para n_estimators, max_depth e min_samples, n√£o superou LGBM/CatBoost no objetivo de neg√≥cio.

### 5.5. Fine-Tuning do LightGBM

Dado o desempenho superior do LightGBM, foram realizados dois ciclos de fine-tuning:

#### 5.5.1. Fine-Tuning 1: Busca Refinada

**Estrat√©gia:** Espa√ßo de busca refinado em torno dos melhores par√¢metros com 50 itera√ß√µes e ranges mais estreitos.

**Resultados Fine-Tuning 1:**

- **Recall Classe 0 (Poor):** 0.786

- **F1-Score Macro:** 0.772

- **Acur√°cia:** 0.784

#### 5.5.2. Fine-Tuning 2: Foco em n_estimators e learning_rate

**Estrat√©gia:** Teste espec√≠fico de combina√ß√µes `n_estimators` vs `learning_rate` mantendo outros par√¢metros fixos.

**Configura√ß√£o Testada:**

```python
# Modelo A (1¬∫ Fine-tune)
n_estimators = 500, learning_rate = 0.1
# Modelo B (2¬∫ Fine-tune)  
n_estimators = 1000, learning_rate = 0.05
```

**Resultados Fine-Tuning 2:**

- **Recall Classe 0 (Poor):** 0.789

- **F1-Score Macro:** 0.773

- **Acur√°cia:** 0.786

**Decis√£o Estrat√©gica:** Apesar do modelo B ter performance ligeiramente superior (0.789 vs 0.786), optou-se pelo modelo A (`n_estimators=500`, `learning_rate=0.1`) devido ao melhor custo-benef√≠cio. A melhora m√≠nima (0.003) n√£o justificava o dobro do custo computacional e maior risco de overfitting.

**Coment√°rio T√©cnico:** Esta decis√£o exemplifica o equil√≠brio entre performance e efici√™ncia operacional, considerando que o aumento nos estimadores eleva o custo computacional e o risco de overfitting sem retorno proporcional em desempenho.

### 5.6. Experimento 4: CatBoost Classifier

**Configura√ß√£o:**

- `RandomizedSearchCV` com 30 itera√ß√µes

- M√©trica interna: `TotalF1` (adequada para multiclasse)

- M√©trica de otimiza√ß√£o externa: `recall_macro`

**Espa√ßo de Hiperpar√¢metros:**

```python
param_distributions = {
    'iterations': [100, 200, 300, 500],
    'learning_rate': [0.01, 0.05, 0.1],
    'depth': [4, 6, 8, 10],
    'l2_leaf_reg': [1, 3, 5, 7],
    'border_count': [32, 64, 128, 255],
    'bagging_temperature': [0, 1, 5, 10]
}
```

**Resultados CatBoost:**

- **Recall Classe 0 (Poor):** 0.743

- **Recall Macro:** 0.732

- **F1-Score Macro:** 0.765

- **Acur√°cia:** 0.779

**Coment√°rio T√©cnico:** CatBoost mostrou-se superior isoladamente na classe 0; na etapa seguinte, sua combina√ß√£o com LightGBM elevou o recall de Poor para ~0.84. O CatBoost FineTuned obteve excelente performance, superando todos os modelos anteriores.

### 5.7. Primeiro Ensemble: Stacking LightGBM + CatBoost

Ap√≥s avaliar os modelos individuais, foi constru√≠do o primeiro ensemble combinando os dois melhores algoritmos.

#### 5.7.1. Justificativa para o Ensemble

**An√°lise dos Resultados Individuais:**

- O **CatBoost FineTuned** obteve excelente performance na classe 0 (Poor) com recall de 0.743

- O **LightGBM FineTuned** apresentou boa cobertura da classe 2 (Good) com tempo de treinamento inferior

- Um Stacking inicial com **tr√™s modelos (LightGBM, XGBoost e RandomForest)** teve desempenho muito abaixo do esperado, com recall da classe 0 em apenas 0.33, sendo **descartado** por baixa efic√°cia e sobreposi√ß√£o de comportamento

**Coment√°rio T√©cnico:** A decis√£o de descartar o ensemble de 3 modelos foi baseada na an√°lise de que XGBoost e Random Forest apresentavam comportamentos muito similares ao LightGBM, n√£o agregando diversidade suficiente ao ensemble.

#### 5.7.2. Configura√ß√£o do Stacking

```python
estimators = [
    ('lgbm', lgbm_best_model),      # LightGBM otimizado
    ('catboost', catboost_best_model) # CatBoost otimizado
]

final_estimator = DecisionTreeClassifier(max_depth=3, random_state=42)

stacking_clf = StackingClassifier(
    estimators=estimators,
    final_estimator=final_estimator,
    cv=5,                    # Valida√ß√£o cruzada para meta-features
    passthrough=False        # Reduz risco de overfitting
)
```

**Coment√°rio T√©cnico:** O uso de `passthrough=False` evita repassar features originais ao meta-learner, concentrando a decis√£o nas probabilidades/sa√≠das dos modelos base e reduzindo risco de sobreajuste. A √°rvore de decis√£o como meta-learner oferece interpretabilidade e baixa vari√¢ncia.

#### 5.7.3. Resultados do Primeiro Stacking

- **Recall Classe 0 (Poor):** 0.842 üéØ

- **Recall Macro:** 0.794

- **F1-Score Macro:** 0.785

- **Acur√°cia:** 0.792

**An√°lise:** Ao combinar apenas **os dois melhores modelos (CatBoost e LightGBM)**, alcan√ßamos um **recall da classe 0 de 0.842** e um **recall_macro de 0.794**. Esse resultado evidencia que o ensemble **potencializou os pontos fortes de cada um** e contribuiu para **uma classifica√ß√£o mais equilibrada entre as tr√™s classes**.

**Coment√°rio T√©cnico:** A valida√ß√£o cruzada externa (5 folds) foi aplicada para aferir generaliza√ß√£o al√©m do split fixo, diminuindo a chance de conclus√µes dependentes de uma √∫nica parti√ß√£o.

### 5.8. Conclus√£o da Primeira √âpoca

| Modelo | Recall Classe 0 (Poor) | F1-Score Macro | Acur√°cia | Ranking |
| --- | --- | --- | --- | --- |
| **Stacking LGBM+CatBoost** | **0.842** | **0.785** | **0.792** | **1¬∫** |
| LightGBM (Fine-tuned) | 0.789 | 0.773 | 0.786 | 2¬∫ |
| CatBoost (Fine-tuned) | 0.743 | 0.765 | 0.779 | 3¬∫ |
| Random Forest | 0.754 | 0.751 | 0.768 | 4¬∫ |
| XGBoost | 0.727 | 0.727 | 0.748 | 5¬∫ |

**Modelo Campe√£o da Primeira √âpoca:** Stacking LightGBM + CatBoost

Com esse resultado, este modelo passou a ser o **candidato principal √† produ√ß√£o** e seria submetido √† valida√ß√£o cruzada externa antes de ser registrado no **MLflow Model Registry**.

---

## 6. SEGUNDA √âPOCA DE EXPERIMENTA√á√ÉO

### 6.1. Estrat√©gia da Segunda √âpoca

A segunda √©poca focou no **refinamento e otimiza√ß√£o do ensemble vencedor**, buscando melhorar ainda mais a performance atrav√©s de t√©cnicas avan√ßadas de regulariza√ß√£o e controle de overfitting. O objetivo era superar o recall de 0.842 da classe Poor mantendo a estabilidade do modelo.

**Coment√°rio T√©cnico:** A segunda √©poca representa uma abordagem mais madura, priorizando robustez e generaliza√ß√£o sobre performance m√°xima, refletindo considera√ß√µes pr√°ticas para deployment em produ√ß√£o.

### 6.2. An√°lise do Modelo Base (Primeira √âpoca)

Antes de iniciar as melhorias, foi realizada uma an√°lise detalhada do modelo vencedor:

**Pontos Fortes:**

- Excelente recall na classe Poor (0.842)

- Boa generaliza√ß√£o entre classes

- Ensemble diversificado e robusto

**Oportunidades de Melhoria:**

- Poss√≠vel overfitting (gap treino-teste a ser investigado)

- Potencial para otimiza√ß√£o de hiperpar√¢metros espec√≠ficos

- Regulariza√ß√£o mais agressiva dos base learners

### 6.3. Stacking 2A: Refinamento dos Par√¢metros Base

**Objetivo:** Otimizar os hiperpar√¢metros dos base learners mantendo a arquitetura do ensemble.

**Estrat√©gia:**

- Manter a estrutura LightGBM + CatBoost ‚Üí Meta-learner

- Aplicar RandomizedSearchCV nos par√¢metros dos base learners

- Trocar meta-learner para RandomForest (mais robusto que DecisionTree)

**Configura√ß√£o LightGBM Otimizada (2A):**

```python
lgbm_params_2a = {
    'learning_rate': 0.1,
    'colsample_bytree': 0.8,
    'min_split_gain': 0.1,
    'subsample': 0.7,
    'subsample_freq': 1,
    'num_leaves': 95,
    'max_depth': 10,
    'min_child_samples': 60,
    'reg_lambda': 1.0,
    'reg_alpha': 0.1,
    'n_estimators': 408
}
```

**Meta-learner Atualizado:**

```python
final_estimator = RandomForestClassifier(
    n_estimators=100, 
    max_depth=3, 
    random_state=42
)
```

**Resultados Stacking 2A:**

- **Recall Classe 0 (Poor):** 0.819

- **F1-Score Macro:** 0.776

- **Acur√°cia:** 0.785

- **Acur√°cia de Treino:** 0.925 (gap de ~14%)

**An√°lise:** Ligeira redu√ß√£o na performance, mas com melhor controle de overfitting devido ao meta-learner mais robusto.

### 6.4. Stacking 2B: Random Search em Torno do 2A

**Objetivo:** Busca direcionada em torno dos par√¢metros do 2A para refinamento fino.

**Estrat√©gia:**

- RandomizedSearchCV com espa√ßo restrito ao redor do 2A

- Manter LightGBM fixo, otimizar apenas CatBoost

- Early stopping para controle de itera√ß√µes

**Resultados Stacking 2B:**

- **Recall Classe 0 (Poor):** 0.821 (+0.2 p.p.)

- **F1-Score Macro:** 0.779

- **Acur√°cia:** 0.788

- **Acur√°cia de Treino:** 0.938 (gap de ~15%)

**An√°lise:** Melhoria marginal com aumento do overfitting - sinal de que o espa√ßo estava sendo esgotado.

### 6.5. Stacking 3A: CatBoost Regularizado + Early Stopping

**Objetivo:** Reduzir overfitting atrav√©s de regulariza√ß√£o agressiva do CatBoost.

**Estrat√©gia de Regulariza√ß√£o:**

- `depth`: 10 ‚Üí 8 (√°rvores mais rasas)

- `l2_leaf_reg`: 3 ‚Üí 8 (regulariza√ß√£o L2 aumentada)

- `rsm`: 0.85 (feature sampling)

- `subsample`: 0.8 com `bootstrap_type='Bernoulli'`

- Early stopping com patience=40

**Configura√ß√£o CatBoost 3A:**

```python
cat_params_3a = {
    'learning_rate': 0.05,
    'depth': 8,                    # ‚Üì de 10 ‚Üí 8
    'l2_leaf_reg': 8,              # ‚Üë de 3 ‚Üí 8
    'rsm': 0.85,                   # feature sampling
    'subsample': 0.8,              # amostragem de registros
    'bootstrap_type': "Bernoulli",
    'random_strength': 1.5,
    'border_count': 64
}
```

**Resultados Stacking 3A:**

- **Recall Classe 0 (Poor):** 0.820

- **F1-Score Macro:** 0.776

- **Acur√°cia:** 0.784

- **Acur√°cia de Treino:** 0.920 (gap reduzido para ~13.6%)

**An√°lise:** Sucesso na redu√ß√£o do overfitting mantendo performance similar.

### 6.6. Stacking 3B-1: CatBoost Agressivamente Regularizado

**Objetivo:** Aplicar regulariza√ß√£o ainda mais agressiva para maximizar generaliza√ß√£o.

**Estrat√©gia Mais Agressiva:**

- `depth`: 7 (ainda mais raso)

- `l2_leaf_reg`: 12 (regulariza√ß√£o L2 m√°xima)

- `rsm`: 0.80 (menos features)

- `subsample`: 0.75 (menos amostras)

- `random_strength`: 2.5 (mais ru√≠do controlado)

- `border_count`: 48 (menos bins)

**Configura√ß√£o CatBoost 3B-1:**

```python
cat_params_3b1 = {
    'learning_rate': 0.05,
    'depth': 7,                    # ‚Üì de 8 ‚Üí 7
    'l2_leaf_reg': 12,             # ‚Üë de 8 ‚Üí 12
    'rsm': 0.80,                   # ‚Üì de 0.85 ‚Üí 0.80
    'bootstrap_type': "Bernoulli",
    'subsample': 0.75,             # ‚Üì de 0.8 ‚Üí 0.75
    'random_strength': 2.5,        # ‚Üë de 1.5 ‚Üí 2.5
    'border_count': 48             # ‚Üì de 64 ‚Üí 48
}
```

**Resultados Stacking 3B-1:**

- **Recall Classe 0 (Poor):** 0.829 üèÜ

- **F1-Score Macro:** 0.777

- **Acur√°cia:** 0.784

- **Acur√°cia de Treino:** 0.925

**An√°lise:** **Melhor recall para classe Poor at√© o momento!** A regulariza√ß√£o agressiva conseguiu melhorar a m√©trica principal mantendo controle de overfitting.

### 6.7. Experimenta√ß√£o com Modelos Alternativos

Durante a segunda √©poca, tamb√©m foram testados modelos alternativos como potenciais substitutos ou adi√ß√µes ao ensemble:

#### 6.7.1. XGBoost como Modelo Alvo

Foram testadas tr√™s variantes do XGBoost para avaliar se poderiam superar o ensemble:

**XGBoost GBTree (Round 1):**

- **Recall Classe 0 (Poor):** 0.731

- **F1-Score Macro:** 0.732

**XGBoost LossGuide:**

- **Recall Classe 0 (Poor):** 0.712

- **F1-Score Macro:** 0.721

**XGBoost DART:**

- **Recall Classe 0 (Poor):** 0.700

- **F1-Score Macro:** 0.708

**Conclus√£o:** Todos os XGBoost ficaram significativamente abaixo do baseline de stacking, sendo descartados. Os XGB avaliados exibem vi√©s alto na classe 0 e n√£o atingem o patamar do stack atual.

#### 6.7.2. CatBoost Individual como Modelo Alvo

**CatBoost C1 (Anti-Overfit Baseline):**

- **Recall Classe 0 (Poor):** 0.690

- **F1-Score Macro:** 0.701

- **Acur√°cia de Treino:** 0.772 (baixo overfitting)

**CatBoost C2 (C1 + Class Weights):**

- `class_weights = [1.8, 1.0, 1.0]` para favorecer classe 0

- **Recall Classe 0 (Poor):** 0.812

- **F1-Score Macro:** 0.715

**CatBoost H2 (Ajuste Fino de Class Weights):**

- **Recall Classe 0 (Poor):** 0.800

- **F1-Score Macro:** 0.733

**Conclus√£o:** Embora o CatBoost individual com class weights tenha alcan√ßado recall alto na classe Poor, o ensemble ainda superava em m√©tricas gerais e robustez.

---

## 7. MODELO CAMPE√ÉO FINAL: Stacking 3B-1

### 7.1. Identifica√ß√£o do Modelo Vencedor

Ap√≥s extensa experimenta√ß√£o em duas √©pocas, o **Stacking LGBM(2A) + CatBoost(3B-1) ‚Üí RF Meta** foi identificado como o modelo campe√£o final.

**Run ID no MLflow:** `bccfb26c333a41cf94facfc225cc8f2c`

### 7.2. Configura√ß√£o Final do Modelo Campe√£o

**Base Learners:**

1. **LightGBM (2A):**

```python
lgbm_params_final = {
    'learning_rate': 0.1,
    'colsample_bytree': 0.8,
    'min_split_gain': 0.1,
    'subsample': 0.7,
    'subsample_freq': 1,
    'num_leaves': 95,
    'max_depth': 10,
    'min_child_samples': 60,
    'reg_lambda': 1.0,
    'reg_alpha': 0.1,
    'n_estimators': 408
}
```

1. **CatBoost (3B-1):**

```python
catboost_params_final = {
    'learning_rate': 0.05,
    'depth': 7,
    'l2_leaf_reg': 12,
    'rsm': 0.80,
    'bootstrap_type': "Bernoulli",
    'subsample': 0.75,
    'random_strength': 2.5,
    'border_count': 48,
    'iterations': [determinado via early stopping]
}
```

**Meta-learner:**

```python
RandomForestClassifier(
    n_estimators=100,
    max_depth=3,
    random_state=42
)
```

### 7.3. Performance Final

| M√©trica | Valor | Observa√ß√µes |
| --- | --- | --- |
| **Recall Classe 0 (Poor)** | **0.829** | **M√©trica principal de neg√≥cio** |
| **Precision Classe 0 (Poor)** | **0.757** | Balanceamento adequado |
| **F1-Score Classe 0 (Poor)** | **0.792** | Harm√¥nica otimizada |
| **Recall Macro** | **0.788** | Excelente performance geral |
| **F1-Score Macro** | **0.777** | Consist√™ncia entre classes |
| **Acur√°cia** | **0.784** | Performance geral s√≥lida |
| **Acur√°cia de Treino** | **0.925** | Gap controlado (~14%) |

### 7.4. Justificativa da Escolha Final

**Por que o Stacking 3B-1 foi escolhido como campe√£o:**

1. **Melhor Recall Classe 0 (Poor):** 0.829 vs 0.842 da primeira √©poca - pequena redu√ß√£o compensada por maior robustez

1. **Controle de Overfitting:** Gap treino-teste mais controlado atrav√©s da regulariza√ß√£o agressiva

1. **Estabilidade:** Regulariza√ß√£o do CatBoost tornou o modelo mais est√°vel e confi√°vel

1. **Generaliza√ß√£o:** Early stopping e t√©cnicas de regulariza√ß√£o melhoraram a capacidade de generaliza√ß√£o

1. **Robustez:** Ensemble diversificado com base learners complementares

**Trade-off Aceito:** A pequena redu√ß√£o no recall da classe Poor (0.842 ‚Üí 0.829) foi aceita em troca de um modelo significativamente mais robusto e com menor risco de overfitting em produ√ß√£o.

**Coment√°rio T√©cnico:** Esta decis√£o exemplifica maturidade t√©cnica, priorizando sustentabilidade e confiabilidade do modelo em produ√ß√£o sobre performance m√°xima em ambiente controlado.

---

## 8. Valida√ß√£o Cruzada Externa

### 8.1. Metodologia de Valida√ß√£o

Para confirmar a robustez do modelo campe√£o, foi realizada uma **valida√ß√£o cruzada externa** com 5 folds:

```python
skf_externo = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
```

**Coment√°rio T√©cnico:** A valida√ß√£o externa utiliza dados completamente independentes do processo de otimiza√ß√£o, fornecendo estimativa n√£o enviesada da performance em produ√ß√£o.

### 8.2. Implementa√ß√£o da Valida√ß√£o Externa

```python
# Pipeline de valida√ß√£o cruzada externa
RUN_NAME = "ExternalCV_Stacking_LGBM_CatBoost3B1_RFMeta"
N_SPLITS_EXTERNO = 5

# Fun√ß√£o helper para estimar iterations do CatBoost
def _best_iters_catboost(X, y, base_params, n_splits=5, patience=45):
    """Estima 'iterations' para CatBoost via CV interna simples."""
    skf_inner = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
    tr_idx, va_idx = next(iter(skf_inner.split(X, y)))
    # ... implementa√ß√£o do early stopping
    return optimal_iterations
```

### 8.3. Resultados da Valida√ß√£o Externa

| Fold | Recall Macro | Recall Poor | F1 Macro | Itera√ß√µes CatBoost |
| --- | --- | --- | --- | --- |
| 1 | 0.7899 | 0.8343 | 0.7801 | 761 |
| 2 | 0.8013 | 0.8540 | 0.7836 | 1247 |
| 3 | 0.7959 | 0.8430 | 0.7836 | 1997 |
| 4 | 0.7972 | 0.8456 | 0.7845 | 1456 |
| 5 | 0.7952 | 0.8381 | 0.7862 | 1123 |

**Estat√≠sticas Agregadas:**

- **Recall Macro:** 0.7959 ¬± 0.0045

- **Recall Poor:** 0.8430 ¬± 0.0092

- **F1 Macro:** 0.7836 ¬± 0.0034

### 8.4. An√°lise da Valida√ß√£o

**Confirma√ß√£o da Robustez:** A valida√ß√£o cruzada externa confirmou que o modelo mant√©m performance est√°vel e consistente, com recall da classe Poor variando apenas entre 0.8343 e 0.8540.

**Baixa Vari√¢ncia:** O desvio padr√£o baixo em todas as m√©tricas indica que o modelo √© robusto e n√£o depende de divis√µes espec√≠ficas dos dados.

**Generaliza√ß√£o Confirmada:** Os resultados da valida√ß√£o externa s√£o consistentes com os resultados do holdout test, confirmando a capacidade de generaliza√ß√£o.

**Adaptabilidade do Early Stopping:** Embora as itera√ß√µes √≥timas do CatBoost tenham variado (761‚Äì1997), a performance permaneceu est√°vel ‚Äî bom sinal de robustez do ensemble.

---

## 9. Evolu√ß√£o da Performance ao Longo das √âpocas

### 9.1. Trajet√≥ria Completa da Experimenta√ß√£o

| √âpoca | Modelo | Recall Poor | F1 Macro | Estrat√©gia | Coment√°rio T√©cnico |
| --- | --- | --- | --- | --- | --- |
| 1¬™ | XGBoost Individual | 0.727 | 0.727 | Baseline | RandomizedSearchCV inicial |
| 1¬™ | LightGBM Individual | 0.778 | 0.766 | Otimiza√ß√£o | Superou XGBoost |
| 1¬™ | CatBoost Individual | 0.743 | 0.765 | Fine-tuning | Melhor individual |
| 1¬™ | **Stacking LGBM+CatBoost** | **0.842** | **0.785** | **Primeiro Ensemble** | **Salto de 6+ p.p.** |
| 2¬™ | Stacking 2A | 0.819 | 0.776 | Refinamento | Meta-learner robusto |
| 2¬™ | Stacking 2B | 0.821 | 0.779 | Random Search | Melhoria marginal |
| 2¬™ | Stacking 3A | 0.820 | 0.776 | Regulariza√ß√£o | Controle overfitting |
| 2¬™ | **Stacking 3B-1** | **0.829** | **0.777** | **Regulariza√ß√£o Agressiva** | **Equil√≠brio √≥timo** |

### 9.2. Insights da Trajet√≥ria

**Salto Inicial:** O primeiro ensemble (0.842) representou um salto significativo em rela√ß√£o aos modelos individuais (+6 pontos percentuais).

**Refinamento Gradual:** A segunda √©poca focou em refinamento e controle de overfitting, priorizando robustez sobre performance m√°xima.

**Decis√£o Estrat√©gica:** A escolha do 3B-1 sobre o modelo da primeira √©poca reflete uma decis√£o madura de priorizar estabilidade e generaliza√ß√£o.

**Coment√°rio T√©cnico:** A trajet√≥ria demonstra evolu√ß√£o natural do processo de ML: explora√ß√£o inicial ‚Üí otimiza√ß√£o de performance ‚Üí foco em robustez e produ√ß√£o.

---

## 10. Registro em Produ√ß√£o

### 10.1. Model Registry

O modelo campe√£o foi registrado no MLflow Model Registry:

```python
run_id = "bccfb26c333a41cf94facfc225cc8f2c"

mlflow.register_model(
    model_uri=f"runs:/{run_id}/model",
    name="credit-score-model"
)
```

### 10.2. Versionamento

- **Nome do Modelo:** `credit-score-model`

- **Vers√£o:** 3

- **Status:** Production Ready

- **Run ID:** `bccfb26c333a41cf94facfc225cc8f2c`

**Coment√°rio T√©cnico:** O registro no Model Registry permite versionamento, promo√ß√£o entre ambientes (staging ‚Üí production) e rollback seguro se necess√°rio.

---

## 11. Li√ß√µes Aprendidas e Insights Estrat√©gicos

### 11.1. Insights T√©cnicos Principais

1. **Ensembles Superam Modelos Individuais:** O primeiro stacking proporcionou ganho de 6+ pontos percentuais no recall da classe Poor.

1. **Regulariza√ß√£o √© Fundamental:** A vers√£o 3B-1 com regulariza√ß√£o agressiva encontrou o melhor equil√≠brio entre performance e robustez.

1. **Trade-offs Conscientes:** Aceitar pequena redu√ß√£o na performance m√°xima em troca de maior estabilidade foi a decis√£o correta.

1. **Early Stopping Cr√≠tico:** Fundamental para encontrar o ponto √≥timo de itera√ß√µes sem overfitting.

1. **Diversidade no Ensemble:** LightGBM + CatBoost ofereceram complementaridade ideal sem redund√¢ncia.

### 11.2. Estrat√©gias de Experimenta√ß√£o Eficazes

1. **Experimenta√ß√£o Estruturada:** Divis√£o em √©pocas permitiu progress√£o l√≥gica da complexidade.

1. **Foco na M√©trica de Neg√≥cio:** Prioriza√ß√£o consistente do recall da classe Poor guiou todas as decis√µes.

1. **Valida√ß√£o Rigorosa:** Valida√ß√£o cruzada externa confirmou robustez das escolhas.

1. **MLOps desde o In√≠cio:** Rastreamento completo facilitou compara√ß√µes e reprodutibilidade.

1. **An√°lise de Trade-offs:** Considera√ß√£o sistem√°tica de performance vs. robustez vs. custo computacional.

### 11.3. Decis√µes Arquiteturais Acertadas

1. **Ensemble Diversificado:** LightGBM + CatBoost ofereceram complementaridade ideal.

1. **Meta-learner Simples:** RandomForest raso evitou overfitting no n√≠vel meta.

1. **Regulariza√ß√£o Progressiva:** Abordagem gradual permitiu encontrar o ponto √≥timo.

1. **Passthrough=False:** Concentrou decis√£o nas sa√≠das dos base learners, reduzindo complexidade.

### 11.4. Coment√°rios T√©cnicos Adicionais

**Sobre RandomizedSearchCV:** O uso de n_iter‚âà30 com cv=5 equilibrou custo/benef√≠cio, permitindo explorar regi√µes promissoras do hiper-espa√ßo sem custo computacional excessivo.

**Sobre Valida√ß√£o Externa:** A aplica√ß√£o de valida√ß√£o cruzada externa (5 folds) foi crucial para aferir generaliza√ß√£o al√©m do split fixo, diminuindo a chance de conclus√µes dependentes de uma √∫nica parti√ß√£o.

**Sobre Meta-learners:** A evolu√ß√£o de DecisionTree ‚Üí RandomForest como meta-learner melhorou a generaliza√ß√£o do stack, demonstrando import√¢ncia da escolha do meta-modelo.

---

## 12. Pr√≥ximos Passos e Recomenda√ß√µes

### 12.1. Melhorias Futuras

1. **An√°lise de Erros:** Investigar os 17.1% de falsos negativos da classe Poor para identificar padr√µes sistem√°ticos e oportunidades de feature engineering.

1. **Feature Engineering Avan√ßada:** Explorar intera√ß√µes entre vari√°veis e features temporais baseadas nos erros identificados.

1. **Calibra√ß√£o de Probabilidades:** Implementar calibra√ß√£o (Platt scaling ou isotonic regression) para melhor interpreta√ß√£o das probabilidades de risco.

1. **Ensemble de Terceiro N√≠vel:** Avaliar adi√ß√£o de um terceiro base learner ou t√©cnicas de voting para aumentar diversidade.

1. **Otimiza√ß√£o de Hiperpar√¢metros Bayesiana:** Substituir RandomizedSearchCV por Optuna ou similar para busca mais eficiente.

### 12.2. Monitoramento em Produ√ß√£o

1. **Drift Detection:** Monitorar mudan√ßas na distribui√ß√£o das features e performance do modelo usando t√©cnicas como KS-test ou PSI.

1. **Performance Tracking:** Acompanhar m√©tricas de neg√≥cio e t√©cnicas em tempo real com alertas autom√°ticos.

1. **Retreinamento Autom√°tico:** Estabelecer gatilhos baseados em degrada√ß√£o de performance ou drift significativo.

1. **A/B Testing:** Comparar performance com modelos alternativos em ambiente controlado antes de atualiza√ß√µes.

### 12.3. Considera√ß√µes de Neg√≥cio

1. **Interpretabilidade:** Desenvolver explica√ß√µes SHAP para decis√µes cr√≠ticas do modelo, especialmente para clientes rejeitados.

1. **Fairness:** Avaliar vieses em diferentes segmentos demogr√°ficos e geogr√°ficos usando m√©tricas de equidade.

1. **Regulamenta√ß√£o:** Garantir compliance com regulamenta√ß√µes financeiras (LGPD, Basel III, resolu√ß√£o 4.658 do BACEN).

1. **Impacto Financeiro:** Quantificar o valor gerado pela melhoria na identifica√ß√£o de clientes Poor atrav√©s de an√°lise de lift e ROI.

### 12.4. Aspectos Operacionais

1. **Lat√™ncia:** Otimizar tempo de infer√™ncia para atender SLAs de neg√≥cio.

1. **Escalabilidade:** Preparar infraestrutura para volume crescente de predi√ß√µes.

1. **Backup e Recovery:** Implementar estrat√©gias de conting√™ncia para falhas do modelo.

1. **Documenta√ß√£o:** Manter documenta√ß√£o t√©cnica e de neg√≥cio atualizada para facilitar manuten√ß√£o.

---

## 13. Conclus√£o

O projeto de desenvolvimento de modelos para previs√£o de score de cr√©dito foi executado com rigor metodol√≥gico e resultou na identifica√ß√£o de uma solu√ß√£o robusta e eficaz. O **modelo campe√£o Stacking 3B-1** alcan√ßou **82.9% de recall na classe Poor**, representando um equil√≠brio otimizado entre performance e robustez.

A jornada da experimenta√ß√£o, estruturada em duas √©pocas distintas, demonstrou a evolu√ß√£o natural do processo de machine learning: da busca pela performance m√°xima (primeira √©poca com 84.2% de recall) para a otimiza√ß√£o da robustez e generaliza√ß√£o (segunda √©poca com 82.9% de recall, mas maior estabilidade).

### 13.1. Principais Conquistas

1. **Performance de Neg√≥cio:** 82.9% de recall na classe Poor atende aos objetivos cr√≠ticos de identifica√ß√£o de risco.

1. **Robustez Comprovada:** Valida√ß√£o cruzada externa confirmou estabilidade com baixa vari√¢ncia (¬±0.0092).

1. **Arquitetura S√≥lida:** Ensemble diversificado com regulariza√ß√£o adequada para produ√ß√£o.

1. **Processo Reprodut√≠vel:** MLOps completo garante manutenibilidade e evolu√ß√£o cont√≠nua.

1. **Decis√µes Fundamentadas:** Cada escolha t√©cnica foi documentada e justificada com base em evid√™ncias emp√≠ricas.

### 13.2. Valor T√©cnico e de Neg√≥cio

**T√©cnico:**

- Framework replic√°vel para projetos similares de ML em finan√ßas

- Metodologia robusta de experimenta√ß√£o e valida√ß√£o

- Integra√ß√£o completa de ferramentas MLOps

**Neg√≥cio:**

- Redu√ß√£o significativa de falsos negativos em clientes de alto risco

- Modelo confi√°vel para decis√µes cr√≠ticas de cr√©dito

- Base s√≥lida para expans√£o e melhorias futuras

### 13.3. Reflex√£o Final

A abordagem metodol√≥gica, combinada com uma infraestrutura s√≥lida de MLOps, n√£o apenas garantiu a qualidade do modelo final, mas tamb√©m estabeleceu um framework replic√°vel para projetos similares de machine learning em contextos financeiros de alto risco.

O **Stacking 3B-1** representa n√£o apenas um modelo de alta performance, mas uma solu√ß√£o equilibrada que prioriza a confiabilidade e a generaliza√ß√£o necess√°rias para aplica√ß√µes cr√≠ticas de neg√≥cio. A documenta√ß√£o c√©lula por c√©lula garante que todo o conhecimento t√©cnico seja preservado e transfer√≠vel, facilitando manuten√ß√£o, evolu√ß√£o e replica√ß√£o do projeto.

**Coment√°rio T√©cnico Final:** Este projeto exemplifica as melhores pr√°ticas em ci√™ncia de dados aplicada, demonstrando como combinar rigor cient√≠fico, considera√ß√µes pr√°ticas de neg√≥cio e excel√™ncia t√©cnica para entregar solu√ß√µes de machine learning de classe mundial.

